<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Huggingface🤗NLP笔记3：Pipeline端到端的背后发生了什么 | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/60.ee946b2f.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link router-link-active">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link router-link-active">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Huggingface🤗NLP笔记3：Pipeline端到端的背后发生了什么</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/nlp_basis/notes/HuggingfaceNLP-3.%20Pipeline%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E8%83%8C%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88.html#_1-tokenizer" class="sidebar-link">1. Tokenizer</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-3.%20Pipeline%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E8%83%8C%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88.html#_2-model" class="sidebar-link">2. Model</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-3.%20Pipeline%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E8%83%8C%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88.html#_3-model-heads" class="sidebar-link">3. Model Heads</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-3.%20Pipeline%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E8%83%8C%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88.html#_4-post-processing" class="sidebar-link">4. Post-Processing</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><blockquote><p><strong>「Huggingface🤗NLP笔记系列-第3集」</strong>
最近跟着Huggingface上的NLP tutorial走了一遍，惊叹居然有如此好的讲解Transformers系列的NLP教程，于是决定记录一下学习的过程，分享我的笔记，可以算是官方教程的精简版。但最推荐的，还是直接跟着官方教程来一遍，真是一种享受。</p></blockquote> <ul><li>官方教程网址：https://huggingface.co/course/chapter1</li> <li>本期内容对应网址：https://huggingface.co/course/chapter2/2?fw=pt</li> <li>本系列笔记的<strong>GitHub</strong>： https://github.com/beyondguo/Learn_PyTorch/tree/master/HuggingfaceNLP</li></ul> <hr> <h1 id="pipeline端到端的背后发生了什么"><a href="#pipeline端到端的背后发生了什么" class="header-anchor">#</a> Pipeline端到端的背后发生了什么</h1> <p>Pipeline的背后：
<img src="https://huggingface.co/course/static/chapter2/full_nlp_pipeline.png" width="1000"></p> <h2 id="_1-tokenizer"><a href="#_1-tokenizer" class="header-anchor">#</a> 1. Tokenizer</h2> <p>我们使用的tokenizer必须跟对应的模型在预训练时的tokenizer保持一致，也就是词表需要一致。<br>
Huggingface中可以直接指定模型的checkpoint的名字，然后自动下载对应的词表。<br>
具体方式是：</p> <ul><li>使用<code>AutoTokenizer</code>的<code>from_pretrained</code>方法</li></ul> <p><code>tokenizer</code>这个对象可以直接接受参数并输出结果，即它是callable的。具体参数见：<br>
https://huggingface.co/transformers/master/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase <br>
主要参数包括：</p> <ul><li>text，可以是单条的string，也可以是一个string的list，还可以是list的list</li> <li>padding，用于填白</li> <li>truncation，用于截断</li> <li>max_length，设置最大句长</li> <li>return_tensors，设置返回数据类型</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

checkpoint <span class="token operator">=</span> <span class="token string">'distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>先看看直接使用tokenizer的结果：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>raw_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Today is a good day! Woo~~~'</span><span class="token punctuation">,</span>
              <span class="token string">'How about tomorrow?'</span><span class="token punctuation">]</span>
tokenizer<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2651</span>, <span class="token number">2003</span>, <span class="token number">1037</span>, <span class="token number">2204</span>, <span class="token number">2154</span>, <span class="token number">999</span>, <span class="token number">15854</span>, <span class="token number">1066</span>, <span class="token number">1066</span>, <span class="token number">1066</span>, <span class="token number">102</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2129</span>, <span class="token number">2055</span>, <span class="token number">4826</span>, <span class="token number">1029</span>, <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>可以加上一个 <code>padding=Ture</code> 参数，让得到的序列长度对齐：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tokenizer<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2651</span>, <span class="token number">2003</span>, <span class="token number">1037</span>, <span class="token number">2204</span>, <span class="token number">2154</span>, <span class="token number">999</span>, <span class="token number">15854</span>, <span class="token number">1066</span>, <span class="token number">1066</span>, <span class="token number">1066</span>, <span class="token number">102</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2129</span>, <span class="token number">2055</span>, <span class="token number">4826</span>, <span class="token number">1029</span>, <span class="token number">102</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>tokenizer还有<code>truncation</code>和<code>max_length</code>属性，用于在max_length处截断：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tokenizer<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span> 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2651</span>, <span class="token number">2003</span>, <span class="token number">1037</span>, <span class="token number">2204</span>, <span class="token number">2154</span>, <span class="token number">102</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2129</span>, <span class="token number">2055</span>, <span class="token number">4826</span>, <span class="token number">1029</span>, <span class="token number">102</span>, <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span>, <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><code>return_tensors</code>属性也很重要，用来指定返回的是什么类型的tensors，<code>pt</code>就是pytorch，<code>tf</code>就是tensorflow：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tokenizer<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span>,  <span class="token number">2651</span>,  <span class="token number">2003</span>,  <span class="token number">1037</span>,  <span class="token number">2204</span>,  <span class="token number">2154</span>,   <span class="token number">999</span>, <span class="token number">15854</span>,  <span class="token number">1066</span>,  <span class="token number">1066</span>,
          <span class="token number">1066</span>,   <span class="token number">102</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span>  <span class="token number">101</span>,  <span class="token number">2129</span>,  <span class="token number">2055</span>,  <span class="token number">4826</span>,  <span class="token number">1029</span>,   <span class="token number">102</span>,     <span class="token number">0</span>,     <span class="token number">0</span>,     <span class="token number">0</span>,     <span class="token number">0</span>,
             <span class="token number">0</span>,     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>, <span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="_2-model"><a href="#_2-model" class="header-anchor">#</a> 2. Model</h2> <p>也可以通过AutoModel来直接从checkpoint导入模型。</p> <p>这里导入的模型，是Transformer的基础模型，接受tokenize之后的输入，<strong>输出hidden states，即文本的向量表示</strong>，是一种上下文表示。</p> <p>这个向量表示，会有三个维度：</p> <ol><li>batch size</li> <li>sequence length</li> <li>hidden size</li></ol> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModel
model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>加载了模型之后，就可以把tokenizer得到的输出，直接输入到model中：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>  <span class="token comment"># 这里变量前面的**，代表把inputs这个dictionary给分解成一个个参数单独输进去</span>
<span class="token builtin">vars</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 查看一下输出有哪些属性</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>dict_keys<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'last_hidden_state'</span>, <span class="token string">'hidden_states'</span>, <span class="token string">'attentions'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p><strong>这里顺便讲一讲这个函数中<code>**</code>的用法：</strong></p></blockquote> <p><code>**</code>在函数中的作用就是把后面紧跟着的这个参数，从一个字典的格式，解压成一个个单独的参数。</p> <p>回顾一下上面tokenizer的输出，我们发现它是一个包含了input_ids和attention_mask两个key的<strong>字典</strong>，因此通过<code>**</code>的解压，相当于变成了<code>intput_ids=..., attention_mask=...</code>喂给函数。</p> <p>我们再来查看一下通过AutoModel加载的DistillBertModel模型的输入：
https://huggingface.co/transformers/master/model_doc/distilbert.html#distilbertmodel</p> <p>可以看到DistillBertModel的直接call的函数是：</p> <p><code>forward(input_ids=None, attention_mask=None, ...)</code>
正好跟<code>**inputs</code>后的格式对应上。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>last_hidden_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
outputs<span class="token punctuation">.</span>last_hidden_state
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>torch.Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span>, <span class="token number">12</span>, <span class="token number">768</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4627</span>,  <span class="token number">0.3042</span>,  <span class="token number">0.5431</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.3706</span>,  <span class="token number">1.0033</span>, -0.6074<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.6100</span>,  <span class="token number">0.3093</span>,  <span class="token number">0.2038</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.3788</span>,  <span class="token number">0.9370</span>, -0.6439<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.6514</span>,  <span class="token number">0.3185</span>,  <span class="token number">0.3855</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.4152</span>,  <span class="token number">1.0199</span>, -0.4450<span class="token punctuation">]</span>,
             <span class="token punctuation">..</span>.,
             <span class="token punctuation">[</span> <span class="token number">0.3674</span>,  <span class="token number">0.1380</span>,  <span class="token number">1.1619</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.4976</span>,  <span class="token number">0.4758</span>, -0.5896<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.4182</span>,  <span class="token number">0.2503</span>,  <span class="token number">1.0898</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.4745</span>,  <span class="token number">0.4042</span>, -0.5444<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">1.1614</span>,  <span class="token number">0.2516</span>,  <span class="token number">0.9561</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.5742</span>,  <span class="token number">0.8437</span>, -0.9604<span class="token punctuation">]</span><span class="token punctuation">]</span>,
    
            <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.7956</span>, -0.2343,  <span class="token number">0.3810</span>,  <span class="token punctuation">..</span>., -0.1270,  <span class="token number">0.5182</span>, -0.1612<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.9337</span>,  <span class="token number">0.2074</span>,  <span class="token number">0.6202</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.1874</span>,  <span class="token number">0.6584</span>, -0.1899<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.6279</span>, -0.3176,  <span class="token number">0.1596</span>,  <span class="token punctuation">..</span>., -0.2956,  <span class="token number">0.2960</span>, -0.1447<span class="token punctuation">]</span>,
             <span class="token punctuation">..</span>.,
             <span class="token punctuation">[</span> <span class="token number">0.3050</span>,  <span class="token number">0.0396</span>,  <span class="token number">0.6345</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.4271</span>,  <span class="token number">0.3367</span>, -0.3285<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.1773</span>,  <span class="token number">0.0111</span>,  <span class="token number">0.6275</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.3831</span>,  <span class="token number">0.3543</span>, -0.2919<span class="token punctuation">]</span>,
             <span class="token punctuation">[</span> <span class="token number">0.2756</span>,  <span class="token number">0.0048</span>,  <span class="token number">0.9281</span>,  <span class="token punctuation">..</span>.,  <span class="token number">0.2006</span>,  <span class="token number">0.4375</span>, -0.3238<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>,
           <span class="token assign-left variable">grad_fn</span><span class="token operator">=</span><span class="token operator">&lt;</span>NativeLayerNormBackward<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>可以看到，输出的shape是<code>torch.Size([2, 12, 768])</code>，三个维度分别是 batch，seq_len和hidden size。</p> <h2 id="_3-model-heads"><a href="#_3-model-heads" class="header-anchor">#</a> 3. Model Heads</h2> <p>模型头，接在基础模型的后面，用于将hidden states文本表示进一步处理，用于具体的任务。</p> <p>整体框架图：</p> <img src="https://huggingface.co/course/static/chapter2/transformer_and_head.png" width="1000"> <p>Head一般是由若干层的线性层来构成的。</p> <p>Transformers库中的主要模型架构有：</p> <ul><li>*Model (retrieve the hidden states)</li> <li>*ForCausalLM</li> <li>*ForMaskedLM</li> <li>*ForMultipleChoice</li> <li>*ForQuestionAnswering</li> <li>*ForSequenceClassification</li> <li>*ForTokenClassification</li> <li>...</li></ul> <p>单纯的<code>*Model</code>，就是不包含 Head 的模型，而有<code>For*</code>的则是包含了具体 Head 的模型。</p> <p>例如，对于前面的那个做在情感分析上pretrain的checkpoint(distilbert-base-uncased-finetuned-sst-2-english)，我们可以使用包含 SequenceClassification 的Head的模型去加载，就可以直接得到对应分类问题的logits，而不仅仅是文本向量表示。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification
clf <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> clf<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">vars</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
outputs<span class="token punctuation">.</span>logits
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>dict_keys<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'loss'</span>, <span class="token string">'logits'</span>, <span class="token string">'hidden_states'</span>, <span class="token string">'attentions'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>-4.2098,  <span class="token number">4.6444</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span> <span class="token number">0.6367</span>, -0.3753<span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">grad_fn</span><span class="token operator">=</span><span class="token operator">&lt;</span>AddmmBackward<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>从outputs的属性就可以看出，带有Head的Model，跟不带Head的Model，输出的东西是不一样的。</p> <p><strong>没有Head的Model</strong>，输出的是<code>'last_hidden_state', 'hidden_states', 'attentions'</code>这些玩意儿，因为它仅仅是一个表示模型；</p> <p><strong>有Head的Model</strong>，输出的是<code>'loss', 'logits', 'hidden_states', 'attentions'</code>这些玩意儿，有logits，loss这些东西，因为它是一个完整的预测模型了。</p> <p>可以顺便看看，加了这个 SequenceClassification Head的DistillBertModel的文档，看看其输入和输出：</p> <p>https://huggingface.co/transformers/master/model_doc/distilbert.html#distilbertforsequenceclassification</p> <p>可以看到，输入中，我们还可以提供<code>labels</code>，这样就可以直接计算loss了。</p> <h2 id="_4-post-processing"><a href="#_4-post-processing" class="header-anchor">#</a> 4. Post-Processing</h2> <p>后处理主要就是两步：</p> <ul><li>把logits转化成概率值 （用softmax）</li> <li>把概率值跟具体的标签对应上 （使用模型的config中的id2label）</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># dim=-1就是沿着最后一维进行操作</span>
predictions
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span>.4276e-04, <span class="token number">9</span>.9986e-01<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">7</span>.3341e-01, <span class="token number">2</span>.6659e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">grad_fn</span><span class="token operator">=</span><span class="token operator">&lt;</span>SoftmaxBackward<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>得到了概率分布，还得知道具体是啥标签吧。标签跟id的隐射关系，也已经被保存在每个pretrain model的config中了，
我们可以去模型的<code>config</code>属性中查看<code>id2label</code>字段：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>id2label <span class="token operator">=</span> clf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label
id2label
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">{</span><span class="token number">0</span>: <span class="token string">'NEGATIVE'</span>, <span class="token number">1</span>: <span class="token string">'POSITIVE'</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>综合起来，直接从prediction得到标签：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">for</span> i <span class="token keyword">in</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>id2label<span class="token punctuation">[</span>i<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>    POSITIVE
    NEGATIVE
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/60.ee946b2f.js" defer></script>
  </body>
</html>
