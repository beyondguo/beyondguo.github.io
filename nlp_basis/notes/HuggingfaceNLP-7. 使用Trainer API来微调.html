<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Huggingface🤗NLP笔记7：使用Trainer API来微调模型 | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/64.61b2d608.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link router-link-active">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link router-link-active">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Huggingface🤗NLP笔记7：使用Trainer API来微调模型</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/nlp_basis/notes/HuggingfaceNLP-7.%20%E4%BD%BF%E7%94%A8Trainer%20API%E6%9D%A5%E5%BE%AE%E8%B0%83.html#_1-数据集准备和预处理" class="sidebar-link">1. 数据集准备和预处理：</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-7.%20%E4%BD%BF%E7%94%A8Trainer%20API%E6%9D%A5%E5%BE%AE%E8%B0%83.html#_2-加载我们要fine-tune的模型" class="sidebar-link">2. 加载我们要fine-tune的模型：</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-7.%20%E4%BD%BF%E7%94%A8Trainer%20API%E6%9D%A5%E5%BE%AE%E8%B0%83.html#_3-使用trainer来训练" class="sidebar-link">3. 使用Trainer来训练</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-7.%20%E4%BD%BF%E7%94%A8Trainer%20API%E6%9D%A5%E5%BE%AE%E8%B0%83.html#_4-构建trainer中的compute-metrics函数" class="sidebar-link">4.构建Trainer中的compute_metrics函数</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/nlp_basis/notes/HuggingfaceNLP-7.%20%E4%BD%BF%E7%94%A8Trainer%20API%E6%9D%A5%E5%BE%AE%E8%B0%83.html#总结一下这个过程" class="sidebar-link">总结一下这个过程：</a></li></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-7.%20%E4%BD%BF%E7%94%A8Trainer%20API%E6%9D%A5%E5%BE%AE%E8%B0%83.html#看看带上了-compute-metrics-之后的训练" class="sidebar-link">看看带上了 compute_metrics 之后的训练：</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><blockquote><p><strong>「Huggingface🤗NLP笔记系列-第7集」</strong>
最近跟着Huggingface上的NLP tutorial走了一遍，惊叹居然有如此好的讲解Transformers系列的NLP教程，于是决定记录一下学习的过程，分享我的笔记，可以算是官方教程的<strong>精简+注解版</strong>。但最推荐的，还是直接跟着官方教程来一遍，真是一种享受。</p></blockquote> <ul><li>官方教程网址：https://huggingface.co/course/chapter1</li> <li>本期内容对应网址：https://huggingface.co/course/chapter3/3?fw=pt</li> <li>本系列笔记的<strong>GitHub</strong>： https://github.com/beyondguo/Learn_PyTorch/tree/master/HuggingfaceNLP</li></ul> <hr> <h1 id="使用trainer-api来微调模型"><a href="#使用trainer-api来微调模型" class="header-anchor">#</a> 使用Trainer API来微调模型</h1> <h2 id="_1-数据集准备和预处理"><a href="#_1-数据集准备和预处理" class="header-anchor">#</a> 1. 数据集准备和预处理：</h2> <p>这部分就是回顾上一集的内容：</p> <ul><li>通过dataset包加载数据集</li> <li>加载预训练模型和tokenizer</li> <li>定义Dataset.map要使用的预处理函数</li> <li>定义DataCollator来用于构造训练batch</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> DataCollatorWithPadding
<span class="token keyword">import</span> datasets
checkpoint <span class="token operator">=</span> <span class="token string">'bert-base-cased'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
raw_datasets <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>sample<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
tokenized_datasets <span class="token operator">=</span> raw_datasets<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h2 id="_2-加载我们要fine-tune的模型"><a href="#_2-加载我们要fine-tune的模型" class="header-anchor">#</a> 2. 加载我们要fine-tune的模型：</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>warnings<span class="token punctuation">)</span>
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: <span class="token punctuation">[</span><span class="token string">'cls.predictions.bias'</span>, <span class="token string">'cls.predictions.transform.dense.weight'</span>, <span class="token string">'cls.predictions.transform.dense.bias'</span>, <span class="token string">'cls.predictions.decoder.weight'</span>, <span class="token string">'cls.seq_relationship.weight'</span>, <span class="token string">'cls.seq_relationship.bias'</span>, <span class="token string">'cls.predictions.transform.LayerNorm.weight'</span>, <span class="token string">'cls.predictions.transform.LayerNorm.bias'</span><span class="token punctuation">]</span>
- This IS expected <span class="token keyword">if</span> you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture <span class="token punctuation">(</span>e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model<span class="token punctuation">)</span>.
- This IS NOT expected <span class="token keyword">if</span> you are initializing BertForSequenceClassification from the checkpoint of a model that you <span class="token function">expect</span> to be exactly identical <span class="token punctuation">(</span>initializing a BertForSequenceClassification model from a BertForSequenceClassification model<span class="token punctuation">)</span>.
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: <span class="token punctuation">[</span><span class="token string">'classifier.weight'</span>, <span class="token string">'classifier.bias'</span><span class="token punctuation">]</span>
You should probably TRAIN this model on a down-stream task to be able to use it <span class="token keyword">for</span> predictions and inference.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>不得不说，这个Huggingface很贴心，这里的warning写的很清楚。这里我们使用的是带<code>ForSequenceClassification</code>这个Head的模型，但是我们的<code>bert-baed-cased</code>虽然它本身也有自身的Head，但跟我们这里的二分类任务不匹配，所以可以看到，它的Head被移除了，使用了一个随机初始化的<code>ForSequenceClassification</code>Head。</p> <p>所以这里提示还说：&quot;You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.&quot;</p> <h2 id="_3-使用trainer来训练"><a href="#_3-使用trainer来训练" class="header-anchor">#</a> 3. 使用<code>Trainer</code>来训练</h2> <p><code>Trainer</code>是Huggingface transformers库的一个高级API，可以帮助我们快速搭建训练框架：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Trainer<span class="token punctuation">,</span> TrainingArguments

training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>output_dir<span class="token operator">=</span><span class="token string">'test_trainer'</span><span class="token punctuation">)</span> <span class="token comment"># 指定输出文件夹，没有会自动创建</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span>
    training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;validation&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>  <span class="token comment"># 在定义了tokenizer之后，其实这里的data_collator就不用再写了，会自动根据tokenizer创建</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>我们看看<code>TrainingArguments</code>和<code>Trainer</code>的参数都有些啥：</p> <ul><li>https://huggingface.co/transformers/master/main_classes/trainer.html</li> <li>https://huggingface.co/transformers/master/main_classes/trainer.html#trainingarguments</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    overwrite_output_dir<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    do_train<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    do_eval<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    do_predict<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token punctuation">:</span> transformers<span class="token punctuation">.</span>trainer_utils<span class="token punctuation">.</span>EvaluationStrategy <span class="token operator">=</span> <span class="token string">'no'</span><span class="token punctuation">,</span>
    prediction_loss_only<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token comment"># 默认的batch_size=8</span>
    per_device_eval_batch_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span>
    per_gpu_train_batch_size<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    per_gpu_eval_batch_size<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    gradient_accumulation_steps<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
    eval_accumulation_steps<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    learning_rate<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">05</span><span class="token punctuation">,</span>
    weight_decay<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
    adam_beta1<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.9</span><span class="token punctuation">,</span>
    adam_beta2<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.999</span><span class="token punctuation">,</span>
    adam_epsilon<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">,</span>
    max_grad_norm<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">3.0</span><span class="token punctuation">,</span>   <span class="token comment"># 默认跑3轮</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><div class="language-python line-numbers-mode"><pre class="language-python"><code>Trainer<span class="token punctuation">(</span>
    model<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>transformers<span class="token punctuation">.</span>modeling_utils<span class="token punctuation">.</span>PreTrainedModel<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>module<span class="token punctuation">.</span>Module<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    args<span class="token punctuation">:</span> transformers<span class="token punctuation">.</span>training_args<span class="token punctuation">.</span>TrainingArguments <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    data_collator<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>DataCollator<span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    train_dataset<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>Dataset<span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    eval_dataset<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>Dataset<span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    tokenizer<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>ForwardRef<span class="token punctuation">(</span><span class="token string">'PreTrainedTokenizerBase'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    model_init<span class="token punctuation">:</span> Callable<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> transformers<span class="token punctuation">.</span>modeling_utils<span class="token punctuation">.</span>PreTrainedModel<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    compute_metrics<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>Callable<span class="token punctuation">[</span><span class="token punctuation">[</span>transformers<span class="token punctuation">.</span>trainer_utils<span class="token punctuation">.</span>EvalPrediction<span class="token punctuation">]</span><span class="token punctuation">,</span> Dict<span class="token punctuation">]</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    callbacks<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>List<span class="token punctuation">[</span>transformers<span class="token punctuation">.</span>trainer_callback<span class="token punctuation">.</span>TrainerCallback<span class="token punctuation">]</span><span class="token punctuation">,</span> NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    optimizers<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Optimizer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 默认会使用AdamW</span>
<span class="token punctuation">)</span>
Docstring<span class="token punctuation">:</span>     
Trainer <span class="token keyword">is</span> a simple but feature<span class="token operator">-</span>complete training <span class="token keyword">and</span> <span class="token builtin">eval</span> loop <span class="token keyword">for</span> PyTorch<span class="token punctuation">,</span> optimized <span class="token keyword">for</span> 🤗 Transformers<span class="token punctuation">.</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>可见，这个<code>Trainer</code>把所有训练中需要考虑的参数、设计都包括在内了，我们可以在这里指定训练验证集、data_collator、metrics、optimizer，并通过<code>TrainingArguments</code>来提供各种超参数。</p> <p>默认情况下，<code>Trainer</code>和<code>TrainingArguments</code>会使用：</p> <ul><li>batch size=8</li> <li>epochs = 3</li> <li>AdamW优化器</li></ul> <p>定义好之后，直接使用<code>.train()</code>来启动训练：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>输出：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20210927151316.png" alt="image-20210927151316532"></p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>TrainOutput<span class="token punctuation">(</span>global_step<span class="token operator">=</span><span class="token number">1377</span>, <span class="token assign-left variable">training_loss</span><span class="token operator">=</span><span class="token number">0.35569445984728887</span>, <span class="token assign-left variable">metrics</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'train_runtime'</span><span class="token builtin class-name">:</span> <span class="token number">383.0158</span>, <span class="token string">'train_samples_per_second'</span><span class="token builtin class-name">:</span> <span class="token number">3.595</span>, <span class="token string">'total_flos'</span><span class="token builtin class-name">:</span> <span class="token number">530185443455520</span>, <span class="token string">'epoch'</span><span class="token builtin class-name">:</span> <span class="token number">3.0</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>然后我们用<code>Trainer</code>来预测：</p> <p><code>trainer.predict()</code>函数处理的结果是一个<code>named_tuple</code>（一种可以直接通过key来取值的tuple），类似一个字典，包含三个属性：predictions, label_ids, metrics</p> <p>注意，这里的三个属性：</p> <ul><li><code>predictions</code>实际上就是logits</li> <li><code>label_ids</code>不是预测出来的id，而是数据集中自带的ground truth的标签，因此如果输入的数据集中没给标签，这里也不会输出</li> <li><code>metrics</code>，也是只有输入的数据集中提供了<code>label_ids</code>才会输出metrics，包括loss之类的指标</li></ul> <p>其中<code>metrics</code>中还可以包含我们自定义的字段，我们需要在定义<code>Trainer</code>的时候给定<code>compute_metrics</code>参数。</p> <p>文档参考： https://huggingface.co/transformers/master/main_classes/trainer.html#transformers.Trainer.predict</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>predictions <span class="token operator">=</span> trainer<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">'validation'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predictions<span class="token punctuation">.</span>predictions<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># logits</span>
<span class="token comment"># array([[-2.7887206,  3.1986978],</span>
<span class="token comment">#       [ 2.5258656, -1.832253 ], ...], dtype=float32)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predictions<span class="token punctuation">.</span>label_ids<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, ...], dtype=int64)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predictions<span class="token punctuation">.</span>metrics<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span><span class="token number">51</span>/51 00:03<span class="token punctuation">]</span>
<span class="token punctuation">(</span><span class="token number">408</span>, <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">408</span>,<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'eval_loss'</span><span class="token builtin class-name">:</span> <span class="token number">0.7387174963951111</span>, <span class="token string">'eval_runtime'</span><span class="token builtin class-name">:</span> <span class="token number">3.2872</span>, <span class="token string">'eval_samples_per_second'</span><span class="token builtin class-name">:</span> <span class="token number">124.117</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>然后就可以用preds和labels来计算一些相关的metrics了。</p> <p>Huggingface <code>datasets</code>里面可以直接导入跟数据集相关的metrics：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric

preds <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predictions<span class="token punctuation">.</span>predictions<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span>
metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>preds<span class="token punctuation">,</span> references<span class="token operator">=</span>predictions<span class="token punctuation">.</span>label_ids<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token punctuation">{</span><span class="token string">'accuracy'</span><span class="token builtin class-name">:</span> <span class="token number">0.8455882352941176</span>, <span class="token string">'f1'</span><span class="token builtin class-name">:</span> <span class="token number">0.8911917098445595</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>看看这里的metric（glue type）的文档：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>Args:
    predictions: list of predictions to score.
        Each translation should be tokenized into a list of tokens.
    references: list of lists of references <span class="token keyword">for</span> each translation.
        Each reference should be tokenized into a list of tokens.
Returns: depending on the GLUE subset, one or several of:
    <span class="token string">&quot;accuracy&quot;</span><span class="token builtin class-name">:</span> Accuracy
    <span class="token string">&quot;f1&quot;</span><span class="token builtin class-name">:</span> F1 score
    <span class="token string">&quot;pearson&quot;</span><span class="token builtin class-name">:</span> Pearson Correlation
    <span class="token string">&quot;spearmanr&quot;</span><span class="token builtin class-name">:</span> Spearman Correlation
    <span class="token string">&quot;matthews_correlation&quot;</span><span class="token builtin class-name">:</span> Matthew Correlation
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h2 id="_4-构建trainer中的compute-metrics函数"><a href="#_4-构建trainer中的compute-metrics函数" class="header-anchor">#</a> 4.构建<code>Trainer</code>中的<code>compute_metrics</code>函数</h2> <p>前面我们注意到<code>Trainer</code>的参数中，可以提供一个<code>compute_metrics</code>函数，用于输出我们希望有的一些指标。</p> <p>这个<code>compute_metrics</code>有一些输入输出的要求：</p> <ul><li>输入：是一个<code>EvalPrediction</code>对象，是一个named tuple，需要有至少<code>predictions</code>和<code>label_ids</code>两个字段；经过查看源码，这里的predictions，<strong>就是logits</strong></li> <li>输出：一个字典，包含各个metrics和对应的数值。</li></ul> <p>源码地址： https://huggingface.co/transformers/master/_modules/transformers/trainer.html#Trainer</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric
<span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>eval_preds<span class="token punctuation">)</span><span class="token punctuation">:</span>
    metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span>
    logits<span class="token punctuation">,</span> labels <span class="token operator">=</span> eval_preds<span class="token punctuation">.</span>predictions<span class="token punctuation">,</span> eval_preds<span class="token punctuation">.</span>label_ids
    <span class="token comment"># 上一行可以直接简写成：</span>
    <span class="token comment"># logits, labels = eval_preds  因为它相当于一个tuple</span>
    predictions <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>labels<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="总结一下这个过程"><a href="#总结一下这个过程" class="header-anchor">#</a> 总结一下这个过程：</h3> <ul><li>首先我们定义了一个<code>compute_metrics</code>函数，交给<code>Trainer</code>；</li> <li><code>Trainer</code>训练模型，模型会对样本计算，产生 predictions (logits)；</li> <li><code>Trainer</code>再把 predictions 和数据集中给定的 label_ids 打包成一个对象，发送给<code>compute_metrics</code>函数；</li> <li><code>compute_metrics</code>函数计算好相应的 metrics 然后返回。</li></ul> <h2 id="看看带上了-compute-metrics-之后的训练"><a href="#看看带上了-compute-metrics-之后的训练" class="header-anchor">#</a> 看看带上了 compute_metrics 之后的训练：</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code>training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>output_dir<span class="token operator">=</span><span class="token string">'test_trainer'</span><span class="token punctuation">,</span> evaluation_strategy<span class="token operator">=</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># new model</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span>
    training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">&quot;validation&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>  <span class="token comment"># 在定义了tokenizer之后，其实这里的data_collator就不用再写了，会自动根据tokenizer创建</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    compute_metrics<span class="token operator">=</span>compute_metrics
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>输出：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20210927151222.png" alt="image-20210927151216236"></p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>TrainOutput<span class="token punctuation">(</span>global_step<span class="token operator">=</span><span class="token number">1377</span>, <span class="token assign-left variable">training_loss</span><span class="token operator">=</span><span class="token number">0.32063739751678666</span>, <span class="token assign-left variable">metrics</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'train_runtime'</span><span class="token builtin class-name">:</span> <span class="token number">414.1719</span>, <span class="token string">'train_samples_per_second'</span><span class="token builtin class-name">:</span> <span class="token number">3.325</span>, <span class="token string">'total_flos'</span><span class="token builtin class-name">:</span> <span class="token number">530351810395680</span>, <span class="token string">'epoch'</span><span class="token builtin class-name">:</span> <span class="token number">3.0</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>可见，带上了<code>compute_metircs</code>函数之后，在Trainer训练过程中，会把增加的metric也打印出来，方便我们时刻了解训练的进展。</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/64.61b2d608.js" defer></script>
  </body>
</html>
