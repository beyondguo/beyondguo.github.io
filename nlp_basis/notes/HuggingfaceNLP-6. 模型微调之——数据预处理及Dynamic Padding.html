<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Huggingface🤗NLP笔记6：数据集预处理，使用dynamic padding构造batch | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/63.14c4cfa2.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link router-link-active">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link router-link-active">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Huggingface🤗NLP笔记6：数据集预处理，使用dynamic padding构造batch</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/nlp_basis/notes/HuggingfaceNLP-6.%20%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B9%8B%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8ADynamic%20Padding.html#试着训练一两条样本" class="sidebar-link">试着训练一两条样本</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-6.%20%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B9%8B%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8ADynamic%20Padding.html#从huggingface-hub中加载数据集" class="sidebar-link">从Huggingface Hub中加载数据集</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-6.%20%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B9%8B%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8ADynamic%20Padding.html#数据集的预处理" class="sidebar-link">数据集的预处理</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/nlp_basis/notes/HuggingfaceNLP-6.%20%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B9%8B%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8ADynamic%20Padding.html#dataset-map方法有啥好处" class="sidebar-link">Dataset.map方法有啥好处：</a></li></ul></li><li><a href="/nlp_basis/notes/HuggingfaceNLP-6.%20%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B9%8B%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8ADynamic%20Padding.html#dynamic-padding-动态padding" class="sidebar-link">Dynamic Padding 动态padding</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><blockquote><p><strong>「Huggingface🤗NLP笔记系列-第6集」</strong>
最近跟着Huggingface上的NLP tutorial走了一遍，惊叹居然有如此好的讲解Transformers系列的NLP教程，于是决定记录一下学习的过程，分享我的笔记，可以算是官方教程的<strong>精简+注解版</strong>。但最推荐的，还是直接跟着官方教程来一遍，真是一种享受。</p></blockquote> <ul><li>官方教程网址：https://huggingface.co/course/chapter1</li> <li>本期内容对应网址：https://huggingface.co/course/chapter3/2?fw=pt</li> <li>本系列笔记的<strong>GitHub</strong>： https://github.com/beyondguo/Learn_PyTorch/tree/master/HuggingfaceNLP</li></ul> <hr> <h1 id="数据集的预处理-使用dynamic-padding构造batch"><a href="#数据集的预处理-使用dynamic-padding构造batch" class="header-anchor">#</a> 数据集的预处理，使用dynamic padding构造batch</h1> <p>从这一集，我们就正式开始使用Transformer来训练模型了。今天的部分是关于数据集预处理。</p> <h2 id="试着训练一两条样本"><a href="#试着训练一两条样本" class="header-anchor">#</a> 试着训练一两条样本</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 先看看cuda是否可用</span>
<span class="token keyword">import</span> torch
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> True
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>首先，我们加载模型。既然模型要在具体任务上微调了，我们就要加载带有Head的模型，这里做的分类问题，因此加载<code>ForSequenceClassification</code>这个Head：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification

<span class="token comment"># Same as before</span>
checkpoint <span class="token operator">=</span> <span class="token string">&quot;bert-base-uncased&quot;</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>下面是模型输出的warning：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> 
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: <span class="token punctuation">[</span><span class="token string">'cls.predictions.bias'</span>, <span class="token string">'cls.predictions.transform.dense.weight'</span>, <span class="token string">'cls.predictions.transform.dense.bias'</span>, <span class="token string">'cls.predictions.decoder.weight'</span>, <span class="token string">'cls.seq_relationship.weight'</span>, <span class="token string">'cls.seq_relationship.bias'</span>, <span class="token string">'cls.predictions.transform.LayerNorm.weight'</span>, <span class="token string">'cls.predictions.transform.LayerNorm.bias'</span><span class="token punctuation">]</span>
- This IS expected <span class="token keyword">if</span> you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture <span class="token punctuation">(</span>e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model<span class="token punctuation">)</span>.
- This IS NOT expected <span class="token keyword">if</span> you are initializing BertForSequenceClassification from the checkpoint of a model that you <span class="token function">expect</span> to be exactly identical <span class="token punctuation">(</span>initializing a BertForSequenceClassification model from a BertForSequenceClassification model<span class="token punctuation">)</span>.
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: <span class="token punctuation">[</span><span class="token string">'classifier.weight'</span>, <span class="token string">'classifier.bias'</span><span class="token punctuation">]</span>
You should probably TRAIN this model on a down-stream task to be able to use it <span class="token keyword">for</span> predictions and inference.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>看到这么一大串的warning出现，不要怕，这个warning正是我们希望看到的。</p> <p>为啥会出现这个warning呢，因为我们加载的预训练权重是<code>bert-based-uncased</code>，而使用的骨架是<code>AutoModelForSequenceClassification</code>，前者是没有在下游任务上微调过的，所以用带有下游任务Head的骨架去加载，会随机初始化这个Head。这些在warning中也说的很明白。</p> <p>接下来，我们试试直接构造一个size=2的batch，丢进模型去。</p> <p>当输入的batch是带有&quot;labels&quot;属性的时候，模型会自动计算loss，拿着这个loss，我们就可以进行反向传播并更新参数了：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>sequences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">&quot;I've been waiting for a HuggingFace course my whole life.&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;This course is amazing!&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
batch <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>
batch<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># tokenizer出来的结果是一个dictionary，所以可以直接加入新的 key-value</span>

optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span><span class="token punctuation">.</span>loss  <span class="token comment">#这里的 loss 是直接根据 batch 中提供的 labels 来计算的，回忆：前面章节查看 model 的输出的时候，有loss这一项</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h2 id="从huggingface-hub中加载数据集"><a href="#从huggingface-hub中加载数据集" class="header-anchor">#</a> 从Huggingface Hub中加载数据集</h2> <p>这里，我们使用MRPC数据集，它的全称是Microsoft Research Paraphrase Corpus，包含了5801个句子对，标签是两个句子是否是同一个意思。</p> <p>Huggingface有一个<code>datasets</code>库，可以让我们轻松地下载常见的数据集：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

raw_datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;glue&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;mrpc&quot;</span><span class="token punctuation">)</span>
raw_datasets
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>看看加载的dataset的样子：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>DatasetDict<span class="token punctuation">(</span><span class="token punctuation">{</span>
    train: Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
        features: <span class="token punctuation">[</span><span class="token string">'sentence1'</span>, <span class="token string">'sentence2'</span>, <span class="token string">'label'</span>, <span class="token string">'idx'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">3668</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    validation: Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
        features: <span class="token punctuation">[</span><span class="token string">'sentence1'</span>, <span class="token string">'sentence2'</span>, <span class="token string">'label'</span>, <span class="token string">'idx'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">408</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    test: Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
        features: <span class="token punctuation">[</span><span class="token string">'sentence1'</span>, <span class="token string">'sentence2'</span>, <span class="token string">'label'</span>, <span class="token string">'idx'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">1725</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>load_dataset出来的是一个DatasetDict对象，它包含了train，validation，test三个属性。可以通过key来直接查询，得到对应的train、valid和test数据集。</p> <p>这里的train，valid，test都是Dataset类型，有 features和num_rows两个属性。还可以直接通过下标来查询对应的样本。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>raw_train_dataset <span class="token operator">=</span> raw_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span>
raw_train_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>看看数据长啥样：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token builtin class-name">:</span> <span class="token string">'Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .'</span>,
 <span class="token string">'sentence2'</span><span class="token builtin class-name">:</span> <span class="token string">'Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .'</span>,
 <span class="token string">'label'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>,
 <span class="token string">'idx'</span><span class="token builtin class-name">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>可见，每一条数据，就是一个dictionary。</p> <p>Dataset的features可以理解为一张表的columns，Dataset甚至可以看做一个pandas的dataframe，二者的使用很类似。</p> <p>我们可以直接像操作dataframe一样，取出某一列：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token builtin">type</span><span class="token punctuation">(</span>raw_train_dataset<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 直接取出所有的sentence1，形成一个list</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> list
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>通过Dataset的features属性，可以详细查看数据集特征，包括labels具体都是啥：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>raw_train_dataset<span class="token punctuation">.</span>features
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token builtin class-name">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span>, <span class="token assign-left variable">id</span><span class="token operator">=</span>None<span class="token punctuation">)</span>,
 <span class="token string">'sentence2'</span><span class="token builtin class-name">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span>, <span class="token assign-left variable">id</span><span class="token operator">=</span>None<span class="token punctuation">)</span>,
 <span class="token string">'label'</span><span class="token builtin class-name">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span>, <span class="token assign-left variable">names</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'not_equivalent'</span>, <span class="token string">'equivalent'</span><span class="token punctuation">]</span>, <span class="token assign-left variable">names_file</span><span class="token operator">=</span>None, <span class="token assign-left variable">id</span><span class="token operator">=</span>None<span class="token punctuation">)</span>,
 <span class="token string">'idx'</span><span class="token builtin class-name">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'int32'</span>, <span class="token assign-left variable">id</span><span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="数据集的预处理"><a href="#数据集的预处理" class="header-anchor">#</a> 数据集的预处理</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>我们可以直接下面这样处理：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tokenized_sentences_1 <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>raw_train_dataset<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tokenized_sentences_2 <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>raw_train_dataset<span class="token punctuation">[</span><span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>但对于MRPC任务，我们不能把两个句子分开输入到模型中，二者应该组成一个pair输进去。</p> <p>tokenizer也可以直接处理sequence pair：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> pprint <span class="token keyword">import</span> pprint <span class="token keyword">as</span> <span class="token keyword">print</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">&quot;first sentence&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;second one&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token punctuation">{</span><span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span>,
 <span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">101</span>, <span class="token number">2034</span>, <span class="token number">6251</span>, <span class="token number">102</span>, <span class="token number">2117</span>, <span class="token number">2028</span>, <span class="token number">102</span><span class="token punctuation">]</span>,
 <span class="token string">'token_type_ids'</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>我们把这里的input_ids给decode看一下：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token string">'[CLS] first sentence [SEP] second one [SEP]'</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>可以看到这里inputs里，还有一个<code>token_type_ids</code>属性，它在这里的作用就很明显了，指示哪些词是属于第一个句子，哪些词是属于第二个句子。tokenizer处理后得到的ids，解码之后，在开头结尾多了<code>[CLS]</code>和<code>[SEP]</code>，两个句子中间也添加了一个<code>[SEP]</code>。另外注意，虽然输入的是一个句子对，但是编码之后是一个整体，通过<code>[SEP]</code>符号相连。</p> <p><strong>这种神奇的做法，其实是源于bert-base预训练的任务</strong>，即<strong>next sentence prediction</strong>。换成其他模型，比如DistilBert，它在预训练的时候没有这个任务，那它的tokenizer的结果就不会有这个<code>token_type_ids</code>属性了。</p> <p>既然这里的tokenizer可以直接处理pair，我们就可以这么去分词：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tokenized_dataset <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
    raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    raw_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>但是这样不一定好，因为先是直接把要处理的整个数据集都读进了内存，又返回一个新的dictionary，会占据很多内存。</p> <p>官方推荐的做法是通过<code>Dataset.map</code>方法，来调用一个分词方法，实现批量化的分词：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 这里可以添加多种操作，不光是tokenize</span>
    <span class="token comment"># 这个函数处理的对象，就是Dataset这种数据类型，通过features中的字段来选择要处理的数据</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>sample<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sample<span class="token punctuation">[</span><span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> raw_datasets<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
tokenized_datasets
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>处理后的dataset的信息：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>DatasetDict<span class="token punctuation">(</span><span class="token punctuation">{</span>
    train: Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
        features: <span class="token punctuation">[</span><span class="token string">'attention_mask'</span>, <span class="token string">'idx'</span>, <span class="token string">'input_ids'</span>, <span class="token string">'label'</span>, <span class="token string">'sentence1'</span>, <span class="token string">'sentence2'</span>, <span class="token string">'token_type_ids'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">3668</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    validation: Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
        features: <span class="token punctuation">[</span><span class="token string">'attention_mask'</span>, <span class="token string">'idx'</span>, <span class="token string">'input_ids'</span>, <span class="token string">'label'</span>, <span class="token string">'sentence1'</span>, <span class="token string">'sentence2'</span>, <span class="token string">'token_type_ids'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">408</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    test: Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
        features: <span class="token punctuation">[</span><span class="token string">'attention_mask'</span>, <span class="token string">'idx'</span>, <span class="token string">'input_ids'</span>, <span class="token string">'label'</span>, <span class="token string">'sentence1'</span>, <span class="token string">'sentence2'</span>, <span class="token string">'token_type_ids'</span><span class="token punctuation">]</span>,
        num_rows: <span class="token number">1725</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>看看这个map的一些参数：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>raw_datasets.map<span class="token punctuation">(</span>
    function,
    with_indices: bool <span class="token operator">=</span> False,
    input_columns: Union<span class="token punctuation">[</span>str, List<span class="token punctuation">[</span>str<span class="token punctuation">]</span>, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,
    batched: bool <span class="token operator">=</span> False,
    batch_size: Union<span class="token punctuation">[</span>int, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1000</span>,
    remove_columns: Union<span class="token punctuation">[</span>str, List<span class="token punctuation">[</span>str<span class="token punctuation">]</span>, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,
    keep_in_memory: bool <span class="token operator">=</span> False,
    load_from_cache_file: bool <span class="token operator">=</span> True,
    cache_file_names: Union<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span>str, Union<span class="token punctuation">[</span>str, NoneType<span class="token punctuation">]</span><span class="token punctuation">]</span>, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,
    writer_batch_size: Union<span class="token punctuation">[</span>int, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1000</span>,
    features: Union<span class="token punctuation">[</span>datasets.features.Features, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,
    disable_nullable: bool <span class="token operator">=</span> False,
    fn_kwargs: Union<span class="token punctuation">[</span>dict, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,
    num_proc: Union<span class="token punctuation">[</span>int, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,  <span class="token comment"># 使用此参数，可以使用多进程处理</span>
    desc: Union<span class="token punctuation">[</span>str, NoneType<span class="token punctuation">]</span> <span class="token operator">=</span> None,
<span class="token punctuation">)</span> -<span class="token operator">&gt;</span> <span class="token string">'DatasetDict'</span>
Docstring:
Apply a <span class="token keyword">function</span> to all the elements <span class="token keyword">in</span> the table <span class="token punctuation">(</span>individually or <span class="token keyword">in</span> batches<span class="token punctuation">)</span>
and update the table <span class="token punctuation">(</span>if <span class="token keyword">function</span> does updated examples<span class="token punctuation">)</span>.
The transformation is applied to all the datasets of the dataset dictionary.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p>关于这个map，在Huggingface的测试题中有讲解，这里搬运并翻译一下，辅助理解：</p> <h3 id="dataset-map方法有啥好处"><a href="#dataset-map方法有啥好处" class="header-anchor">#</a> Dataset.map方法有啥好处：</h3> <ul><li><p>The results of the function are cached, so it won't take any time if we re-execute the code.</p> <p>（通过这个map，对数据集的处理会被缓存，所以重新执行代码，也不会再费时间。）</p></li> <li><p>It can apply multiprocessing to go faster than applying the function on each element of the dataset.</p> <p>（它可以使用多进程来处理从而提高处理速度。）</p></li> <li><p>It does not load the whole dataset into memory, saving the results as soon as one element is processed.</p> <p>（它不需要把整个数据集都加载到内存里，同时每个元素一经处理就会马上被保存，因此十分节省内存。）</p></li></ul> <p>观察一下，这里通过map之后，得到的Dataset的features变多了：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>多的几个columns就是tokenizer处理后的结果。</p> <p>注意到，<strong>在这个<code>tokenize_function</code>中，我们没有使用<code>padding</code></strong>，因为如果使用了padding之后，就会全局统一对一个maxlen进行padding，这样无论在tokenize还是模型的训练上都不够高效。</p> <h2 id="dynamic-padding-动态padding"><a href="#dynamic-padding-动态padding" class="header-anchor">#</a> Dynamic Padding 动态padding</h2> <p>实际上，我们是故意先不进行padding的，因为我们想<strong>在划分batch的时候再进行padding</strong>，这样可以避免出现很多有一堆padding的序列，从而可以显著节省我们的训练时间。</p> <p>这里，我们就需要用到**<code>DataCollatorWithPadding</code><strong>，来进行</strong>动态padding**：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorWithPadding
data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>注意，我们需要使用tokenizer来初始化这个<code>DataCollatorWithPadding</code>，因为需要tokenizer来告知具体的padding token是啥，以及padding的方式是在左边还是右边（不同的预训练模型，使用的padding token以及方式可能不同）。</p> <p>下面假设我们要搞一个size=5的batch，看看如何使用<code>DataCollatorWithPadding</code>来实现：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>samples <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>
samples<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># &gt;&gt;&gt; ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids']</span>
samples <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> samples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">&quot;idx&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sentence1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sentence2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">}</span>  <span class="token comment"># 把这里多余的几列去掉</span>
samples<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># &gt;&gt;&gt; ['attention_mask', 'input_ids', 'label', 'token_type_ids']</span>

<span class="token comment"># 打印出每个句子的长度：</span>
<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> samples<span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token punctuation">[</span><span class="token number">50</span>, <span class="token number">59</span>, <span class="token number">47</span>, <span class="token number">67</span>, <span class="token number">59</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>然后我们使用data_collator来处理：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>batch <span class="token operator">=</span> data_collator<span class="token punctuation">(</span>samples<span class="token punctuation">)</span>  <span class="token comment"># samples中必须包含 input_ids 字段，因为这就是collator要处理的对象</span>
batch<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># &gt;&gt;&gt; dict_keys(['attention_mask', 'input_ids', 'token_type_ids', 'labels'])</span>

<span class="token comment"># 再打印长度：</span>
<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> batch<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token punctuation">[</span><span class="token number">67</span>, <span class="token number">67</span>, <span class="token number">67</span>, <span class="token number">67</span>, <span class="token number">67</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>可以看到，这个<code>data_collator</code>就是一个把给定dataset进行padding的工具，其输入跟输出是完全一样的格式。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token punctuation">{</span>k<span class="token punctuation">:</span>v<span class="token punctuation">.</span>shape <span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token punctuation">{</span><span class="token string">'attention_mask'</span><span class="token builtin class-name">:</span> torch.Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span>, <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">)</span>,
 <span class="token string">'input_ids'</span><span class="token builtin class-name">:</span> torch.Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span>, <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">)</span>,
 <span class="token string">'token_type_ids'</span><span class="token builtin class-name">:</span> torch.Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span>, <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">)</span>,
 <span class="token string">'labels'</span><span class="token builtin class-name">:</span> torch.Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>这个batch，可以形成一个tensor了！接下来就可以用于训练了！</p> <hr> <p>对了，这里多提一句，<code>collator</code>这个单词实际上在平时使用英语的时候并不常见，但却在编程中见到多次。</p> <p>最开始一直以为是<code>collector</code>，意为“收集者”等意思，后来查了查，发现不是的。下面是柯林斯词典中对<code>collate</code>这个词的解释：</p> <blockquote><p><strong>collate</strong>:</p> <p>When you collate pieces of information, you <strong>gather</strong> them all together and <strong>examine</strong> them.</p></blockquote> <p>就是归纳并整理的意思。所以在我们这个情景下，就是对这些杂乱无章长短不一的序列数据，进行一个个地分组，然后检查并统一长度。</p> <p>关于DataCollator更多的信息，可以参见文档：
https://huggingface.co/transformers/master/main_classes/data_collator.html?highlight=datacollatorwithpadding#data-collator</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/63.14c4cfa2.js" defer></script>
  </body>
</html>
