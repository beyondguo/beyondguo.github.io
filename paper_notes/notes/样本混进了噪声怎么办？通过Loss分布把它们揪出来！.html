<!DOCTYPE html>
<html lang="ch">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>样本混进了噪声怎么办？通过Loss分布把它们揪出来！(ICML-19) | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/102.969e84bd.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>样本混进了噪声怎么办？通过Loss分布把它们揪出来！(ICML-19)</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#一、本文的主要思想、贡献" class="sidebar-link">一、本文的主要思想、贡献</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#二、关于training-with-noise的一些研究背景" class="sidebar-link">二、关于Training with noise的一些研究背景</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#_1-bootstrapping-loss-☆" class="sidebar-link">1. Bootstrapping loss（☆）</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#_2-curriculum-learning" class="sidebar-link">2. Curriculum learning</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#_3-mixed-data-augmentation" class="sidebar-link">3. Mixed data augmentation</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#_4-其他" class="sidebar-link">4.其他：</a></li></ul></li><li><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#三、本文提出的方法" class="sidebar-link">三、本文提出的方法：</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#第一步-label-noise-modeling" class="sidebar-link">第一步：Label noise modeling</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%A0%B7%E6%9C%AC%E6%B7%B7%E8%BF%9B%E4%BA%86%E5%99%AA%E5%A3%B0%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%80%9A%E8%BF%87Loss%E5%88%86%E5%B8%83%E6%8A%8A%E5%AE%83%E4%BB%AC%E6%8F%AA%E5%87%BA%E6%9D%A5%EF%BC%81.html#第二步-noise-model-for-label-correction" class="sidebar-link">第二步：Noise model for label correction</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="样本混进了噪声怎么办-通过loss分布把它们揪出来"><a href="#样本混进了噪声怎么办-通过loss分布把它们揪出来" class="header-anchor">#</a> 样本混进了噪声怎么办？通过Loss分布把它们揪出来！</h1> <center>作者：郭必扬</center> <center>时间：2020.12.30</center> <blockquote><p>前言：今天继续分享一篇很有意思的文章，来自2019年ICML的“Unsupervised Label Noise Modeling and Loss Correction”，本文发现了一个“大家都知道但又不太确定”的现象——noisy样本的loss一般比较大，通过实验证实了这一点，并利用这个特点来定位noise从而排除这些noise的影响，来提高模型的性能。可以说是挺有趣了！</p></blockquote> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-24/1624541013735-image.png" alt=""></p> <ul><li>论文标题：Unsupervised Label Noise Modeling and Loss Correction</li> <li>会议/期刊：ICML-19</li> <li>团队：Dublin City University (DCU)</li></ul> <h2 id="一、本文的主要思想、贡献"><a href="#一、本文的主要思想、贡献" class="header-anchor">#</a> 一、本文的主要思想、贡献</h2> <ul><li>首先发现并证实了，神经网络在学习“随机的标签”或“错误的标签”（都可以称为噪音样本）的时候，会比学习“正确的标签”要慢，由此发现噪音样本在训练时的loss更大；</li> <li>通过对样本的loss distribution进行观察，作者发现可以使用一个Beta分布来刻画正常样本和噪音样本，从而将二者区分；</li> <li>由此，作者设计了一种复合的模型，在训练的期间，可以通过一种无监督的方式来实时辨别噪声并去除，从而提高模型效果。</li></ul> <p>下面稍微详细地介绍一下：</p> <h2 id="二、关于training-with-noise的一些研究背景"><a href="#二、关于training-with-noise的一些研究背景" class="header-anchor">#</a> 二、关于Training with noise的一些研究背景</h2> <p>当训练样本中混有噪音，就很容易让模型过拟合，学习到错误的信息，因此必须加以干涉，来控制噪音带来的影响。这方面的研究，主要集中于“损失修正”方法，即loss correction。典型的方法有这些：</p> <h3 id="_1-bootstrapping-loss-☆"><a href="#_1-bootstrapping-loss-☆" class="header-anchor">#</a> 1. Bootstrapping loss（☆）</h3> <p>这是我非常喜欢的一个loss function，十分的简洁，又有道理，让人一见钟情。公式如下：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mi>B</mi></msub><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mrow><mo fence="true">(</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>w</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><msub><mi>w</mi><mi>i</mi></msub><msub><mi>z</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>T</mi></msup><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\ell_{B}=-\sum_{i=1}^{N}\left(\left(1-w_{i}\right) y_{i}+w_{i} z_{i}\right)^{T} \log \left(h_{i}\right)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p> <p>上面的公式，实际上是指&quot;hard bootstrapping loss&quot;。这里的yi就是真实的标签（一般是one-hot形式的），zi则是预测的标签（也是转化成one-hot形式的，因此叫hard），然后hi就是预测的概率分布。</p> <p>这个loss实际上就是对cross-entropy loss的一个修正，把真实标签改了改，分了一部分到预测出来的那个维度上。</p> <p>这样做的效果是什么？首先我们得有一个概念：</p> <blockquote><p>如果一个样本的损失很小，模型就不会在这个样本上面花太多功夫去拟合它；相反，损失很大，模型就会花大力气去拟合它。</p></blockquote> <p>那么，对一个噪音点，其相比于正常点，计算出来的loss一般都会更大一些（label跟实际的相差较远），因此模型会花大力气去拟合这些噪音点，因此传统的cross-entropy loss是鼓励模型学习到错误信息的。而bootstrapping loss，把模型自己的预测，加入到真实标签中，这样就会直接降低这些噪音点的loss（极端一点，如果真实标签就是模型的预测，那loss就趋于0），因此模型会降低对噪音点的注意力；对于正常的样本，zi带来的影响相对会较小（zi更容易跟yi一致），因此正常样本还是可以得到有效的训练。</p> <p>是不是真·有、意思？</p> <p>这个B-loss来自2015ICLR，目前引用量高达467次了。。。好东西大家都喜欢啊。</p> <h3 id="_2-curriculum-learning"><a href="#_2-curriculum-learning" class="header-anchor">#</a> 2. Curriculum learning</h3> <p>Curriculum learning这名字一听就很有意思，“课程学习”往往是由浅入深、先易后难的，这个curriculum learning也是这个思想，最早由Bengio在09年的时候提出，思想就是：</p> <blockquote><p>“把训练样本按照一个有意义的顺序（比如先易后难）排列，有助于加快模型的迭代和泛化性能。”</p></blockquote> <p>因此有学者使用这样的思想，把clean样本视为简单的，noisy样本视为困难的，来让模型学习。具体的方法还是通过改变clean和noisy样本的loss权重来实现这个目的。</p> <h3 id="_3-mixed-data-augmentation"><a href="#_3-mixed-data-augmentation" class="header-anchor">#</a> 3. Mixed data augmentation</h3> <p>这个方法也比较有新意，通过一种数据增强的方法，来减少noise带来的影响：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.1600em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>=</mo><mi>δ</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>δ</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mi>q</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">ℓ</mi><mo>=</mo><mi>δ</mi><msub><mi mathvariant="normal">ℓ</mi><mi>p</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>δ</mi><mo stretchy="false">)</mo><msub><mi mathvariant="normal">ℓ</mi><mi>q</mi></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{l}
x=\delta x_{p}+(1-\delta) x_{q} \\
\ell=\delta \ell_{p}+(1-\delta) \ell_{q}
\end{array}
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:2.4000000000000004em;vertical-align:-0.9500000000000004em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">ℓ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mclose">)</span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p> <p>具体则是将clean和noisy的样本和标签进行结合，得到新样本和新标签。</p> <p>简单的理解为将两个不同的样本做了一个平均，平均肯定更加稳定嘛！</p> <h3 id="_4-其他"><a href="#_4-其他" class="header-anchor">#</a> 4.其他：</h3> <p>其他的我就没细看了，比如使用一个noise transition matrix来调整loss或者预测概率等等。</p> <h2 id="三、本文提出的方法"><a href="#三、本文提出的方法" class="header-anchor">#</a> 三、本文提出的方法：</h2> <p>本文提出的方法思路也十分清晰：</p> <ul><li>第一步：通过cross-entropy得到的loss分布来判断样本是noisy还是clean的概率</li> <li>第二步：使用这个概率来动态地调整loss function，使用该loss来训练</li></ul> <h3 id="第一步-label-noise-modeling"><a href="#第一步-label-noise-modeling" class="header-anchor">#</a> 第一步：Label noise modeling</h3> <p>作者通过实验发现noise和clean在loss上的分布是十分不同的，下图是作者的一个实验结果图：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-24/1624541026515-image.png" alt=""></p> <p>图中展示的是训练了10轮之后的各个样本的cross-entropy loss，可以看出clean和noisy（注意这里是作者为了展示二者的不同而特意标的，实际训练时我们不知道谁是clean谁是noisy）的loss分布呈现出一个双峰分布，这样的分布可以使用混合概率模型来模拟，比如高斯混合模型（GMM），但实际上作者发现用贝塔混合模型（BMM）模拟更好（因为形状更像）。</p> <p>通过EM算法，可以迭代求解出这个BMM分布的参数，从而根据loss的值计算出属于clean还是noisy的概率。</p> <h3 id="第二步-noise-model-for-label-correction"><a href="#第二步-noise-model-for-label-correction" class="header-anchor">#</a> 第二步：Noise model for label correction</h3> <p>能够判别一个样本是clean还是noisy，就可以去改进前面提到一些方法了，比如Boostrapping loss方法。</p> <p>前面提到B-loss的主要思想，就是针对对noise样本来对loss进行修正。但是B-loss中的工事中的权重wi是一个超参数，也就是在训练的时候是固定的，这使得clean样本总是会受到一些不好的影响（wi越大，影响越大），而noisy样本往往又调整的不够（wi越小，效果越少），因此这个就十分不灵活了。</p> <p>现在，我们知道了一个样本是clean还是noisy的概率，那么就有机会动态地调整wi了，即，吧原来的B-loss，改成：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mi>D</mi></msub><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mrow><mo fence="true">(</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>p</mi><mrow><mi>n</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>y</mi></mrow></msub><mo fence="true">)</mo></mrow><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><msub><mi>p</mi><mrow><mi>n</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>y</mi></mrow></msub><msub><mi>z</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>T</mi></msup><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\ell_{D}=-\sum_{i=1}^{N}\left(\left(1-p_{noisy}\right) y_{i}+p_{noisy} z_{i}\right)^{T} \log \left(h_{i}\right)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">sy</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">sy</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p> <p>是不是很简洁？总的来说，本文提出的训练方式就是</p> <blockquote><p>还是在原来的使用CE-loss的训练模式下，每个epoch训练完之后，去使用EM算法把当前这个混合贝塔分布BMM给模拟出来，然后计算新的loss——D-loss，使用这个D-loss来更新参数。注意每一轮都是使用CE-loss来学习BMM，然后使用D-loss更新。</p></blockquote> <p>其实论文中还提到了一个更加复杂的方法，就是对前面提到的mixup data augmentation的改进，但我感觉普适性不够强，所以这里不再介绍了。</p> <p>通过作者改造后的loss function，我们可以跟原来的CE-loss做一个对比：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-24/1624541038260-image.png" alt=""></p> <p>发现，确实可以吧clean和noisy进行很好的区分。</p> <p>实验的部分，没什么特别的，这里也不多嘴了。</p> <hr> <p>好了，本篇论文解读就到这里了，最让人影响深刻的，应该就是这个Boostrapping Loss和使用BMM来模拟clean/noisy的loss分布的想法了。</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/102.969e84bd.js" defer></script>
  </body>
</html>
