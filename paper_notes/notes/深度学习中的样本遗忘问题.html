<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度学习中的样本遗忘问题 (ICLR-2019) | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/103.a356b143.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>深度学习中的样本遗忘问题 (ICLR-2019)</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#一、跟-灾难性遗忘-的关系" class="sidebar-link">一、跟“灾难性遗忘”的关系</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#二、概念定义" class="sidebar-link">二、概念定义</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_1-forgetting-learning-events" class="sidebar-link">1. Forgetting &amp; Learning events</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_2-classification-margin" class="sidebar-link">2. Classification margin</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_3-forgettable-unforgettable-examples" class="sidebar-link">3. Forgettable &amp; Unforgettable examples</a></li></ul></li><li><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#三、实验设置-统计流程" class="sidebar-link">三、实验设置&amp;统计流程：</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#四、☆实验观察" class="sidebar-link">四、☆实验观察</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_1-遗忘次数的统计" class="sidebar-link">1. 遗忘次数的统计</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_2-何时被第一次学到" class="sidebar-link">2. 何时被第一次学到</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_3-遗忘次数跟misclassification-margin的关系" class="sidebar-link">3. 遗忘次数跟misclassification margin的关系</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_4-发现噪音样本" class="sidebar-link">4. 发现噪音样本</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_5-微观视角的灾难性遗忘" class="sidebar-link">5. 微观视角的灾难性遗忘</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_6-我们可以丢掉很多样本-还能保持泛化性能" class="sidebar-link">6. 我们可以丢掉很多样本，还能保持泛化性能</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#_7-样本遗忘现象的稳定性" class="sidebar-link">7. 样本遗忘现象的稳定性</a></li></ul></li><li><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#五、总结-思考" class="sidebar-link">五、总结&amp; 思考</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#写作上" class="sidebar-link">写作上：</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98.html#样本遗忘带来的启发" class="sidebar-link">样本遗忘带来的启发</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="深度学习中的样本遗忘问题-iclr-2019"><a href="#深度学习中的样本遗忘问题-iclr-2019" class="header-anchor">#</a> 深度学习中的样本遗忘问题 (ICLR-2019)</h1> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126095342509.png" alt="image-20220126095342509"></p> <ul><li>标题：An Empirical Study of Example Forgetting during Deep Neural Network Learning</li> <li>会议：ICLR-2019</li> <li>机构：CMU，MSR，MILA</li></ul> <blockquote><p>一句话总结：</p> <p>学了忘，忘了学。你我如此，神经网络也如此。在深度模型训练过程中，可能发生了大量的、反复的样本遗忘现象。</p></blockquote> <p>本论文的写法很特别，更大家常读的八股文不同，本文更像一个“实验报告”，标题也说了是一个Empirical Study，我觉得是一个很好的写Empirical Study的范本，值得收藏。</p> <h2 id="一、跟-灾难性遗忘-的关系"><a href="#一、跟-灾难性遗忘-的关系" class="header-anchor">#</a> 一、跟“灾难性遗忘”的关系</h2> <p><strong>灾难性遗忘</strong>（catastrophic forgetting），是一个在深度学习中常被提起的概念，也是lifelong learning, continual learning中研究的主要问题之一。</p> <p>灾难性遗忘，描述的是<strong>在一个任务上训练出来的模型，如果在一个新任务上进行训练，就会大大降低原任务上的泛化性能，即之前的知识被严重遗忘了。</strong> 在论文<em>Attention-Based Selective Plasticity</em>中的一幅图很形象地描述了这个概念：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126102259330.png" alt="灾难性遗忘，来源：论文Attention-Based Selective Plasticity"></p> <p>而本文提出的样本遗忘（example forgetting），则是受到灾难性遗忘现象的启发而提出的，即<strong>在同一个任务的训练过程中，也可能会有遗忘现象，一个样本可能在训练过程中反复地学了忘，忘了学。</strong></p> <p>实际上，如果我们把<strong>任务</strong>的概念放宽，那么我每一个mini-batch都可以看做一个小task，所以这里的example forgetting，就是更微观视角的catastrophic forgetting.</p> <h2 id="二、概念定义"><a href="#二、概念定义" class="header-anchor">#</a> 二、概念定义</h2> <h3 id="_1-forgetting-learning-events"><a href="#_1-forgetting-learning-events" class="header-anchor">#</a> 1. Forgetting &amp; Learning events</h3> <p>当一个样本本来预测对的，现在预测错了，就是一次forgetting event；相反的就是learning event.</p> <p>我们会初始化一开始每个样本的预测都是不对的，但是在经过训练后（比如一个batch之后）进行上述的检查。</p> <h3 id="_2-classification-margin"><a href="#_2-classification-margin" class="header-anchor">#</a> 2. Classification margin</h3> <p>分类边际，被定义为：正确的类别对应的logit，跟其他类别中最大的logit的差。</p> <h3 id="_3-forgettable-unforgettable-examples"><a href="#_3-forgettable-unforgettable-examples" class="header-anchor">#</a> 3. Forgettable &amp; Unforgettable examples</h3> <ul><li>被遗忘至少一次的，就叫forgettable example</li> <li>在某时刻被学习到了，然后从此就没有被遗忘过的样本，就叫unforgettable example</li> <li>从未被学习到的（即自始至终都预测是错的），不能算作unforgettable（但是，自始至终预测都是对的，就算）</li></ul> <h2 id="三、实验设置-统计流程"><a href="#三、实验设置-统计流程" class="header-anchor">#</a> 三、实验设置&amp;统计流程：</h2> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126104625864.png" alt="统计算法"></p> <p>上述统计算法更加清晰地告诉我们本文是如何进行对forgetting events进行统计的，即我们是在每个batch训练完之后统计一次。</p> <p>本文使用了三个数据集：MNIST， permuted-MNIST（MNIST的像素重排版）和CIFAR-10，这三个数据集的学习难度是递增的。</p> <h2 id="四、☆实验观察"><a href="#四、☆实验观察" class="header-anchor">#</a> 四、☆实验观察</h2> <p>这一部分就是本论文的主要部分了，没有太多的理论，主要就是通过一系列的实验来向我们展示训练过程中发生了什么，但真的都挺有意思的，能给人带来很多启发和思考。</p> <h3 id="_1-遗忘次数的统计"><a href="#_1-遗忘次数的统计" class="header-anchor">#</a> 1. 遗忘次数的统计</h3> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126113512825.png" alt="number of forgetting events"></p> <p>从上图可以看出，随着数据集的复杂度和多样性（complexity &amp; diversity）的增加，样本遗忘的情况越来越多。简单的数据集，有大量的unforgettable examples. 作者统计如下：</p> <table><thead><tr><th>dataset</th> <th># unforgettable examples</th></tr></thead> <tbody><tr><td>MNIST</td> <td>91.7%</td></tr> <tr><td>permuted-MNIST</td> <td>75.3%</td></tr> <tr><td>CIFAR-10</td> <td>31.3%</td></tr></tbody></table> <p>另外，有些样本遗忘，可能是随机发生的，就是模型自己随便更新都可能造成遗忘，所以作者们专门做了一个统计，让模型用随机的梯度来更新，看看遗忘的情况：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126114611696.png" alt="forgetting by chance"></p> <p>可见随机遗忘的分布，跟真实遗忘的分布还是有很大差别的，而且随机遗忘的次数会很少，一般在2次以内。</p> <h3 id="_2-何时被第一次学到"><a href="#_2-何时被第一次学到" class="header-anchor">#</a> 2. 何时被第一次学到</h3> <p>一个样本究竟出现几次才会被模型学到？这是一个很有意思的问题，作者分别对unforgettable和forgettable的样本进行了统计：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126115128398.png" alt="first learning event"></p> <p>从上图可以发现，大部分的样本，在出现5次以内就可以被学习到。相比而言，unforgettable样本更早被学到。</p> <h3 id="_3-遗忘次数跟misclassification-margin的关系"><a href="#_3-遗忘次数跟misclassification-margin的关系" class="header-anchor">#</a> 3. 遗忘次数跟misclassification margin的关系</h3> <p>前面定义了classification margin，而misclassification margin这里定义为一个样本在所有forgetting events中的平均classification margin，所以这个的绝对值越大，就代表分类的模糊程度越大。</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126120046417.png" alt="misclassification margin"></p> <p>上图是一个2D的直方图，代表了所有样本是如何分布的。总体上看，forgetting次数多的样本，其misclassification margin也很大。</p> <h3 id="_4-发现噪音样本"><a href="#_4-发现噪音样本" class="header-anchor">#</a> 4. 发现噪音样本</h3> <p>我们很自然可以想到，能否利用遗忘次数，来判断一个样本是否是噪音（标签错误）呢？作者从数据集中随机挑选了20%的样本改变其标签，然后做了如下统计：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126121031751.png" alt="noise detection"></p> <p>发现，噪音样本跟正常样本在遗忘次数上，分布十分不一样，遗忘次数会显著多于正常样本。因此我们可以利用这个特点，来帮助我们对数据集去噪，例如最近的文章<em>DataCLUE</em>: A Benchmark Suite for Data-centric NLP中就使用了这种方法。</p> <p>上面展示的是label noise的结果，作者在附录部分还附上了对input添加noise的实验，也挺有意思的：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126185349116.png" alt="pixel noise"></p> <p>发现，对样本（图片）添加的noise越大，这个forgetting的统计就越接近一个正态分布，这也一定程度上反映了分类任务越难，样本遗忘的情况就越严重。</p> <h3 id="_5-微观视角的灾难性遗忘"><a href="#_5-微观视角的灾难性遗忘" class="header-anchor">#</a> 5. 微观视角的灾难性遗忘</h3> <p>这是一个很有意思的实验。</p> <p>上面的很多分析都验证了神经网络确实会有遗忘，即使在同一个任务的训练中。为了跟经典的灾难性遗忘进行对照，作者仿照经典的continual learning的实验方法来设计了实验：<strong>将样本分两批，使用模型依次进行训练，并记录模型在两批样本上的分类准确率</strong>。</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126121917102.png" alt="continual learning"></p> <p>上图最左边，是使用一个数据集中<strong>随机挑选的两部分来轮流训练</strong>。我们发现，及时两个task都来自同一个数据分布，灾难性遗忘也可能发生！模型太健忘了。</p> <p>右边的两个图，则是使用unforgettable和forgettable样本作为两个数据集来依次训练，可以发现两个结论：</p> <ul><li>在容易遗忘的样本上训练完之后，再去难忘的样本上训练，灾难性遗忘很严重（刚刚把易遗忘的样本学会，就一下子忘记了）</li> <li>在难忘的样本上训练完之后，再去易遗忘的样本上训练，灾难性遗忘的现象很轻微。</li></ul> <h3 id="_6-我们可以丢掉很多样本-还能保持泛化性能"><a href="#_6-我们可以丢掉很多样本-还能保持泛化性能" class="header-anchor">#</a> 6. 我们可以丢掉很多样本，还能保持泛化性能</h3> <p>在上面的实验我们可以看出，学习forgettable examples对于unforgettable examples上的泛化性能似乎影响不大，而反过来就影响很大。借助开头的那个图来理解一下：</p> <img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126150635720.png" alt="image-20220126150635720" style="zoom:67%;"> <p>这意味着forgettable examples的分布能够比较好地涵盖unforgettable examples的分布，这样才会使得学习新的样本对原来的decision boundary不会有太大改变。</p> <p>所以，从这个角度看的话，forgettable examples比unforgettable examples蕴含了更多的信息，<strong>样本在训练中被遗忘的次数越多，它对分类任务的作用可能越大</strong>。</p> <p>因此，我们可以大胆假设，是不是我把unforgettable examples丢掉一大批，都不会怎么影响模型的性能呢？作者做了如下的样本丢弃实验：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126151338069.png" alt="removing unforgettable examples"></p> <p>左图中的绿线和蓝线分别代表按照被遗忘次数排序的样本和随机排列的样本，不断增大丢弃比例后的结果。可以发现，在CIFAR-10数据集中，我们可以把<strong>前35%最少遗忘的样本丢掉，只损失0.2%的准确率</strong>。</p> <p>右图则是同样去除5000个样本，但是改变这5000个样本中平均被遗忘次数。可以发现，大体上，包含的forgettable examples越多，效果越差。但是有意思的是存在一个明显的拐点，当forgettable examples达到一定比例时，效果又会抬升一点。作者解释，这说明数据集中<strong>可能存在某些异常点或者错误标注的样本</strong>（outliers or mislabeled examples），把他们去掉了对模型有好处，但这些样本往往被遗忘次数也很多。</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126152553310.png" alt="removing unforgettable examples"></p> <p>这个图则对比了三个数据集，对比发现MNIST，permuted-MNIST和CIFAR-10可以分别移除高达80%，50%，30%的训练样本且几乎不影响性能。</p> <h3 id="_7-样本遗忘现象的稳定性"><a href="#_7-样本遗忘现象的稳定性" class="header-anchor">#</a> 7. 样本遗忘现象的稳定性</h3> <p>我们肯定还会关心这种样本遗忘现象，换了随机种子，换了模型，结果会不会差别很大，还是说，（不）容易遗忘的样本，换了模型和种子都依然（不）容易遗忘？</p> <p>作者对此都做了实验探究，首先，使用了10个不同seed，对所有样本的number of forgetting进行统计，然后彼此之间计算排序的Pearson相关系数，发现高达89.2%，所以不同seed下，样本的遗忘现象是十分类似的。</p> <p>然后，作者探究了在不同的训练阶段（不同的epoch时）的遗忘情况的差异，见下图最左边，实验表明，训练到75轮以后，样本遗忘的情况就基本稳定了。</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220126183214956.png" alt="image-20220126183214956"></p> <p>（中间那个图我看不懂，就不讲了）</p> <p>最右边那个图，是使用ResNet18来对forgetting events进行统计，然后使用这个统计结果，不断删减训练样本，在更大型的模型WideResNet上进行训练的结果，发现依然可以删除30%的数据还能保持性能基本不变，这说明，我们<strong>可以使用轻量的模型进行遗忘现象的统计，来辅助重型模型的训练。</strong></p> <p>总之，<strong>你如何训练（超参数、模型架构等）对遗忘现象的统计结果的影响不大，遗忘现象反映的是数据集本身的特点。</strong></p> <h2 id="五、总结-思考"><a href="#五、总结-思考" class="header-anchor">#</a> 五、总结&amp; 思考</h2> <h3 id="写作上"><a href="#写作上" class="header-anchor">#</a> 写作上：</h3> <p>读到这里，我们应该可以发现，这就是一个对模型训练过程中的一些现象进行了一系列简单的统计，并没有什么技术含量，但是读完的感觉，却让我们大呼过瘾，原来深度学习这个黑箱子里还发生了这么多有趣的事情！</p> <p>这篇文章，让我看到了搞深度学习的科研的另一种可能，我们不一定要设计复杂的模型，要提出什么深刻的数学理论才能做出好的研究，像本文这种对模型的行为的观察、对数据集特点的分析，也可以做出好的研究，并给后续的研究者提供很多经验和思考。</p> <p>本文虽然像一个实验报告，使用的统计手段也很简单，但是本文设计实验的方法、如何从各种角度去对一个现象进行观测，是很值得我们学习的。</p> <h3 id="样本遗忘带来的启发"><a href="#样本遗忘带来的启发" class="header-anchor">#</a> 样本遗忘带来的启发</h3> <p>样本遗忘，以及灾难性遗忘，告诉我们神经网络本身存在一定缺陷，没法将学到的知识进行比较好的保留，知识很容易被覆盖。这明显跟人类学习过程不太一样，新的知识一般不会对曾经学过的知识进行巨大冲击，而是融合。所以这对于我们设计神经网络，设计训练方法，应该有很大启示，在continual learning领域应该已经有丰富的工作来试图解决这方面问题。</p> <p>另外，样本遗忘现象本身，也可以帮助我们认识数据集，这对于Data-centric AI领域的研究应该也有很大帮助。</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/103.a356b143.js" defer></script>
  </body>
</html>
