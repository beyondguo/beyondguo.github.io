<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>文本检索、开放域问答与Dense Passage Retrieval (EMNLP-20) | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/80.a8c296e0.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>文本检索、开放域问答与Dense Passage Retrieval (EMNLP-20)</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/paper_notes/notes/DPR.html#open-domain-question-answering-qa" class="sidebar-link">Open-domain question answering (QA)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#open-domain-qa的两个步骤" class="sidebar-link">Open-domain QA的两个步骤</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#文本检索" class="sidebar-link">文本检索</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#阅读理解" class="sidebar-link">阅读理解</a></li></ul></li><li><a href="/paper_notes/notes/DPR.html#dense-passage-retriever-dpr" class="sidebar-link">Dense Passage Retriever (DPR)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#dual-encoder" class="sidebar-link">Dual-encoder</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#损失函数设计" class="sidebar-link">损失函数设计</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#负样本选择" class="sidebar-link">负样本选择</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#关键的trick-in-batch-negatives" class="sidebar-link">关键的Trick——In-batch negatives</a></li></ul></li><li><a href="/paper_notes/notes/DPR.html#实验设置-数据集" class="sidebar-link">实验设置&amp;数据集</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#knowledge-source" class="sidebar-link">Knowledge Source</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#qa-datasets" class="sidebar-link">QA Datasets</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#baselines" class="sidebar-link">Baselines</a></li></ul></li><li><a href="/paper_notes/notes/DPR.html#retrieval任务实验结果" class="sidebar-link">Retrieval任务实验结果</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#main-results" class="sidebar-link">Main Results：</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#在精确匹配上效果并不好" class="sidebar-link">在精确匹配上效果并不好：</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#训练好的dpr需要多少数据量" class="sidebar-link">训练好的DPR需要多少数据量：</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#in-batch-negatives" class="sidebar-link">In-batch negatives：</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#similarity和loss的选择" class="sidebar-link">Similarity和loss的选择</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/DPR.html#cross-dataset-generalization" class="sidebar-link">Cross-dataset generalization</a></li></ul></li><li><a href="/paper_notes/notes/DPR.html#end-to-end-qa实验结果" class="sidebar-link">End-to-End QA实验结果</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/paper_notes/notes/DPR.html#总结" class="sidebar-link">总结</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="文本检索、开放域问答与dense-passage-retrieval-emnlp-20"><a href="#文本检索、开放域问答与dense-passage-retrieval-emnlp-20" class="header-anchor">#</a> 文本检索、开放域问答与Dense Passage Retrieval (EMNLP-20)</h1> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220215131419.png" alt=""></p> <ul><li>标题：Dense Passage Retrieval for Open-Domain Question Answering</li> <li>会议：EMNLP-20</li> <li>机构：Facebook AI, University of Washington, Princeton University</li> <li>链接：https://readpaper.com/paper/3099700870</li></ul> <blockquote><p><strong>一句话总结：</strong>
一个很好的文本检索（IR）、问答（QA）的学习材料。开放域问答一般分两步——检索和阅读理解，本文提出的DPR是一个高效的基于语义匹配的检索模型，从而提高整体QA的效果，该思路对后续的对<strong>比学习</strong>的一系列工作都有启发。</p></blockquote> <h2 id="open-domain-question-answering-qa"><a href="#open-domain-question-answering-qa" class="header-anchor">#</a> Open-domain question answering (QA)</h2> <p>QA可以分为Close-domain QA和Open-domain QA，前者一般限制在某个特定领域，有一个给定的该领域的知识库，比如医院里的问答机器人，只负责回答医疗相关问题，甚至只负责回答该医院的一些说明性问题，再比如我们在淘宝上的智能客服，甚至只能在它给定的一个问题集合里面问问题；而Open-domain QA则是我们可以问任何事实性问题，一般是给你一个海量文本的语料库，比方Wikipedia/百度百科，让你从这个里面去找回答任意非主观问题的答案，这显然就困难地多。总结一下，Open-domain QA的定义：</p> <blockquote><p>Open-domain QA，是这样一种任务：给定海量文档，来回答一个事实性问题（factoid questions ）。</p></blockquote> <p>注意，是回答factoid questions，即一个很客观的问题，不能问一些主观的问题。</p> <p>这就类似于我们只在在搜索引擎里搜索某个问题的答案，我们希望搜索引擎能直接告诉我们答案，而不单单是找到一篇文章，然后我们需要自己找答案。</p> <p>举个例子，正好我前几天搜索triplet loss的时候印象深刻：</p> <p>我在Google里面直接搜triplet loss：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220216105121.png" alt="image-20220216105121926"></p> <p>首先，排在第一的结果就是Wikipedia的link，同时上面显示了一段话，让我不用点开Wikipedia，就能直接知道triplet loss<strong>是什么，有什么用</strong>，另外，仔细看的话，发现它把具体定义的那句话给我加粗了，就是我上面高亮的部分。</p> <p>如果我继续点击进入Wikipedia，会更清楚的看到搜索引擎帮我把我想要的答案给高亮了（下图中的紫色部分是浏览器自动显示的，不是我选择的）：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220216104918.png" alt="image-20220216104917986"></p> <p>我想这就是个很好的例子，告诉我们open-domain QA想要做的是什么事。</p> <p>当然，搜索引擎返回答案，还涉及到其他技术，比如有一些事实性问题，比如“姚明比奥尼尔高多少”，就需要借助知识图谱等技术来实现了。</p> <h3 id="open-domain-qa的两个步骤"><a href="#open-domain-qa的两个步骤" class="header-anchor">#</a> Open-domain QA的两个步骤</h3> <p>我们这里讲深度学习时代的Open-domain QA，传统的方法往往涉及到十分复杂的组件，而随着基于深度学习的阅读理解（reading comprehension）模型的兴起，我们现在可以把Open-domain QA给简化成两个步骤：文本检索与阅读理解。</p> <p>① 文本检索：需要一个retriever，从海量文本中，找到跟question最相关的N篇文档，这些文档中包含了该问题的答案；
② 阅读理解：需要一个reader，从上面抽取出来的文档中，找到具体答案。</p> <h3 id="文本检索"><a href="#文本检索" class="header-anchor">#</a> 文本检索</h3> <p>对于文本的检索，目前最常用的方案就是基于倒排索引（inverted index）的关键词检索方式，例如最常用的ElasticSearch方案，就是基于倒排索引的，简言之，这是一种关键词搜索，具体的匹配排序规则有TF-IDF和BM25两种方式。这种文本检索的方式，是一种文本的bag-of-words表示，通过词频、逆文档频率等统计指标来计算question和document之间的相关性，可参考BM25的wiki。</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220216200646975.png" alt=""></p> <p>这种方式，是比较“硬”的匹配，当你搜索的关键词准确、明确时，搜索结果会非常好，但是当你只知道大概意思，搜索的结果可能就很差，因为bag-of-words的表示，无法认识到词语之间的相似性关系，因此就只能搜索到你输入的关键词，却无法找到词语不同但意思相近的结果。</p> <p>一般的Open-domain QA都会直接使用这种基于TF-IDF或者BM25的匹配方式来进行检索，本论文则是提出，我们可以使用语义的匹配来达到更好的效果，弥补硬匹配的不足，这也是本论文的主要关注点。具体地，我们可以训练一个语义表示模型，赋予文本一个dense encoding，然后通过向量相似度来对文档进行排序。</p> <p>其实向量搜索也很常见了，像以图搜图就是典型的向量相似度搜索，常用的开源引擎有Facebook家的FAISS.</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220217095416.png" alt=""></p> <h3 id="阅读理解"><a href="#阅读理解" class="header-anchor">#</a> 阅读理解</h3> <p>阅读理解一般指的是，给定一个问题（question）和一段话（passage），要求从这段话中找出问题的答案。训练方式一般是我们计算passage中每个token是question的开头s或者结尾t的概率，然后计算正确答案对应start/end token最大似然损失之和。具体咱们可以参考BERT论文中对fine-tuning QA模型中的方法介绍：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220216193432332.png" alt="源自BERT论文"></p> <p>即，通过BERT encoder，我们可以得到每个token的一个representation，然后我们再额外设置一个start vector和一个end vector，与每个token的representation计算内积，再通过softmax归一化，就得到了每个token是start或者end的概率。</p> <p>我在一个博客上看到了一个画的更清楚的图：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220216200401533.png" alt="https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/#part-1-how-bert-is-applied-to-question-answering"></p> <p>关于阅读理解的具体内容，这里也不赘述，这也不是今天这篇论文的重点。</p> <h2 id="dense-passage-retriever-dpr"><a href="#dense-passage-retriever-dpr" class="header-anchor">#</a> Dense Passage Retriever (DPR)</h2> <p>本文最重要的就是这个DPR了，它解决的就是open-domain QA中的检索问题，目标是训练一个文本表示模型，可以对question和passage进行很好的语义向量表示，从而实现高精度的向量搜索。</p> <p>DPR是一个retriever，实际上分两块，首先我们需要得到文档的向量表示，然后我们需要一个向量搜索工具，后者本文中直接使用著名的FAISS向量搜索引擎，所以重点就是训练一个文本表示模型。</p> <h3 id="dual-encoder"><a href="#dual-encoder" class="header-anchor">#</a> Dual-encoder</h3> <p>本文使用了一个dual-encoder的框架，可以理解为一个双塔结构，一个encoder <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>P</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E_P(\cdot)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span>专门对passage进行表示，另一个encoder <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>Q</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E_Q(\cdot)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span>专门对question进行表示，然后我们使用内积来表示二者的相似度：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>E</mi><mi>P</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>E</mi><mi>Q</mi></msub><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">sim(p,q) =E_P(p)\cdot E_Q(q)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span></span></p> <h3 id="损失函数设计"><a href="#损失函数设计" class="header-anchor">#</a> 损失函数设计</h3> <p>我们首先构造训练样本，它是这样的形式：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mo>=</mo><mo stretchy="false">{</mo><mo>&lt;</mo><msub><mi>q</mi><mi>i</mi></msub><mo separator="true">,</mo><msubsup><mi>p</mi><mi>i</mi><mo>+</mo></msubsup><mo separator="true">,</mo><msubsup><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow><mo>−</mo></msubsup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msubsup><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>n</mi></mrow><mo>−</mo></msubsup><mo>&gt;</mo><msub><mo stretchy="false">}</mo><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">D = \{ &lt; q_i, p_i^+, p_{i,1}^-, ..., p_{i,n}^- &gt; \}_i
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.224434em;vertical-align:-0.403103em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.433005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.266995em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-2.4330050000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403103em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-2.4330050000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403103em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p> <p>即，<strong>每个训练样本，都是由1个question，1个positive passage和n个negative passage构成的</strong>。positive就是与问题相关的文本，negative就是无关的文本。</p> <p>用一个样本中每个passage（n+1个）和当前question的相似度作为logits，使用softmax对logits进行归一化，就可以得到每个passage与当前question匹配的概率，由此就可以设计极大似然损失——取positive passage的概率的负对数：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>p</mi><mo>+</mo></msup><mo separator="true">,</mo><msubsup><mi>p</mi><mn>1</mn><mo>−</mo></msubsup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msubsup><mi>p</mi><mi>n</mi><mo>−</mo></msubsup><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mo>=</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>p</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msup><mi>p</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><msubsup><mi>p</mi><mi>j</mi><mo>−</mo></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">L(q, p^+, p_{1}^-, ..., p_{n}^-)\\
=-log\frac{exp(sim(q, p^+))}{exp(sim(q, p^+))+\sum_{j=1}^{n} exp(sim(q, p_{j}^-))}
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.0777700000000001em;vertical-align:-0.256439em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.821331em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.4435610000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.256439em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8213309999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.585611em;vertical-align:-1.13728em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.448331em;"><span style="top:-2.2985379999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.697331em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.13728em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p> <p>上面的公式里，为方便看清楚，我省去了样本的下标<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>。可以看到，这就相当于一个cross-entropy loss。而这样的设计，跟现在遍地的对比学习的loss非常像，例如知名的SimCSE也引用了本文：</p> <img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220216211321915.png" alt="image-20220216211321915" style="zoom:80%;"> <h3 id="负样本选择"><a href="#负样本选择" class="header-anchor">#</a> 负样本选择</h3> <p>在上面的损失函数中，我们发现负样本起着重要的作用。另外，正样本一般都是确定的，而负样本的选择则是多种多样的，所以负样本怎么选，对结果应该有很大的影响。</p> <p>作者设计了三种负样本（negative passage）选择的方式：</p> <ol><li><strong>Random</strong>：从语料库中随机抽取一个passage，基本上都是跟当前question无关的；</li> <li><strong>BM25</strong>：使用基于BM25的文本检索方式在语料库中检索跟question最相关的文本，但要求不包含答案；</li> <li><strong>Gold</strong>：在训练样本中，其他样本中的positive passage。即对于训练样本<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>对应的正样本是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">p_i^+</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span></span></span></span>，而这个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo>+</mo></msubsup></mrow><annotation encoding="application/x-tex">p_i^+</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span></span></span></span>可以作为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">q_j</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>的负样本。</li></ol> <p>既然都命名为Gold了，那说明作者对它给予了厚望，肯定是主要的负样本来源。</p> <p>论文最终的最佳实践，就是主要采用同一个mini-batch中的Gold passages，配合上一个BM25 passage（以及同batch内其他question的BM25）。</p> <h3 id="关键的trick-in-batch-negatives"><a href="#关键的trick-in-batch-negatives" class="header-anchor">#</a> 关键的Trick——In-batch negatives</h3> <p>假设我们的batch size为B，每个question有1个positive和n个negative，那么一个batch内就有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>×</mo><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B \times (n+1)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>个passages要经过encoding，而一般我们都需要比较多的negatives才能保证较好的效果，所以光是encoding，这个计算开销就很大。</p> <p>于是，有人就想出了一个办法，我们只需要B个questions和其对应的B个positives，形成两个矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>，然后“我的positive，可以当做你的negative”，这样我们就不需要额外再找negative了，然后直接算一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mi>Q</mi><msup><mi>P</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">S=QP^T</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>就可以得到计算损失函数所需要的所有pair的相似度，这就使得整个过程变得高效又简洁。由于不需要额外找negatives，所以一个batch内只有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>个positive passages需要经过encoding，这比前面的方法减少了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>倍，干净又卫生啊兄弟们。</p> <p>上面说的方式，相当于只使用Gold负样本，实际上作者在最佳方案中还使用了BM25负样本，但也是采用的in-batch training的策略，即，我每个question都找一个BM25负样本， 然后，该BM25样本也会作为同batch内所有其他question的负样本，这相当于再增加一个矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>，总共有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">B \times 2</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>个passages进行encoding，然后多计算一个矩阵乘法得到相似度。</p> <p>最后注意，in-batch training并不是DPR论文首创，前面很多工作中已经得到成功应用。</p> <h2 id="实验设置-数据集"><a href="#实验设置-数据集" class="header-anchor">#</a> 实验设置&amp;数据集</h2> <h3 id="knowledge-source"><a href="#knowledge-source" class="header-anchor">#</a> Knowledge Source</h3> <p>知识库，就是我们open-domain QA使用什么语料库来进行问答。本文选用Wikipedia，这也是最常用的设定。当然，Wikipedia是一篇篇文章，通常是十分长，模型不便处理，因此这里作者将所有文本，都继续划分成100个词长度的passages，这些length=100的passages就是本文做检索的基本单元。另外，每个passage还在开头拼接上了对应Wikipedia page的title。</p> <h3 id="qa-datasets"><a href="#qa-datasets" class="header-anchor">#</a> QA Datasets</h3> <p>我们还需要有&lt;问题，答案&gt;这样的数据集，来让我们训练retriever和reader。</p> <p>具体数据集有：</p> <ul><li>Natural Questions (NQ) ：提供了question和answer，且答案全都来自Wikipedia</li> <li>TriviaQA：提供question-answer-evidence triples</li> <li>WebQuestions (WQ)：只提供了question和answer</li> <li>CuratedTREC (TREC)：只提供了question和answer</li> <li>SQuAD v1.1：提供question，context和answer</li></ul> <p>这些数据集中，对于TriviaQA，WQ和TREC，由于没有给相关的context，没法直接那answer当做positive passages，所以作者选择在Wikipedia passages中使用BM25来检索包含answer的passage来作为positive passage（虽然这种做法我感觉不一定好，因为匹配上的，不一定就能回答你的问题，比如你问“阿里巴巴谁创办的”，答案是“马云”，但包含“马云”的句子可能是“马云在达沃斯论坛演讲”，这显然不能回答该问题）。</p> <p>对于SQuAD和NQ，由于这些数据集提供的passage跟作者自己的预处理方式不一样，所以作者用这些passage在前面对Wikipedia预处理后的passages pool中去匹配得到positive passage。</p> <h3 id="baselines"><a href="#baselines" class="header-anchor">#</a> Baselines</h3> <p>对于retrieval任务，baseline就是BM25算法，同时作者还对比了BM25+DPR的效果，即将二者的得分进行加权平均:<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mn>25</mn><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mo>⋅</mo><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">BM25(q,p)+\lambda \cdot sim(q,p)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mord">25</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span>，其中作者发现<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1.1</mn></mrow><annotation encoding="application/x-tex">\lambda=1.1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1.1</span></span></span></span>效果较好。</p> <p>另外对于DPR来说，越多的训练样本肯定越好，所以除了在单个数据集上训练测试外，作者还尝试了使用所有数据集的训练样本来训练DPR然后测试。而BM25也是纯统计方法，所以不存在使用训练数据一说。</p> <h2 id="retrieval任务实验结果"><a href="#retrieval任务实验结果" class="header-anchor">#</a> Retrieval任务实验结果</h2> <h3 id="main-results"><a href="#main-results" class="header-anchor">#</a> Main Results：</h3> <p>结果见下表：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220218191438.png" alt="retrieval任务结果"></p> <p>可以发现，<strong>除了SQuAD数据集</strong>，其他的数据集上，DPR的表现都不错，都大幅超越了BM25算法，而结不结合BM25，其实影响不是很大，但使用更多的训练数据集，总体上肯定更好些。</p> <h3 id="在精确匹配上效果并不好"><a href="#在精确匹配上效果并不好" class="header-anchor">#</a> 在精确匹配上效果并不好：</h3> <p><strong>在SQuAD上，效果很差，这一点很有意思</strong>。关于这一点，作者给出的解释是：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220218192133.png" alt="image-20220218192133247"></p> <p>即 1.这个数据集的question跟passage再语言上高度重合，所以BM25天然有优势；2. 这个数据集采样是有偏的。</p> <p>其实这也告诉我们，你DPR也不是万能的，天下没有免费的午餐，在那种“精确匹配”的场景下，相似度搜索一般不会比bag-of-words硬匹配更好。</p> <h3 id="训练好的dpr需要多少数据量"><a href="#训练好的dpr需要多少数据量" class="header-anchor">#</a> 训练好的DPR需要多少数据量：</h3> <p>然后我们看看使用多少数据量，DPR就超过了BM25：</p> <img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220218191754.png" alt="DPR使用的训练集大小" style="zoom:85%;"> <p>可见，仅仅使用1k的数据量，DPR这种语义匹配的方式，就超越了BM25这种硬匹配。</p> <h3 id="in-batch-negatives"><a href="#in-batch-negatives" class="header-anchor">#</a> In-batch negatives：</h3> <p>然后再看看negative样本的选择的影响，也看看in-batch training这种方式怎么样：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220218192713.png" alt="in-batch training"></p> <p>这个表初次读的时候一直搞不懂，文中也没写明白，后来请教了同学才搞明白：</p> <p>第一个block，batch size不太清楚，有可能是128，但不使用in-batch的策略，每个question都自带7个negatives参与训练。这个block是为了对比不同的negative的效果，发现其实差不多，各有优劣。</p> <p>第二个block，batch size分别是8，32，128，采用的in-batch策略，使用同batch内的其他positive作为negative，所以batch越大，可以使用的negatives就越多，因此效果就越好，效果比第一个block好了很多。</p> <p>第三个block，batch size分别是32，32，128，除了Gold，每个样本还带了1-2个BM25样本，且这些样本在整个batch内共享（参考上文中“负样本选择”一节的介绍），发现，带一个BM25样本就有明显提高，再多了就没效果了。</p> <p>总之，这个实验说明，in-batch training是很高效、有效的一种方法，然后负样本我们可以主要使用batch内的那些positives（即Gold passages），再配上一个额外的BM25 passage即可取得很好的效果。</p> <h3 id="similarity和loss的选择"><a href="#similarity和loss的选择" class="header-anchor">#</a> Similarity和loss的选择</h3> <p>本文采用的是dot product作为相似度度量，作者还测试了L2距离和cosine similarity，发现最差的是cosine similarity。（这一点有意思，可探究一下为什么）</p> <p>关于loss，除了本文的NLL loss，作者还尝试了在similarity任务中常用的triplet loss，发现效果差别不大，但还是NLL loss更好一点。</p> <h3 id="cross-dataset-generalization"><a href="#cross-dataset-generalization" class="header-anchor">#</a> Cross-dataset generalization</h3> <p>这里文中也是一笔带过，所以我也不赘述，我只是很高兴在论文中看到了这样的实验，cross-dataset generalization是大多数人不会去考虑的一个实验，但对于验证泛化性能是很重要的。</p> <h2 id="end-to-end-qa实验结果"><a href="#end-to-end-qa实验结果" class="header-anchor">#</a> End-to-End QA实验结果</h2> <p>这部分并不是本文的重点，前面讲了，除了训练一个retriever（对应本文的DPR），完成open-domain QA还需要一个reader。之前的sota工作都涉及到复杂的预训练，但是本文重点在于搞一个很好的retriever——DPR，从而只需要简单训练一个reader就够了，下面是实验结果：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220218195546.png" alt="QA实验"></p> <p>最后再贴一段作者自己的评论：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20220218195645.png" alt="image-20220218195645629"></p> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>这篇文章最大的亮点在于在训练学习text representation的时候如何选择negative samples，其中的Gold和BM25对学习一个好的表示起到了重要的作用，因此仅仅使用1k个训练样本，就可以训练一个超越BM25算法的文本检索工具。本文也为后续的一些对比学习工作，例如SimCSE等产生了启发，作为文本相似度匹配的重要工作，本文还是很值得一读的。</p> <p>以上，这篇文章就解读完毕了，其实我之前怎么了解过QA，而本文对于QA小白来说也是一个绝佳的教材，所以这篇文章除了让我了解DPR这个工作之外，也让我学习了很多关于QA的相关知识，收获颇丰。</p> <p>推荐资料：</p> <p>[1]Wikipedia: Question Answering https://en.wikipedia.org/wiki/Question_answering
[2]Wikipedia: BM25 https://en.wikipedia.org/wiki/Okapi_BM25
[3] DrQA: Reading Wikipedia to Answer Open-Domain Questions
[4] Efficient Natural Language Response Suggestionfor Smart Reply</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/80.a8c296e0.js" defer></script>
  </body>
</html>
