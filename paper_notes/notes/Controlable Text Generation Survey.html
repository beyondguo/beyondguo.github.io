<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Controlable Text Generation Survey | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/79.f9a1e6f0.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link router-link-active">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Controlable Text Generation Survey</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#一、controlable-text-generation-ctg-定义与应用" class="sidebar-link">一、Controlable Text Generation(CTG)定义与应用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#_1-什么是ctg" class="sidebar-link">1. 什么是CTG</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#_2-ctg的应用场景" class="sidebar-link">2. CTG的应用场景</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#_3-ctg使用的主要plm结构" class="sidebar-link">3. CTG使用的主要PLM结构</a></li></ul></li><li><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#二、ctg的不同方法流派" class="sidebar-link">二、CTG的不同方法流派</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#_1-改良派-fine-tuning" class="sidebar-link">1. 改良派——Fine-tuning</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#_2-改革派-retrain-refactor" class="sidebar-link">2. 改革派——Retrain/Refactor</a></li><li class="sidebar-sub-header"><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#_3-保守派-post-process" class="sidebar-link">3. 保守派——Post-Process</a></li></ul></li><li><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#三、evaluation" class="sidebar-link">三、Evaluation</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#四、挑战-未来方向" class="sidebar-link">四、挑战，未来方向</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/paper_notes/notes/Controlable%20Text%20Generation%20Survey.html#references" class="sidebar-link">-References:</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="盘点controllable-text-generation-ctg-的进展"><a href="#盘点controllable-text-generation-ctg-的进展" class="header-anchor">#</a> 盘点Controllable Text Generation(CTG)的进展</h1> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041438988.png" alt="image-20220404143858765"></p> <p>A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models，一篇2022年1月上传到Arxiv上的一篇综述文章，作者团队里面有<strong>周明</strong>和<strong>宋大为</strong>两个大佬。比较奇怪的是论文使用的是ACM Journal的模板，还有DOI号，但是搜索DOI却发现是另外一篇无关的文章，所以不知道这个文章到底发表在哪里、有无发表。但不管怎么，这依然是一篇很好的综述，对<strong>可控制的文本生成</strong>这个领域的工作做了很好的梳理和总结，值得一读。</p> <p><strong>Notice:</strong> 本博客主要根据这篇Survey论文进行总结，单也添加了很多论文中没有的内容，比如对Survey中列举的具体工作，进行了更加深入的说明和讨论，还有一些Survey中没有涉及到的工作，也在本博客中有讨论，同时，本文也没有涵盖Survey中列举的所有工作。</p> <h2 id="一、controlable-text-generation-ctg-定义与应用"><a href="#一、controlable-text-generation-ctg-定义与应用" class="header-anchor">#</a> 一、Controlable Text Generation(CTG)定义与应用</h2> <h3 id="_1-什么是ctg"><a href="#_1-什么是ctg" class="header-anchor">#</a> 1. 什么是CTG</h3> <p>Controlable Text Generation，可控制的文本生成，就是能够在传统的文本生成的基础上，增加对生成文本一些属性、风格、关键信息等等的控制，从而使得生成的文本符合我们的某种预期。如果给一个明确的定义的话，文中引用了另一篇更早的综述的定义：</p> <blockquote><p><strong>Controllable text generation (CTG)</strong> refers to the task of generating text according to the givencontrolled element.
--<em>Exploring Controllable Text Generation Techniques (2020)</em> [1]</p></blockquote> <p>论文中给出了两个简单的例子：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041454581.png" alt="CTG examples"></p> <p>第一个例子就是给定一个故事线，要求模型按照这样的思路去生成。第二个例子是关于传统人机对话中如果机器生成文本时不受控制可能带来的问题，比如会给出有害的建议，甚至说脏话，这个时候就需要我们在模型生成的时候加以控制。</p> <p>作者对CTG总结了这么一个Input-Process-Output的总体框架，简称IPO：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/ipt.png" alt="IPO框架"></p> <p>跟传统NLG的区别就在于我们会在输入的时候加入某些控制因素，从而让最终的输出满足某种条件。</p> <h3 id="_2-ctg的应用场景"><a href="#_2-ctg的应用场景" class="header-anchor">#</a> 2. CTG的应用场景</h3> <p>CTG可以应用的场景非常广泛：</p> <ul><li><strong>Attribute-based Generation</strong>，基于某种属性的自然语言生成，比如生成特定情感/口吻/风格的文本</li> <li><strong>Dialogue Generation</strong>，对话系统对NLG有更高的要求，因此CTG的应用就不言而喻了</li> <li><strong>Storytelling</strong>，用CTG来辅助文学创作，想想就很爽，而传统的NLG，基本给了开头你就无法控制了</li> <li><strong>Data to Text</strong>，使用一些结构化数据（table，graph）来生成自然语言，可用于给定每天的天气数据，来自动生成天气播报，或者把老板看不懂的表格数据用CTG技术翻译成人话给他听</li> <li><strong>Data Augmentation</strong>，使用CTG可以把已有的文本的某些信息给重新生成，变成我们想要的属性</li> <li><strong>Debiasing</strong>，这也非常重要，可以帮助我们把带有某些偏见的文本转化成无偏见的文本，让机器也符合伦理道德</li> <li><strong>Format Control</strong>，风格、格式的转换，比如中国古诗词就有明确的格式，这就需要在生成的时候加以控制</li></ul> <p>作者很详细地把这些方面总结在下表中：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041524328.png" alt="overview applications"></p> <h3 id="_3-ctg使用的主要plm结构"><a href="#_3-ctg使用的主要plm结构" class="header-anchor">#</a> 3. CTG使用的主要PLM结构</h3> <p>本文主要是调查基于Pre-trained Language Model(PLM)的CTG方法，所以了解主要的PLM也很重要：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041530813.png" alt="PLMs"></p> <p>上面我们主要关注一下各种PLM针对语言的生成，设计使用的何种预训练任务。首先我们最熟悉的BERT，主要使用的是MLM，所以使用BERT的话你只能做完形填空。而GPT家族则使用的经典的causal LM，本文称为SLM，因此可以不断生成流利的句子。T5/UniLM/ERINE等都使用了CTR（corrupted text reconstruction）任务，mask掉的是一个span，可以是连续的很多词，然后让模型学习去复原，因此比BERT的MLM能力更强。而mBART则更是使用了FTR（full text reconstruction），让模型的复原能力更进一步。</p> <h2 id="二、ctg的不同方法流派"><a href="#二、ctg的不同方法流派" class="header-anchor">#</a> 二、CTG的不同方法流派</h2> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041554953.png" alt="Approaches for CTG"></p> <p>论文把目前基于PLM的CTG的各种方法流派做了个总结，上图看得十分清晰。主要分为三派：</p> <ul><li>改良派：在已有PLM的基础上继续预训练</li> <li>革命派：另起炉灶，重新训练一个大型预训练模型</li> <li>保守派：连PLM都不想动，直接在PLM的输出上做后处理</li></ul> <h3 id="_1-改良派-fine-tuning"><a href="#_1-改良派-fine-tuning" class="header-anchor">#</a> 1. 改良派——Fine-tuning</h3> <p>改良派，实际上就是沿用了PLM最经典的使用方法——Fine-tuning，虽然原始的PLM在训练的时候，并没有对某些属性、特点、要素进行控制，但是PLM预训练中学习的大规模知识是很有用的，所以我们使用特定的语料，让PLM进一步去学习我们希望的某种控制效果，就可以实现CTG的目的。</p> <p>而Finetuning中又分为三种方式：</p> <ul><li>Adapted Module方式，通过额外添加一个控制模块，用于添加属性控制，然后连同PLM一起进行训练。代表方法包括 Auxiliary Tuning[2]，DialGPT[3]。</li> <li>Prompt方式，包括prompt Learning、prompt tuning[4]等方法，实际上基于prompt的方法，本身就是对PLM的生成加入了额外的控制，如果使用有监督的风格、属性数据集进行训练，就可以直接得到基于prompt的CTG模型。也有更新的工作Inverse Prompt[5]，用模型生成的句子来反过来去预测代表风格、主题等的prompt，从而让prompt对文本生成的控制力更强。</li> <li>基于强化学习RL的方法。</li></ul> <p>总之，这些基于finetuning的方法，基本都要求我们有一个下游任务的有监督数据集，从而帮助我们学习某种控制性，比如你希望控制生成文本的情感属性，那么就需要你有情感分类的数据集，让模型去学习[指定情感]——&gt;[该情感的文本]的映射。</p> <h3 id="_2-改革派-retrain-refactor"><a href="#_2-改革派-retrain-refactor" class="header-anchor">#</a> 2. 改革派——Retrain/Refactor</h3> <p>改革派的目标都更加宏大，单纯的Finetuning在具体任务上小打小闹一下是可以的，但如果想有一个更加通用的CTG，还是得预训练，或者修改PLM的结构。</p> <p>代表性方法之一是<strong>CTRL</strong>[6]，由Salesforce团队带来，背后是Richard Socher大佬。CTRL收集了140GB的数据，涵盖了很多个domain的语料（百科、reddit、影评、新闻、翻译、问答...），每个domain都设置有一个control code，从而训练一个大型的包含1.63B参数量的conditional language model：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041714472.png" alt="conditional LM"></p> <p>具体训练上，CTRL使用的是经典的Transformer结构，那些control code是预定义好的，直接插入在sequence的开头。更多训练细节见原文。CTRL取得了比较明显的控制生成效果：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041748971.png" alt="CTRL examples"></p> <p>甚至可以编造一个URL作为control code就可以生成一段新闻：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041756361.png" alt="generating news according to URL"></p> <p>另一个由南洋理工大学带来的工作<strong>Content-Conditioner (CoCon)</strong> [10]既改造了GPT模型，并在250K个样本上进行了对GPT进行了微调。CoCon跟CTRL和PPLM的区别在于：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042211351.png" alt="image-20220404221124310"></p> <p>以CTRL为代表的方法只能从一个总体的层面对生成文本增加限制，比如某种风格主题，但无法对具体内容进行精细控制，CoCon则是直接以原文中的部分内容作为condition，来预测下文，CoCon的结构图如下：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042224458.png" alt="CoCon"></p> <p>然后为了训练这个模型，作者设计了多种自监督的loss：Self Reconstruction Loss, Null Content Loss, Cycle ReconstructionLoss,  Adversarial Loss. 核心思想就是<strong>使用文本的一部分作为condition，让模型对剩余部分进行复原，具体方法如下图</strong>：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042238096.png" alt="loss"></p> <p>最终也取得了比较优秀的控制效果，并且支持多个控制：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042251456.png" alt="image-20220404225113420"></p> <blockquote><p>上面列举的CTRL和CoCon的对NLG添加的实际上是比较soft的限制，并不强制要求模型一定要输出什么元素，而有一些工作则会使用hard的限制，要求模型必须输出给定的某些关键词：</p></blockquote> <p>代表性工作之一是<strong>POINTER</strong>[7]，出自MSR。POINTER的主要目的是训练根据指定词汇然后生成包含这些词汇的模型，采用的是一种基于插入的、渐进生成的方法：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204041829346.png" alt="POINTER progressive generation"></p> <p>POINTER的生成是一种迭代式地生成，先生成给定的关键词，然后每一轮都按照重要性不断插入新的词，直到把句子给补齐。POINTER中使用的一种Transformer结构叫做<strong>Insertion Transformer</strong>[8]，下图则展示了POINTER是如何渐进生成的：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042008258.png" alt="POINTER generation"></p> <p>类似的一个受限生成的工作是<strong>Constrained BART (CBART)</strong> [9]，来自香港大学，对BART进行了改造，通过在encoder上面添加一个token-level classifier来指导decoder在生成的时候应该进行replace还是insert，最终取得了比POINTER更好的效果:</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042256971.png" alt="CBART"></p> <h3 id="_3-保守派-post-process"><a href="#_3-保守派-post-process" class="header-anchor">#</a> 3. 保守派——Post-Process</h3> <p>保守派则认为，干嘛要这么麻烦，直接后处理不就完事儿了。</p> <p>最知名的工作，要数来自Uber AI的<strong>Plug and Play Language Models (PPLM)</strong>[11]了:</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042302900.png" alt="pplm"></p> <p>PPLM不希望去训练PLM，而是通过额外的一个attribute model来对PLM的输出加以修正，从而符合某种预期。这里的attribute model，既可以是一个bag of words来代表某个topic，也可以是一个训练好的小模型来对某个topic进行打分，然后通过这个attribute model向PLM的hidden states传递梯度，从而对hidden states进行一定的修正，然后PLM的输出就会往我们希望的topic倾斜了。</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042306328.png" alt="image-20220404230634300"></p> <p>基于PPLM，Stanford CS224N的一个project作业中，某学生提出了<strong>Ranked Keywords to Story Generation</strong>，该工作的目标是给定一个排序的关键词，让模型能够按照重要性在生成句子的时候把这些关键词都包括在内，具体则是在PPLM的基础上进行了改进：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042317839.png" alt="Ranked Keywords with PPLM"></p> <p>具体方式是构造<code>&lt;s&gt;keywords&lt;sep&gt;sentence</code>这样的语料，然后对GPT-2进行finetune，然后再利用PPLM的思想，使用改进的BoW的方法来控制生成，也得到了比较好的效果：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042320453.png" alt="image-20220404232021425"></p> <p><strong>MEGATRON-CNTRL</strong>[13]则选择利用外部知识库来辅助生成，给定一个context，MEGATRON-CNTRL会首先使用一个predictor生成一批关键词，然后通过一个retriever从知识库中找到跟这些关键词匹配的句子，然后通过一个ranker进行筛选，最后再输入PLM进行句子的生成：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042343004.png" alt="MEGATRON-CNTRL"></p> <p>还有工作比如<strong>PAIR</strong>[14]则是先生成一个包含关键词和位置信息的模板，然后对模板进行填空，从而进行控制性生成；<strong>GeDi</strong>[15]则是训练一个小型的discriminator来引导PLM的生成。</p> <p>终于把三个派别的代表方法都介绍了一遍，Survey中总结了这个表，方便大家查阅：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042347513.png" alt="image-20220404234720484"></p> <h2 id="三、evaluation"><a href="#三、evaluation" class="header-anchor">#</a> 三、Evaluation</h2> <p>具体见论文吧，不想写了。</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/202204042348945.png" alt="image-20220404234806920"></p> <h2 id="四、挑战-未来方向"><a href="#四、挑战-未来方向" class="header-anchor">#</a> 四、挑战，未来方向</h2> <p>一些不痛不痒的建议未来方向：</p> <ul><li>Prompt-based Learning</li> <li>Fine-grained Decoding Control</li> <li>Integration with Classic Generative Theory and Linguistic Knowledge</li> <li>Integration with Classic Generative Theory and Linguistic Knowledge</li> <li>Novel Evaluation Metrics and Methods</li> <li>New CTG tasks</li></ul> <h2 id="references"><a href="#references" class="header-anchor">#</a> -References:</h2> <p>[1] Exploring Controllable Text Generation Techniques (2020) <br>
[2] Technical report: Auxiliary tuning and its application to conditional text generation (2020) <br>
[3] DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation (ACL-20) <br>
[4] The Power of Scale for Parameter-Efficient Prompt Tuning (EMNLP-21) <br>
[5] Controllable Generation from Pre-trained Language Models via Inverse Prompting (KDD-21) <br>
[6] CTRL: A Conditional Transformer Language Model for Controllable Generation (2019) <br>
[7] POINTER: Constrained Text Generation via Insertion-based Generative Pre-training (EMNLP-20) <br>
[8] Insertion Transformer: Flexible Sequence Generation via Insertion Operations (2019) <br>
[9] Parallel Refinements for Lexically Constrained Text Generation with BART (EMNLP-21) <br>
[10] CoCon: A Self-Supervised Approach for Controlled Text Generation (ICLR-21) <br>
[11] Plug and Play Language Models: A Simple Approach to Controlled Text Generation (ICLR-20) <br>
[12] Ranked Keywords to Story Generation (2021, Stanford Student Project) <br>
[13] MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models (EMNLP-20) <br>
[14] PAIR: Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation （EMNLP-20） <br>
[15] GeDi: Generative Discriminator Guided Sequence Generation (EMNLP-21-findings)</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/79.f9a1e6f0.js" defer></script>
  </body>
</html>
