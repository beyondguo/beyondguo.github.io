<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>用Annoy和ThreadPool把相似度计算加速360倍 | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/46.1e480f1b.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link router-link-active">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link router-link-active">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>用Annoy和ThreadPool把相似度计算加速360倍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#_0-背景故事" class="sidebar-link">0. 背景故事</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#_1-想一劳永逸-那就把word2vec变成一个相似词词典" class="sidebar-link">1. 想一劳永逸，那就把Word2Vec变成一个相似词词典</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#_2-问题来了" class="sidebar-link">2. 问题来了...</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#_3-approximate-nearest-neighbors-oh-yeah-annoy" class="sidebar-link">3. Approximate Nearest Neighbors Oh Yeah ! (Annoy)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#annoy算法原理" class="sidebar-link">Annoy算法原理</a></li><li class="sidebar-sub-header"><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#annoy的问题" class="sidebar-link">Annoy的问题</a></li><li class="sidebar-sub-header"><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#在gensim中使用annoy-加速75倍" class="sidebar-link">在Gensim中使用Annoy，加速75倍</a></li></ul></li><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#_4-使用多线程-把cpu榨的一滴不剩" class="sidebar-link">4. 使用多线程，把CPU榨的一滴不剩</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#其他尝试" class="sidebar-link">其他尝试</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/engineering/notes/%E4%BD%BF%E7%94%A8Annoy%E5%92%8CThreadPool%E6%8A%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F400%E5%80%8D.html#后记" class="sidebar-link">后记</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="用annoy和threadpool把相似度计算加速360倍"><a href="#用annoy和threadpool把相似度计算加速360倍" class="header-anchor">#</a> 用Annoy和ThreadPool把相似度计算加速360倍</h1> <h2 id="_0-背景故事"><a href="#_0-背景故事" class="header-anchor">#</a> 0. 背景故事</h2> <p>我最近的一个项目中需要大量查询一个词的相似词，而无论是英文的WordNet，还是中文的同义词词林，都覆盖面太窄，我决定借助训练好的<strong>Word2Vec</strong>模型，使用<code>gensim</code>库，调用它经典的<code>.most_similar()</code>函数来进行相似词查询。而由于程序中需要大量查询相似词，所以就需要大量调用<code>.most_similar()</code>函数，而这，就成为了整个程序的瓶颈，因为：</p> <blockquote><p><code>.most_similar()</code>太慢了！</p></blockquote> <p>为什么它这么慢呢？因为这个<code>gensim</code>中查询相似词，默认是直接<strong>brute-force search</strong>，即我会把当前查询的词，跟词表里所有的词都计算一个相似度，然后给你排序返回。如果词典很大，词向量维度又很高，那这个计算代价是很大的！我还特地看了看<code>gensim</code>的源码（gensim/gensim/models/keyedvectors.py#L783）：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224110300717.png" alt="image-20220224110300717"></p> <p>可看到，这个<code>.most_similar()</code>函数内部，就是通过对当前向量（代码中的<code>mean</code>）去跟所有的<code>vectors</code>计算dot product，然后再排序返回。</p> <p>另外，虽然我们可以在每次跑程序的时候都维护一个词典，查询过的结果就直接保存，这对于当前程序是可以提升效率的，但是我之后<strong>再次运行程序，或者语料库改变了，那依然需要重新计算</strong>，所以必须想办法解决一下。</p> <h2 id="_1-想一劳永逸-那就把word2vec变成一个相似词词典"><a href="#_1-想一劳永逸-那就把word2vec变成一个相似词词典" class="header-anchor">#</a> 1. 想一劳永逸，那就把Word2Vec变成一个相似词词典</h2> <p>一个很直接的思路就是，既然我使用Word2Vec是为了查相似词，其他的功能不需要（比如我不需要获取向量），那么我可以把一个Word2Vec词向量模型，转化成一个相似词词典，这样通过一个现成的词典查询相似词，就比使用<code>.most_similar()</code>快得多了！</p> <p>于是我开开心心得写下了如下代码（针对一个100维，40万词的中文词向量）：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>keyedvectors <span class="token keyword">import</span> KeyedVectors
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token comment"># synonyms_words.vector为一个100维的中文词向量模型</span>
w2v_model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">&quot;weights/synonyms_words.vector&quot;</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> unicode_errors<span class="token operator">=</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>
<span class="token comment"># 获取该词向量的词汇表</span>
vocab <span class="token operator">=</span> w2v_model<span class="token punctuation">.</span>index_to_key

<span class="token comment"># 把所有词遍历一遍，查询最相似的15个词，并保存到词典</span>
similars_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword">for</span> w <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">:</span>
    similar_words <span class="token operator">=</span> <span class="token punctuation">[</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> pair <span class="token keyword">in</span> w2v_model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>w<span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> indexer<span class="token operator">=</span>indexer<span class="token punctuation">)</span><span class="token punctuation">]</span>
    similars_dict<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> similar_words
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>运行，耗时<strong>2小时20分钟</strong>。
基本上就是出去吃个晚饭，散个步，就跑完了，so easy~</p> <p>心想着，后面直接把项目程序中所有的<code>.most_similar(w)</code>，都替换成<code>similars_dict[w]</code>，速度直接起飞~舒服！</p> <p>（本文结束）</p> <p>...</p> <h2 id="_2-问题来了"><a href="#_2-问题来了" class="header-anchor">#</a> 2. 问题来了...</h2> <p>我本来确实以为就这么结束了，直到我对一个英文Word2Vec模型重复了上面的操作：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>keyedvectors <span class="token keyword">import</span> KeyedVectors
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token comment"># GoogleNews-vectors-negative300.bin为一个300维的英文词向量模型</span>
w2v_model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">&quot;weights/GoogleNews-vectors-negative300.bin&quot;</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> unicode_errors<span class="token operator">=</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>
<span class="token comment"># 获取该词向量的词汇表</span>
vocab <span class="token operator">=</span> w2v_model<span class="token punctuation">.</span>index_to_key

<span class="token comment"># 把所有词遍历一遍，查询最相似的15个词，并保存到词典</span>
similars_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword">for</span> w <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">:</span>
    similar_words <span class="token operator">=</span> <span class="token punctuation">[</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> pair <span class="token keyword">in</span> w2v_model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>w<span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> indexer<span class="token operator">=</span>indexer<span class="token punctuation">)</span><span class="token punctuation">]</span>
    similars_dict<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> similar_words
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>给大家看看进度条：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224111445169.png" alt="进度条1"></p> <p>预计用时<strong>150小时</strong>！天哪，为什么差别这么大？</p> <p>原来我前面那么轻松，是因为使用了一个较小的词向量模型：</p> <ul><li>100维，40万词——&gt; 2小时 （一次健身的时间）</li> <li>300维，300万词——&gt; 150小时（你可以去度一个假了，回来应该可以跑完吧）</li></ul> <p>我还试着用了一个线程池，发现依然需要80~100小时...</p> <p>怎么办？</p> <p>一看时间，已经8:00 PM了，开启多线程让这玩意儿跑着吧，明早过来看看能跑多少吧，溜了溜了~</p> <h2 id="_3-approximate-nearest-neighbors-oh-yeah-annoy"><a href="#_3-approximate-nearest-neighbors-oh-yeah-annoy" class="header-anchor">#</a> 3. Approximate Nearest Neighbors Oh Yeah ! (Annoy)</h2> <p>第二天中午来到实验室，打开电脑一看，跑了50万了，还有250万没跑完... 摸一摸主机，已经滚烫了，我的8核CPU哼哧哼哧了一晚上才跑了1/5的词，现在一定怨声载道了...</p> <p>我果断kill掉了程序，看着任务管理器缓缓下降的CPU利用率曲线，我和CPU们都进入了贤者时间。</p> <p>之前也了解过ANN算法，即近似最近邻算法，于是我开始在Google上搜索有关ANN和gensim的内容，终于，找到了这篇文章的主角——Annoy，而且我发现，gensim其实已经对Annoy做了封装，支持使用Annoy来进行加速。</p> <p>Annoy算法，是一种<strong>基于二叉树的近似最近邻算法</strong>，他的全称是：<strong>A</strong>pproximate Nearest <strong>N</strong>eighbors <strong>O</strong>h <strong>Y</strong>eah，别的不说，这个<strong>Oh Yeah</strong>直接让我对这个算法好感倍增。下面看看Annoy自己的介绍：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224121732634.png" alt="image-20220224121732634"></p> <p>看最后一句话：</p> <blockquote><p>Annoy算法是Erik这个老哥，在Spotify的Hack Week期间，花了几个下午的时候开发的。</p></blockquote> <p>你都可以想想那个场景，Erik在阳光的午后，边喝咖啡，边写代码，构思着一个巧妙的ANN算法，几天后他做到了，成功地发明了一种新的ANN算法，他高呼&quot;Oh Yeah!&quot;，遂取名ANNOY~（纯属个人遐想，请勿当真）</p> <h3 id="annoy算法原理"><a href="#annoy算法原理" class="header-anchor">#</a> Annoy算法原理</h3> <p>一个有追求的programmer，除了知道有这么个算法外，一定还想了解一下它背后的原理，所以我花了一天阅读Annoy作者的博客，找到YouTube上一些介绍的视频，配合一些代码一起理解，算是搞懂了Annoy的原理。下面我来简单讲解一下：</p> <p>（下面的一些图，引自Erik的博客）</p> <p>首先我们有一大堆点，每个点都是一个向量：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224150139702.png" alt="image-20220224150139702"></p> <p>然后，对于一个新的点，我们希望找到它的最近邻。</p> <p>然而，如果对全局都扫一遍，那复杂度就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>，这样如果我们的搜索量很大的话就太费劲了。</p> <blockquote><p>Annoy的核心思想就是：
<strong>把空间分割成一个个的子空间，且在子空间中的点都是彼此间比较接近的。那么对于一个新的点，我们只需要搜索它所在的子空间中的那些点，就可以找到它的近似的最近邻们。</strong></p></blockquote> <p>所以，Annoy最终实现的效果是这样的：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224150631474.png" alt="image-20220224150631474"></p> <p>图中红色叉叉就是新的点，整个空间已经被分成了很多个小区域，我们只需要在图中蓝色的那一小块搜索即可，这样，复杂度就大大大大降低了。</p> <blockquote><p>关键在于——如何划分空间？</p> <p>答案是使用随机投影（random projection）来构建二叉树（binary tree）。</p></blockquote> <p>回到最开始的散点图，我们先<strong>随机</strong>挑两个点，这两个点的正中间就确定了一个分割超平面：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224152019731.png" alt="image-20220224152019731"></p> <p>这样，就能将空间一分为二，所有的点，就都分配到一个子空间了。</p> <p>这里可能有人会问，在确定超平面之后，如何把所有点进行区间划分呢？是不是还是得把所有点都计算一遍距离，再确定呢？答案是“<strong>是的，我们需要做一个linear scan来确定归属</strong>”。为了确认，我查看作者Erik给出的一个示例代码（并非Annoy代码，Annoy使用C++写的，我还看不太明白，但作者为了展示Annoy算法的代码，也用python写了一个简单例子）：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224153529927.png" alt="image-20220224153529927"></p> <p>上述代码我画了一个图来表示，应该就很清楚了，所以不再赘述：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224155453628.png" alt="image-20220224155453628"></p> <p>好，接下来我们可以在每个子空间中，都使用类似的方法，继续划分，不断迭代这个过程（可设定一个超参数K，最多迭代K次）：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224153630328.png" alt="image-20220224153630328"></p> <p>如果我们把每个超平面当做一个树的分支，最终每个小区域中的点当做树的叶子节点，那么就可以得到一下的一棵树：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224153834856.png" alt="image-20220224153834856"></p> <p>有了这棵树之后，我们想搜索一个点的最近邻，就只用访问这棵树的一个分支即可，即使用上面说的那个确定一个点归属的算法，从root节点一直找到最下面的小分支，然后跟那个分支上的leaf节点逐一计算相似度，就完事儿了：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224160214015.png" alt="image-20220224160214015"></p> <p>这样，我们就将相似节点查询的复杂度都<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>降低到了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(logn)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>.</p> <h3 id="annoy的问题"><a href="#annoy的问题" class="header-anchor">#</a> Annoy的问题</h3> <p>很明显，我们可以知道上述的构件树并查询相似点的方法是不精确的，因为我们发现每个超平面，都是随机挑选两个点来确定的，这就导致很有可能有些相近的点，会被分开，而一旦分开，在树的搜索中很可能就被丢弃了。</p> <p>一个解决方法就是构建多棵树！形成一个森林！然后把所有树的结果进行平均，或者把所有树找到的最小区域进行合并：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224160810958.png" alt="image-20220224160810958"></p> <p>这样，就可以大大提升准确率。当然，还有一些其他技巧，比如使用priority queue等等，这里也不赘述了。</p> <p>研究了一天，终于把Annoy这优美的算法搞明白了，很是兴奋。晚上，老婆一直睡不着觉，想聊天，于是我绘声绘色地跟她讲解Annoy算法的原理，算法名称的来历，怎么诞生的...... 当我激动地完成了演讲，转头一看，老婆已经呼呼大睡~~</p> <p>第二天早上，我要求她复述这个算法的基本原理，她说：“Oh Yeah？”</p> <h3 id="在gensim中使用annoy-加速75倍"><a href="#在gensim中使用annoy-加速75倍" class="header-anchor">#</a> 在Gensim中使用Annoy，加速75倍</h3> <p>第三天，在搞懂了原理之后，终于开始动手了。幸运的是，Gensim早就为我们封装好了Annoy工具，所以我们可以直接使用：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>similarities<span class="token punctuation">.</span>annoy <span class="token keyword">import</span> AnnoyIndexer
indexer <span class="token operator">=</span> AnnoyIndexer<span class="token punctuation">(</span>w2v_model<span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>

similars_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword">for</span> w <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">:</span>
    similar_words <span class="token operator">=</span> <span class="token punctuation">[</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> pair <span class="token keyword">in</span> w2v_model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>w<span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> indexer<span class="token operator">=</span>indexer<span class="token punctuation">)</span><span class="token punctuation">]</span>
    similars_dict<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> similar_words
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>您猜怎么着？</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224162122864.png" alt="image-20220224162122864"></p> <p>300维向量，300万的词汇量，300万次查询，只要 <strong>2小时</strong>13分钟！记得在不使用Annoy indexer的情况下，上面代码需要跑150小时！（我们不用去度假啦，健个身代码就跑完啦~）所以这个Annoy足足把速度加速了75倍！</p> <p>一些细节需要说明：</p> <ul><li>首先需要构造Indexer，这时我们要指定构建多少棵树。上面例子中我构建了200棵，建树时间大概20分钟。树越多，结果越精确，但建树和查询的速度会变慢；</li> <li>我也测试了100或者500棵树，前者的相似度精度不够，后者则太慢（大概30~50小时？）</li></ul> <h2 id="_4-使用多线程-把cpu榨的一滴不剩"><a href="#_4-使用多线程-把cpu榨的一滴不剩" class="header-anchor">#</a> 4. 使用多线程，把CPU榨的一滴不剩</h2> <p>通过上面的方法，我们已经把耗时从150小时缩短到2小时了。</p> <p>然而，我的CPU们跃跃欲试，说“我们还可以为你做更多”。</p> <p>注意到，上面的代码中，我是通过for循环来遍历这个长度为300万的vocab词典，而这正好可以通过多线程来进行并发，因此我写下了如下代码：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> multiprocessing<span class="token punctuation">.</span>dummy <span class="token keyword">import</span> Pool <span class="token keyword">as</span> ThreadPool
<span class="token keyword">from</span> logger <span class="token keyword">import</span> logger
pool <span class="token operator">=</span> ThreadPool<span class="token punctuation">(</span><span class="token punctuation">)</span>

similars_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    similar_words <span class="token operator">=</span> <span class="token punctuation">[</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> pair <span class="token keyword">in</span> w2v_model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>w<span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> indexer<span class="token operator">=</span>indexer<span class="token punctuation">)</span><span class="token punctuation">]</span>
    similars_dict<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> similar_words
    c <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>similars_dict<span class="token punctuation">)</span>
    <span class="token keyword">if</span> c <span class="token operator">%</span> <span class="token number">10000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'already processed '</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">' items.'</span><span class="token punctuation">)</span>

logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'start'</span><span class="token punctuation">)</span>
<span class="token comment"># pool.map函数，可以把一个list中的所有item，分配到不同线程并行执行   </span>
pool<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>process<span class="token punctuation">,</span> vocab<span class="token punctuation">)</span>
pool<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
pool<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>这里主要使用到了<code>pool.map(process_for_item, your_list)</code>函数，这个函数可以使用你自定义的<code>process_for_item</code>函数，在多个线程中并行地对<code>your_list</code>中所有item进行处理，非常方便。</p> <p>查看输出：</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span><span class="token number">23</span>/Feb/2022 <span class="token number">20</span>:11:46<span class="token punctuation">]</span> INFO - start
<span class="token punctuation">[</span><span class="token number">23</span>/Feb/2022 <span class="token number">20</span>:11:51<span class="token punctuation">]</span> INFO - already processed <span class="token number">10000</span> items.
<span class="token punctuation">..</span>.
<span class="token punctuation">[</span><span class="token number">23</span>/Feb/2022 <span class="token number">20</span>:35:29<span class="token punctuation">]</span> INFO - already processed <span class="token number">2990000</span> items.
<span class="token punctuation">[</span><span class="token number">23</span>/Feb/2022 <span class="token number">20</span>:35:46<span class="token punctuation">]</span> INFO - already processed <span class="token number">3000000</span> items.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>总共耗时<strong>25分钟</strong>！！这是值得铭记的历史的一刻！</p> <p>至此，我们经历了将<strong>150小时</strong>，缩短到100小时（多线程），再缩短到<strong>2小时</strong>（Annoy近似搜索），最终缩短到25分钟（Annoy+多线程），将任务在我的单机上提速了<strong>360</strong>倍。</p> <h2 id="其他尝试"><a href="#其他尝试" class="header-anchor">#</a> 其他尝试</h2> <p>其实我还尝试过Faiss框架，使用<code>IndexFlatL2</code>作为quantizer，使用<code>IndexIVFFlat</code>作为indexer，使用nlist = 1000，nprobe = 10，结果对300万个query查询完毕，需要8小时。而且目测的效果，并没有比我前面使用Annoy的结果好，再加上这玩意儿调参困难，所以后面就没有继续尝试Faiss。</p> <p>根据ANN-benchmark：</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224165732371.png" alt="image-20220224165732371"></p> <p>Annoy算法算是一个中规中矩的，还算可以的算法。而Gensim还提供了NMSLIB算法支持，所以有兴趣的同学，可以把Annoy换成NMSLIB看看效果。</p> <h2 id="后记"><a href="#后记" class="header-anchor">#</a> 后记</h2> <p>—— “如果当初不做改进，让它占着电脑慢慢跑，你现在应该度假还没结束吧~”
—— “也许吧，可能我的假期还有100小时呢，哈哈”
—— “你高兴啥，度假不是更快乐吗？”
—— “那不是真正的快乐！” 我扶着发际线，骄傲的说
—— “... 那你的快乐是什么？”
—— “是我只用25分钟，把<code>.most_similar()</code>给加速了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>5</mn></msup></mrow><annotation encoding="application/x-tex">10^5</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span>倍~”</p> <p><img src="https://gitee.com/beyond_guo/typora_pics/raw/master/typora/image-20220224170852415.png" alt="真正的快乐"></p> <p>最后，拜谢以下资料，陪我走过这几天：</p> <ul><li><p>Annoy作者博客：https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html</p></li> <li><p>Annoy官方GitHub：https://github.com/spotify/annoy</p></li> <li><p>gensim上的Annoy支持：https://radimrehurek.com/gensim/similarities/annoy.html</p></li> <li><p>Ball-tree &amp; KD-tree：https://towardsdatascience.com/tree-algorithms-explained-ball-tree-algorithm-vs-kd-tree-vs-brute-force-9746debcd940 另外Wikipedia上的KD-tree也讲的非常好：https://en.wikipedia.org/wiki/K-d_tree</p></li> <li><p>Faiss Wiki：https://github.com/facebookresearch/faiss/wiki/Getting-started</p></li> <li><p>ANN算法benchmark：http://ann-benchmarks.com/index.html#algorithms</p></li> <li><p>python多线程并行：https://chriskiehl.com/article/parallelism-in-one-line</p></li> <li><p>Random Projection：https://medium.com/data-science-in-your-pocket/random-projection-for-dimension-reduction-27d2ec7d40cd</p></li> <li><p>CVPR20上一个关于ANN的分享：https://speakerdeck.com/matsui_528/cvpr20-tutorial-billion-scale-approximate-nearest-neighbor-search?slide=115</p></li></ul></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/46.1e480f1b.js" defer></script>
  </body>
</html>
