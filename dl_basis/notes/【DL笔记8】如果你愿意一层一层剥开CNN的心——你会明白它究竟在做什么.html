<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>【DL笔记8】如果你愿意一层一层剥开CNN的心——你会明白它究竟在做什么 | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/35.b804bcd7.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/40.51f0a3f5.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link router-link-active">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link router-link-active">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>【DL笔记8】如果你愿意一层一层剥开CNN的心——你会明白它究竟在做什么</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/dl_basis/notes/%E3%80%90DL%E7%AC%94%E8%AE%B08%E3%80%91%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%84%BF%E6%84%8F%E4%B8%80%E5%B1%82%E4%B8%80%E5%B1%82%E5%89%A5%E5%BC%80CNN%E7%9A%84%E5%BF%83%E2%80%94%E2%80%94%E4%BD%A0%E4%BC%9A%E6%98%8E%E7%99%BD%E5%AE%83%E7%A9%B6%E7%AB%9F%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88.html#一、cnn每一层都输出了什么玩意儿" class="sidebar-link">一、CNN每一层都输出了什么玩意儿</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/dl_basis/notes/%E3%80%90DL%E7%AC%94%E8%AE%B08%E3%80%91%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%84%BF%E6%84%8F%E4%B8%80%E5%B1%82%E4%B8%80%E5%B1%82%E5%89%A5%E5%BC%80CNN%E7%9A%84%E5%BF%83%E2%80%94%E2%80%94%E4%BD%A0%E4%BC%9A%E6%98%8E%E7%99%BD%E5%AE%83%E7%A9%B6%E7%AB%9F%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88.html#二、cnn的每一层的filters到底识别啥特征" class="sidebar-link">二、CNN的每一层的filters到底识别啥特征</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/dl_basis/notes/%E3%80%90DL%E7%AC%94%E8%AE%B08%E3%80%91%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%84%BF%E6%84%8F%E4%B8%80%E5%B1%82%E4%B8%80%E5%B1%82%E5%89%A5%E5%BC%80CNN%E7%9A%84%E5%BF%83%E2%80%94%E2%80%94%E4%BD%A0%E4%BC%9A%E6%98%8E%E7%99%BD%E5%AE%83%E7%A9%B6%E7%AB%9F%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88.html#三、更近一步-用deconvnet可视化filters" class="sidebar-link">三、更近一步，用Deconvnet可视化filters</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/dl_basis/notes/%E3%80%90DL%E7%AC%94%E8%AE%B08%E3%80%91%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%84%BF%E6%84%8F%E4%B8%80%E5%B1%82%E4%B8%80%E5%B1%82%E5%89%A5%E5%BC%80CNN%E7%9A%84%E5%BF%83%E2%80%94%E2%80%94%E4%BD%A0%E4%BC%9A%E6%98%8E%E7%99%BD%E5%AE%83%E7%A9%B6%E7%AB%9F%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88.html#综上面的所有之上" class="sidebar-link">综上面的所有之上</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="【dl笔记8】如果你愿意一层一层剥开cnn的心-你会明白它究竟在做什么"><a href="#【dl笔记8】如果你愿意一层一层剥开cnn的心-你会明白它究竟在做什么" class="header-anchor">#</a> 【DL笔记8】如果你愿意一层一层剥开CNN的心——你会明白它究竟在做什么</h1> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597845300-image.png" alt=""></p> <blockquote><p>一直以来，卷积神经网络对人们来说都是一个黑箱，我们只知道它识别图片准确率很惊人，但是具体是怎么做到的，它究竟使用了什么特征来分辨图像，我们一无所知。无数的学者、研究人员都想弄清楚CNN内部运作的机制，甚至试图找到卷积神经网络和生物神经网络的联系。2013年，纽约大学的Matthew Zeiler和Rob Fergus的论文Visualizing and Understanding Convolutional Neural Networks用可视化的方法揭示了CNN的每一层识别出了什么特征，也揭开了CNN内部的神秘面纱。之后，也有越来越多的学者使用各种方法将CNN的每一层的激活值、filters等等可视化，让我们从各个方面了解到CNN内部的秘密。今天这篇文章，将会带大家从多个角度看看CNN各层的功能。</p></blockquote> <h2 id="一、cnn每一层都输出了什么玩意儿"><a href="#一、cnn每一层都输出了什么玩意儿" class="header-anchor">#</a> 一、CNN每一层都输出了什么玩意儿</h2> <p>这个是最直接了解CNN每一层的方法，给一张图片，经过每一个卷积层，图片到底变成了啥。</p> <p>这里，我用Keras直接导入VGG19这个网络，然后我自己上传一张照片，让这个照片从VGG中走一遭，同时记录每一层的输出，然后把这个输出画出来。</p> <p>先引入必要的包：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> keras
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>applications<span class="token punctuation">.</span>vgg19 <span class="token keyword">import</span> VGG19
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> image
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>applications<span class="token punctuation">.</span>vgg19 <span class="token keyword">import</span> preprocess_input
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>现在引入把我男神的图片上传一下，用keras的图片处理工具把它处理成可以直接丢进网络的形式：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>img_path <span class="token operator">=</span> <span class="token string">'andrew.jpg'</span>
img <span class="token operator">=</span> image<span class="token punctuation">.</span>load_img<span class="token punctuation">(</span>img_path<span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
x <span class="token operator">=</span> image<span class="token punctuation">.</span>img_to_array<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x<span class="token punctuation">.</span>shape
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>我输入的图像：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597871670-image.png" alt=""></p> <p>然后，我们导入VGG模型，去掉FC层（就是把include_top设为FALSE），因为如果有FC层在的话，由于FC层神经元个数是固定的，所以网络的输入形状就有限制，就必须跟原来的网络的输入一模一样。但是卷积层不受输入形状的限制，因此我们只保留卷积层（和池化层）。</p> <p>VGG19有19个CONV或FC层，但是如果我们打印出所有层的话，会包括POOL层，所以不止19个。这里我取第2~20层的输出，作为我们研究的对象：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>base_model = VGG19(weights='imagenet',include_top=False)
# 获取各层的输出：
layer_outputs = [layer.output for layer in base_model.layers[2:20]]
# 获取各层的名称：
layer_names = []
for layer in base_model.layers[2:20]:
    layer_names.append(layer.name)
print(layer_names)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>注意，这里的输出还没有实际的值！只是一个壳子，当我们把图片输入到模型中之后，它才有值。</p> <p>然后我们组装我们新的模型：输入图片，同时输出各层的激活值：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code># 组装模型：
model = Model(inputs=base_model.input, outputs=layer_outputs)
# 将前面的图片数据x，输入到model中，得到各层的激活值activations：
activations = model.predict(x)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>就这么easy！（如果不太明白代码的含义，可以参见Keras文档。）</p> <p>这个activations里面，就装好了各层的所有的激活值。我们可以随便找一层的activation打印出来它的形状看看：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>print(activations[0].shape)

#输出：
#(1, 200, 300, 64)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>什么意思呢？
1，代表输入图片的个数，我们这里只输入了一个图片，所以是1；
200,300，代表图片的大小；
64，代表该层有多少个filters。
所以，相当于我们的这一层输出了64张单通道图片。</p> <p>好了，我们可以将每一层激活得到的图片打印出来看看了。
我们将每一层所有filters对应的图片拼在一起显示，代码如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import math
for activation,layer_name in zip(activations,layer_names):
    h = activation.shape[1]
    w = activation.shape[2]
    num_channels = activation.shape[3]
    cols = 16
    rows = math.ceil(num_channels/cols)
    img_grid = np.zeros((h*rows,w*cols))

    for c in range(num_channels):
        f_r = math.ceil((c+1)/cols)
        f_c = (c+1)if f_r==1 else (c+1-(f_r-1)*cols)
        img_grid[(f_r-1)*h:f_r*h,(f_c-1)*w:f_c*w ] = activation[0,:,:,c]


    plt.figure(figsize=(25,25))
    plt.imshow(img_grid, aspect='equal',cmap='viridis')
    plt.grid(False)
    plt.title(layer_name,fontsize=16)
plt.show()
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>这个代码感觉写的不大好。。。如果读者有更好的方法，也请麻烦告知。</p> <p>最后是输出了18张大图，由于版面限制，我这里就挑其中的一些来展示：</p> <h4 id="这个是很靠前的一层-block1-conv2"><a href="#这个是很靠前的一层-block1-conv2" class="header-anchor">#</a> 这个是很靠前的一层（block1_conv2）：</h4> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597886936-image.png" alt="block1_conv2"></p> <p>可以看到，里面很多图片都跟我们的输入图片很像。
如果我们放大仔细观察的话，比如：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597902154-image.png" alt=""></p> <p>可以发现，很多图片都是把原图片的 <strong>边缘勾勒了出来</strong>。因此，我们知道，<strong>该层主要的功能是边缘检测</strong>。</p> <blockquote><p>####这里再说一下我们分析的思路：
<strong>根据前面讲解的CNN的原理，我们知道，当filter和我们的原图像的对应部分越像，它们卷积的结果就会越大，因此输出的像素点就越亮！因此，我们可以通过分析输出图片哪些部分比较亮来得知，该层的filters的作用。</strong></p></blockquote> <p>所以，其实该层不光是“边缘检测”，还有一个功能——<strong>“颜色检测”</strong>。因为我还发现了很多这样的图片：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597909437-image.png" alt="颜色检测"></p> <p>这些图中的 <strong>高亮部分，都对应于原图片中的整块的颜色</strong>，因此我们可以推断 <strong>该层的部分filters具有检测颜色的功能</strong>。</p> <p>很有意思~</p> <h5 id="我们接着看中间的某一层-block2-conv2"><a href="#我们接着看中间的某一层-block2-conv2" class="header-anchor">#</a> 我们接着看中间的某一层（block2_conv2）：</h5> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597922845-image.png" alt="block2_conv2"></p> <p>还是放大看一看：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597934390-image.png" alt=""></p> <p>这一层似乎复杂了很多，因为我们搞不清楚这些高亮的部分是一种什么特征，似乎是某种纹路。因此，和前面那个很浅的层相比，这一层提取的特征就没那么直白了。</p> <h5 id="我们接着再看一个很深的层"><a href="#我们接着再看一个很深的层" class="header-anchor">#</a> 我们接着再看一个很深的层：</h5> <p>(图太大，我截取部分)</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597944758-image.png" alt="深层"></p> <p>这大概是VGG的第十几层吧，由于经过反复的卷积，图片大小会缩小，因此越来越“像素化”，这个时候，我们可以把这些激活图片，跟原图片去对比，看看原图片哪些部分被激活了：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597957126-image.png" alt=""></p> <p>从这个图可以看到，<strong>Andrew整个上半身都被激活了。</strong>
再看看这个：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597968730-image.png" alt=""></p> <p>Andrew的 <strong>手部被激活了。</strong>
更多的例子等大家自己去尝试。
我们由此可以合理的推测，该层，<strong>已经可以将一些较复杂的东西作为特征来识别了</strong>，比如“手”、“身体”等等。这些特征比前面浅层的“边缘”、“颜色”等特征高级了不少。</p> <p>为了让大家更全面地看到各层的状态， 我从每层中调了一张图片排在一起打印出来：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597978361-image.png" alt="各层输出的演变"></p> <blockquote><p>综上：
随着CNN的层数增加，每一层的输出图像越来越抽象，这意味着我们的filters在变得越来越复杂；我们可以很合理地推断，随着CNN的深入，网络层学得的特征越来越高级和复杂。</p></blockquote> <h2 id="二、cnn的每一层的filters到底识别啥特征"><a href="#二、cnn的每一层的filters到底识别啥特征" class="header-anchor">#</a> 二、CNN的每一层的filters到底识别啥特征</h2> <p>在上面，我们已经知道了每一层的输出是什么样子，并且由此推测每一层的filters越来越复杂。于是，我们就想进一步地探索一下，这些filters，到底在识别些什么，到底长啥样？</p> <p>这里就有一个大问题：
比如VGG，我们前面讲过这是一个十分规则的网络，所有的filter大小都是3×3。这么小的玩意儿，画出来根本看不出任何猫腻。所有无法像我们上面画出每一层的激活值一样来分析。</p> <p>那么怎么办呢？
我们依然可以用刚刚的思路来分析：</p> <blockquote><p>当输入图片与filter越像，他们的卷积输出就会越大。因此，给CNN喂入大量的图片，看看哪个的输出最大。但这样可行度不高，可以换个思路：<strong>我们可以直接输入一个噪音图片，用类似梯度下降的方法来不断更新这个图片，使得我们的输出结果不断增大，那么这个图片就一定程度上反映了filter的模样。</strong></p></blockquote> <p>这里实际上不是用 <strong>梯度下降</strong>，而是用 <strong>梯度上升</strong>，因为我们要求的是一个极大值问题，而不是极小值问题。</p> <p><strong>梯度下降</strong>的更新参数w的过程，就是
<strong>w--&gt;w-α·dw</strong>，其中α是学习率，dw是损失对w的梯度。
<strong>梯度上升</strong>是类似的，是更新输入x，更新的方向变了：
<strong>x--&gt;x+s·dx</strong>，其中s代表步长，与α类似，dx是激活值对x的梯度。</p> <p>所以，我们可以仿照梯度下降法，来构造梯度上升算法。
<strong>具体方法和代码可以参见keras的发明者Fchollet亲自写的教程</strong>：
<a href="https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb" target="_blank" rel="noopener noreferrer">visualizing what convnets learn<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>这里我展示一下从浅到深的5个卷积层的filters的模样（注意，这个不是真的filters，而是输入图片，因为这个输入图片与filters的卷积结果最大化了，所以我们这里用输入图片的模样来代表filters的模样）：</p> <hr> <p><strong>【预警：图片可能引起密恐者不适】</strong></p> <hr> <h4 id="block1-conv3"><a href="#block1-conv3" class="header-anchor">#</a> block1-conv3：</h4> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597996309-image.png" alt=""></p> <p>这一层，<strong>印证了我们之前的推断</strong>：这个很靠近输入的浅层的filters的功能，就是 <strong>“边缘检测”和“颜色检测”</strong>。</p> <p>可能还是有同学不大明白，毕竟这个问题我也想了好久，<strong>为什么图片会这么密密麻麻的</strong>，看的让人瘆得慌？因为这个不是真的filter！filter大小只有3×3，而这些图片的大小都是我们设置的输入图片大小150×150，加入我们的某个filter是检测竖直边缘，那么输入图片要使卷积的结果最大，必然会到处各个角落都长满竖直的条条，所以我们看到的图片都是密密麻麻的某种图案的堆积。</p> <h4 id="block2-conv3"><a href="#block2-conv3" class="header-anchor">#</a> block2-conv3：</h4> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598005758-image.png" alt=""></p> <h4 id="block3-conv3"><a href="#block3-conv3" class="header-anchor">#</a> block3-conv3：</h4> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598011655-image.png" alt=""></p> <p>到了这一层，我开始看到各种较为 <strong>复杂的图案</strong>了，比如<strong>螺旋、波浪、方块、像眼睛一样的形状、像屋顶的砖瓦那样的形状</strong>······因缺思厅~</p> <h4 id="block4-conv3"><a href="#block4-conv3" class="header-anchor">#</a> block4-conv3：</h4> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598022356-image.png" alt=""></p> <h4 id="block5-conv3"><a href="#block5-conv3" class="header-anchor">#</a> block5-conv3：</h4> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598032613-image.png" alt=""></p> <p>到了这个比较深的层，我们发现，图片的图案更加复杂了，似乎是 <strong>前面那些小图案组成的大图案</strong>，比如有类似 <strong>麻花的形状</strong>，有类似 <strong>蜘蛛网</strong>的形状，等等，我们直接说不出来，但是明显这些filters识别的特征更加高级了。由于我只选取了部分的filters可视化，所以这里看不到更多的图案，也许把该层的几百个filters都打印出来，我们可以找到一些像虫子、手臂等东西的图案。</p> <p>同时我们发现，<strong>越到深层，图片这种密密麻麻的程度就会降低</strong>，因为越到深层，filters对应于原图像的 <strong>视野就会越大</strong>，所以特征图案的范围也会越大，因此不会那么密集了。</p> <p>另外，如果细心的话，我们可以注意到，<strong>越到深层，filters越稀疏</strong>，表现在图中就是像这种失效图片越来越多：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598042594-image.png" alt="失效图片"></p> <p>这些图片就是纯噪音，也就是根本没有激活出什么东西。具体原因我还不太清楚，等日后查清楚了再补充。但从另一个侧面我们可以理解：越深层，filters的数目往往越多，比如我们这里的block1-conv3，只有64个filters，但是最后一层block5-conv3有多达512个filters，所以有用的filters必然会更加稀疏一些。</p> <blockquote><p>综上：
我们现在可以明白（刚刚是推断），CNN的浅层的filters一般会检测“边缘”、“颜色”等最初级的特征，之后，filters可以识别出各种“纹理纹路”，到深层的时候，filters可以检测出类似“麻花”、“蜘蛛”等等由前面的基础特征组成的图案。</p></blockquote> <h2 id="三、更近一步-用deconvnet可视化filters"><a href="#三、更近一步-用deconvnet可视化filters" class="header-anchor">#</a> 三、更近一步，用Deconvnet可视化filters</h2> <p>在CNNs可视化中最有名的的论文当属我们文首提到的：
<a href="https://arxiv.org/pdf/1311.2901v3.pdf" target="_blank" rel="noopener noreferrer">Matthew D. Zeiler and Rob Fergus:Visualizing and Understanding
Convolutional Networks.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
无论是吴恩达上深度学习还是李飞飞讲计算机视觉，都会引用这个论文里面的例子，有空推荐大家都去看看这个论文。</p> <p>我看了好久不太懂，但是写完上面的“第一部分”之后，我似乎理解了作者的思路。</p> <p>我们回到我们在“一”中得到的某个深层的激活值：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598067644-image.png" alt="某层的激活结果"></p> <p>然后，我试着把原图贴上去，看看它们哪些地方重合了：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598081853-image.png" alt="看看哪里被激活了"></p> <p>当时，我们惊喜地发现，“上半身”、“手”、“Ng”被精准地激活了。</p> <p>而上面那篇论文的作者，正是沿着 <strong>“将激活值与输入图片对应”这种思路（我的猜测）</strong>，利用 <strong>Deconvnet</strong>这种结构，<strong>将激活值沿着CNN反向映射到输入空间，并重构输入图像</strong>，从而更加清晰明白地知道filters到底识别出了什么。
可以说，这个思路，正式我们上面介绍的“一”、“二”的结合！</p> <p>我画一个草图来说明：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598094842-image.png" alt="将特征反向映射到输入图像"></p> <p>我这个草图相当地“草”，只是示意一下。
具体的方法，其实是将原来的CNN的顺序完全反过来，但是组件不变（即filters、POOL等等都不变），如 <strong>原来的顺序是：</strong>
input--&gt;Conv--&gt;relu--&gt;Pool--&gt;Activation
<strong>现在就变成了：</strong>
Activation--&gt;UnPool--&gt;relu--&gt;DeConv--&gt;input</p> <p>这里的UNPool和DeConv，是对原来的Pool和conv的逆操作，这里面的细节请翻阅原论文，对于DeConv这个操作，我还推荐看这个：
https://arxiv.org/abs/1603.07285</p> <p>其实说白了，Conv基本上是把一个大图（input）通过filter变成了小图（activation），DeConv就反过来，从小图（activation）通过filter的转置再变回大图（input）：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598110490-image.png" alt="Conv和DeConv"></p> <p>于是，我们把每一层的激活值中挑选最大的激活值，通过Deconvnet传回去，映射到输入空间重构输入图像。这里，我直接把论文中的结论搬出来给大家看看：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598132451-image.png" alt=""></p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598137693-image.png" alt=""></p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624598144996-image.png" alt=""></p> <p>左边这些灰色的图案就是我们激活值通过DeConvnet反向输出的，右边的是跟左边图案对应的原图案的区域。</p> <p>我们可以看出，第一层，filters识别出了各种边缘和颜色，
第二层识别出了螺旋等各种纹路；
第三层开始识别出轮胎、人的上半身、一排字母等等；
第四层，已经开始识别出狗头、鸟腿；
第五层城市直接识别出自行车、各种狗类等等完整的物体了！</p> <p>其实我们发现这个跟我们在“二”中得到的似乎很像，但是 <strong>这里得到的图案是很具体的</strong>，而“二”中得到的各层的图案很抽象。这是因为，在这里，我们不是讲所有的激活值都映射回去，而是挑选最突出的某个激活值来进行映射，而且，在“二”中，我们是从一个噪音图像来生成图案使得激活值最大（存在一个训练的过程），而这里是直接用某个具体图片的激活值传回去重构图片，因此是十分具体的。</p> <hr> <h2 id="综上面的所有之上"><a href="#综上面的所有之上" class="header-anchor">#</a> 综上面的所有之上</h2> <p>CNNs的各层并不是黑箱，每一层都有其特定个功能，分工明确。从浅到深，CNN会逐步提取出边缘、颜色、纹理、各种形状的图案，一直到提取出具体的物体。
也就是说，CNNs在训练的过程中，自动的提取了我们的任务所需要的各种特征：
<strong>这些特征，越在浅层，越是普遍和通用；
越在深层，就越接近我们的实际任务场景。</strong>
因此，我们可以利用以及训练好的CNNs来进行 <strong>迁移学习（transfer learning）</strong>，也就是直接使用CNNs已经训练好的那些filters（特征提取器），来提取我们自己数据集的特征，然后就可以很容易地实现分类、预测等等目的。</p> <hr> <p>参考资料：
<a href="https://arxiv.org/pdf/1311.2901v3.pdf" target="_blank" rel="noopener noreferrer">1.Matthew D. Zeiler and Rob Fergus:Visualizing and Understanding
Convolutional Networks.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://arxiv.org/abs/1603.07285" target="_blank" rel="noopener noreferrer">2.A guide to convolution arithmetic for deep learning<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb" target="_blank" rel="noopener noreferrer">3.Visualizing what convnets learn<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/35.b804bcd7.js" defer></script>
  </body>
</html>
