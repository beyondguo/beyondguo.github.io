<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>神经网络的前世今生 | 郭必扬的写字楼</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-alpha/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/img/logo_no_words.png">
    <script>
    var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?5aca48f844181444aea941eb9d707584";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
    </script>
    <meta name="description" content="欢迎光临写字楼，大楼尚在施工中🚧，对您造成的不便请您谅解">
    
    <link rel="preload" href="/assets/css/0.styles.29dce6f0.css" as="style"><link rel="preload" href="/assets/js/app.41fc4255.js" as="script"><link rel="preload" href="/assets/js/2.a266bdc2.js" as="script"><link rel="preload" href="/assets/js/40.51f0a3f5.js" as="script"><link rel="prefetch" href="/assets/js/10.4ee4705c.js"><link rel="prefetch" href="/assets/js/100.29306973.js"><link rel="prefetch" href="/assets/js/101.b7851f01.js"><link rel="prefetch" href="/assets/js/102.969e84bd.js"><link rel="prefetch" href="/assets/js/103.a356b143.js"><link rel="prefetch" href="/assets/js/104.51024b34.js"><link rel="prefetch" href="/assets/js/105.43f26204.js"><link rel="prefetch" href="/assets/js/106.c52df18d.js"><link rel="prefetch" href="/assets/js/107.856c79a2.js"><link rel="prefetch" href="/assets/js/108.bfb45b71.js"><link rel="prefetch" href="/assets/js/11.e2907ec5.js"><link rel="prefetch" href="/assets/js/12.65ea25ed.js"><link rel="prefetch" href="/assets/js/13.cbd5d07c.js"><link rel="prefetch" href="/assets/js/14.b84744eb.js"><link rel="prefetch" href="/assets/js/15.aadcc6a8.js"><link rel="prefetch" href="/assets/js/16.db45b326.js"><link rel="prefetch" href="/assets/js/17.7b58bd1b.js"><link rel="prefetch" href="/assets/js/18.38d69ee8.js"><link rel="prefetch" href="/assets/js/19.4e5ae4a8.js"><link rel="prefetch" href="/assets/js/20.7095c920.js"><link rel="prefetch" href="/assets/js/21.242fa291.js"><link rel="prefetch" href="/assets/js/22.5d8fafb1.js"><link rel="prefetch" href="/assets/js/23.7ce40eb4.js"><link rel="prefetch" href="/assets/js/24.18bba9ed.js"><link rel="prefetch" href="/assets/js/25.5d7dc814.js"><link rel="prefetch" href="/assets/js/26.a658bfa8.js"><link rel="prefetch" href="/assets/js/27.67a75243.js"><link rel="prefetch" href="/assets/js/28.f618d912.js"><link rel="prefetch" href="/assets/js/29.cebd6470.js"><link rel="prefetch" href="/assets/js/3.56cdaf41.js"><link rel="prefetch" href="/assets/js/30.8b95a1f1.js"><link rel="prefetch" href="/assets/js/31.c91ff346.js"><link rel="prefetch" href="/assets/js/32.b98ca641.js"><link rel="prefetch" href="/assets/js/33.d0d05ad0.js"><link rel="prefetch" href="/assets/js/34.4c521488.js"><link rel="prefetch" href="/assets/js/35.b804bcd7.js"><link rel="prefetch" href="/assets/js/36.5c07cfef.js"><link rel="prefetch" href="/assets/js/37.a0565011.js"><link rel="prefetch" href="/assets/js/38.b8ae16d0.js"><link rel="prefetch" href="/assets/js/39.ac23927e.js"><link rel="prefetch" href="/assets/js/4.b9abaf2a.js"><link rel="prefetch" href="/assets/js/41.c1a8242a.js"><link rel="prefetch" href="/assets/js/42.749efe23.js"><link rel="prefetch" href="/assets/js/43.624833c8.js"><link rel="prefetch" href="/assets/js/44.bbddd63e.js"><link rel="prefetch" href="/assets/js/45.d8d15651.js"><link rel="prefetch" href="/assets/js/46.1e480f1b.js"><link rel="prefetch" href="/assets/js/47.4f1075d4.js"><link rel="prefetch" href="/assets/js/48.a8f6c2ba.js"><link rel="prefetch" href="/assets/js/49.106d8698.js"><link rel="prefetch" href="/assets/js/5.1c0b46f4.js"><link rel="prefetch" href="/assets/js/50.a0819973.js"><link rel="prefetch" href="/assets/js/51.cb93eaba.js"><link rel="prefetch" href="/assets/js/52.69fe7f19.js"><link rel="prefetch" href="/assets/js/53.ad8f6842.js"><link rel="prefetch" href="/assets/js/54.c25909c5.js"><link rel="prefetch" href="/assets/js/55.833154c7.js"><link rel="prefetch" href="/assets/js/56.75e06106.js"><link rel="prefetch" href="/assets/js/57.f5b5d514.js"><link rel="prefetch" href="/assets/js/58.574fd406.js"><link rel="prefetch" href="/assets/js/59.d07a17b6.js"><link rel="prefetch" href="/assets/js/6.4b4de84d.js"><link rel="prefetch" href="/assets/js/60.ee946b2f.js"><link rel="prefetch" href="/assets/js/61.68581797.js"><link rel="prefetch" href="/assets/js/62.99d168fd.js"><link rel="prefetch" href="/assets/js/63.14c4cfa2.js"><link rel="prefetch" href="/assets/js/64.61b2d608.js"><link rel="prefetch" href="/assets/js/65.f7077be9.js"><link rel="prefetch" href="/assets/js/66.0ce2a0ec.js"><link rel="prefetch" href="/assets/js/67.ee0094b6.js"><link rel="prefetch" href="/assets/js/68.c61d0f9f.js"><link rel="prefetch" href="/assets/js/69.c59f3168.js"><link rel="prefetch" href="/assets/js/7.ea2aa07c.js"><link rel="prefetch" href="/assets/js/70.21ea68bf.js"><link rel="prefetch" href="/assets/js/71.11355b09.js"><link rel="prefetch" href="/assets/js/72.cdc4bc45.js"><link rel="prefetch" href="/assets/js/73.d8946aed.js"><link rel="prefetch" href="/assets/js/74.75a2fd5c.js"><link rel="prefetch" href="/assets/js/75.14d3ef7d.js"><link rel="prefetch" href="/assets/js/76.3f73a91e.js"><link rel="prefetch" href="/assets/js/77.0018ed7f.js"><link rel="prefetch" href="/assets/js/78.c471326e.js"><link rel="prefetch" href="/assets/js/79.f9a1e6f0.js"><link rel="prefetch" href="/assets/js/8.f25633c9.js"><link rel="prefetch" href="/assets/js/80.a8c296e0.js"><link rel="prefetch" href="/assets/js/81.f6451a8b.js"><link rel="prefetch" href="/assets/js/82.f7393e31.js"><link rel="prefetch" href="/assets/js/83.a0642cbd.js"><link rel="prefetch" href="/assets/js/84.f2c12c65.js"><link rel="prefetch" href="/assets/js/85.f0077176.js"><link rel="prefetch" href="/assets/js/86.4180d39a.js"><link rel="prefetch" href="/assets/js/87.04e4ab18.js"><link rel="prefetch" href="/assets/js/88.93ea241c.js"><link rel="prefetch" href="/assets/js/89.555a3ba8.js"><link rel="prefetch" href="/assets/js/9.9aae1341.js"><link rel="prefetch" href="/assets/js/90.0701a493.js"><link rel="prefetch" href="/assets/js/91.8347eb90.js"><link rel="prefetch" href="/assets/js/92.9320e5ec.js"><link rel="prefetch" href="/assets/js/93.87dec14c.js"><link rel="prefetch" href="/assets/js/94.7a4ce357.js"><link rel="prefetch" href="/assets/js/95.060612ac.js"><link rel="prefetch" href="/assets/js/96.0b640400.js"><link rel="prefetch" href="/assets/js/97.5572d4ae.js"><link rel="prefetch" href="/assets/js/98.e013c8af.js"><link rel="prefetch" href="/assets/js/99.867ed389.js">
    <link rel="stylesheet" href="/assets/css/0.styles.29dce6f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo_no_words.png" alt="郭必扬的写字楼" class="logo"> <span class="site-name can-hide">郭必扬的写字楼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link router-link-active">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/dl_basis/" class="nav-link router-link-active">
  深度学习笔记
</a></div><div class="nav-item"><a href="/nlp_basis/" class="nav-link">
  NLP笔记
</a></div><div class="nav-item"><a href="/paper_notes/" class="nav-link">
  吃点儿论文
</a></div><div class="nav-item"><a href="/engineering/" class="nav-link">
  工程
</a></div><div class="nav-item"><a href="/opinions/" class="nav-link">
  随笔
</a></div><div class="nav-item"><a href="/about/" class="nav-link">
  Me
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="在别处~" class="dropdown-title"><span class="title">在别处~</span> <span class="arrow down"></span></button> <button type="button" aria-label="在别处~" class="mobile-dropdown-title"><span class="title">在别处~</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/beyondguo" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://mp.weixin.qq.com/s/v35g-p7wK2MkuM-SqjkF3g" target="_blank" rel="noopener noreferrer" class="nav-link external">
  微信公众号「SimpleAI」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.zhihu.com/people/guo-bi-yang-78" target="_blank" rel="noopener noreferrer" class="nav-link external">
  知乎「蝈蝈」
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://www.jianshu.com/u/f4fe92da869c" target="_blank" rel="noopener noreferrer" class="nav-link external">
  简书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>神经网络的前世今生</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/dl_basis/notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F.html#一、传统机器学习对付分类问题" class="sidebar-link">一、传统机器学习对付分类问题</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/dl_basis/notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F.html#_1-logistic-regression-二分类-和softmax-多分类" class="sidebar-link">1.Logistic Regression(二分类)和Softmax(多分类)</a></li><li class="sidebar-sub-header"><a href="/dl_basis/notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F.html#_2-损失函数" class="sidebar-link">2.损失函数</a></li></ul></li><li><a href="/dl_basis/notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F.html#二、神经网络登场" class="sidebar-link">二、神经网络登场</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/dl_basis/notes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F.html#_3-卷积神经网络" class="sidebar-link">3.卷积神经网络</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="神经网络的前世今生"><a href="#神经网络的前世今生" class="header-anchor">#</a> 神经网络的前世今生</h1> <blockquote><p>From Logistic regression to Neural netword</p></blockquote> <blockquote><p>提纲：</p> <ul><li><p><strong>传统的机器学习来做分类问题</strong></p> <ol><li>Logistic/Softmax regression</li> <li>上述算法的决策边界</li> <li>用什么损失函数</li></ol></li> <li><p><strong>神经网络的本质剖析</strong></p> <ol><li>从Logistic regression到神经网络</li> <li>前向传播和反向传播</li> <li>训练的注意事项（参数初始化、优化方法）</li> <li>从神经网络的角度看Word2Vec</li></ol></li> <li><p><strong>卷积神经网络什么鬼</strong>
......</p></li></ul></blockquote> <h2 id="一、传统机器学习对付分类问题"><a href="#一、传统机器学习对付分类问题" class="header-anchor">#</a> 一、传统机器学习对付分类问题</h2> <h3 id="_1-logistic-regression-二分类-和softmax-多分类"><a href="#_1-logistic-regression-二分类-和softmax-多分类" class="header-anchor">#</a> 1.Logistic Regression(二分类)和Softmax(多分类)</h3> <p>LR我们一般之前都接触过，就是一个用W、b对X进行线性表示，然后再通过一个非线性的激活函数输出预测值。
曾经我突然有一个问题：“不是有一个非线性的激活函数吗？为什么还是只能进行线性的分类？”
这个问题说明了我对Logistic regression 的理解十分肤浅，对分类问题的本质还是不了解。
所以我重新回顾了一下分类问题的本质是什么。</p> <p>假设我们的两个类别在图上表示为：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614639802-image.png" alt=""></p> <p><strong>思路是什么：</strong></p> <ol><li>首先观察不同类别的点的分布情况</li> <li>找到分割开不同类别的方法（寻找切平面）</li> <li>拟合切平面</li></ol> <p>图上的两个类，可以大致用一条直线分隔开来，我们设这个直线可以表示为：</p> <p><strong>Z = W·X + b</strong></p> <p>我们希望能够求得这条直线，或者说，想求出W和b。这样的话，WX+b&gt;0和WX+b&lt;0就可以吧原来的两个类给区分开了。见下图：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614646691-image.png" alt=""></p> <p>怎么学习这条直线呢？我们可以使用所有训练样本的点到直线的距离作为衡量指标，让距离尽可能大。也就是我们的最小二乘法。</p> <p>但是，如果我们希望得到的结果是一个概率，即预测一个点属于各个类别的概率分布式多少。拿我们应该怎么办呢？
这个时候，我们就可以采用<strong>sigmoid函数</strong>。</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614654181-image.png" alt=""></p> <p>从sigmoid函数的图像可以看出，它可以把一个输入压缩到0-1之间，并且是一个中心对称图形，可以很好地拟合一个概率分布。比方我们希望某个点，属于第一类的概率为0.7，属于第二类的概率为0.3.这样似乎更符合实际一些，没那么武断。</p> <p>我们把上面的<strong>Z = W·X + b</strong>作为sigmoid的输入，输出为y，则当Z&gt;0时，y&gt;0.5;当Z&lt;0时，y&lt;0.5。我们可以发现这样的结构很合理：</p> <blockquote><p>对于那些靠近直线<strong>Z = W·X + b</strong>的点，本来类别就比较模糊，如果直接用Z的符号来判断类别，就不大好。但是，这些靠近直线的点，由于Z的值和接近0，所以通过sigmoid输出的概率值也接近0.5，我们就可以看出那些点的分类的把握不是很大，这样就十分合理。</p></blockquote> <p>上面说的这些，就是所谓的<strong>Logistic Regression</strong>，表达式就是：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Z = W·X + b
y = σ(Z)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这样，我们的输出就是一个概率分布了。</p> <p>上面讲的问题是一个<strong>二分类问题</strong>，那对于<strong>多分类</strong>我们怎么办呢？</p> <p>多分类，可以转化为多个二分类，即学习多条直线的W和b：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614663566-image.png" alt=""></p> <p>图中，每一条直线，都是用于把对应的类和其他所有的类分开，这样，有几类，就需要几条直线。
设类别为i，则每一条直线可以表示为：<strong>Zi = Wi·X + bi</strong>。这里的Wi和前面的W形状一样。</p> <p>如何获得多个类别的概率分布呢？用sigmoid函数是肯定没办法了。这个时候，Softmax函数就闪亮登场了。</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614671453-image.png" alt=""></p> <p>可以很容易地看到，每一类的pi加起来就是1，于是就形成了一个多类别的概率分布。</p> <p>再回头看，为什么是决策边界都是线性的？因为我们<strong>预设分割边界就是线性的呀</strong>！**而sigmoid和Softmax这些非线性函数，只是起到概率分布转换的作用！**所以，决策边界自然是线性的。那个问题不攻自破了。</p> <p>传统机器学习的方法怎么解决非线性问题呢？————<strong>SVM</strong></p> <p>上面介绍了Logistic/Softmax Regression，但是问题还没完，损失函数还没设定呢，那么我们应该怎么设定损失函数呢？</p> <h3 id="_2-损失函数"><a href="#_2-损失函数" class="header-anchor">#</a> 2.损失函数</h3> <p>开门见山吧，这里我们使用**“交叉熵（Cross-entropy）”**。主要是我们要了解，这个交叉熵到底是什么玩意儿，为什么用这种形式，以及能否用其他的损失函数？</p> <p>熵的概念来源于信息论，<strong>熵说白了就是信息量</strong>。在信息论中，一件事的信息量是怎么衡量的呢？</p> <p>假设事件A发生的概率为p，则定义熵(信息量)为</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614680066-image.png" alt=""></p> <p>可以发现，概率p越大，熵就越小，信息量就越小。为啥呢？细细想一想也很自然，概率很大的事情，就很确定，那就跟地球是圆的一样，没什么信息量。而概率小的事情，因为不确定性很大，有很多种可能，所以信息量就大，就比如说“地球是平的”，会蕴含很多的信息。</p> <p>那现在我们有一堆样本X=[x1,x2,...,xn]，概率分布是p(x1),p(x2),...,p(xn).那么这些样本蕴含的<strong>平均信息量/平均熵</strong>是多大呢？很简单，求平均：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614689257-image.png" alt=""></p> <p>明白了上面的内容，我们接下来看一下，如果有两个概率分布p和q，怎么衡量这两个概率分布之间的差异呢？这里就使用<strong>KL散度</strong>：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614695623-image.png" alt=""></p> <p>把KL散度分解一下，可以得到：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614704551-image.png" alt=""></p> <p>可以看到，左边的部分就是前面的概率分布p的信息量，剩下的右边的部分，就是我们传说中的<strong>交叉熵</strong>：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614715421-image.png" alt=""></p> <p>回到我们的机器学习中，假设我们样本的真实概率分布是p，我们通过模型预测出来的概率分布是q，那么我们的损失函数，就可以使用KL散度。而因为真实概率分布p是固定的，所以KL散度的第一项-H(p(x))是一个定值，可以省去，所以我们就可以只用交叉熵来作为损失函数了，它就是衡量了我们的预测分布q与真实分布p的差距。</p> <p>所以，一般对于这种输出概率分布的模型，我们都采用交叉熵来作为损失函数。</p> <blockquote><p><strong>Cross-entropy VS. MSE</strong></p></blockquote> <p>有人问，不是还有一个著名的MSE(Mean Square Error)吗？也是经常作为回归问题的目标函数呀，它和ACE（Average Cross Entropy）比起来孰优孰劣呢？</p> <p>它俩的差别其实不大，都是常用的损失函数。但是在Logistic regression以及神经网络中，我们更常使用的还是ACE。原因主要体现在<strong>求导、更新参数</strong>的过程中：</p> <p>大家不妨手推一下使用MSE和ACE对参数W进行求导的公式，大致推一推便可以发现：</p> <ul><li><strong>MSE对W的导数，正比于sigmoid的导数</strong>，而根据sigmoid的图像可知，随着我们的训练的进行，预测值y会越来越接近0或者1，sigmoid的导数越来越小，这样会导致在梯度下降法中参数更新的速度越来越慢，<strong>可能难以收敛</strong>。</li> <li><strong>ACE对W的导数，正比于预测的误差</strong>，误差越大，导数越大，<strong>更容易收敛</strong>。</li></ul> <h2 id="二、神经网络登场"><a href="#二、神经网络登场" class="header-anchor">#</a> 二、神经网络登场</h2> <p>其实，理解了Logistic regression，也就基本理解了神经网络，也就大概知道了深度学习的大致思路。</p> <p>我们首先用一个图表示一个Logistic regression：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614724148-image.png" alt=""></p> <p>图中x1-x4为X的各个维度，Z=WX+b，a就是把Z输入激活函数sigmoid得到的结果，称为激活值（activation），然后就得到预测值y^.</p> <p>如果我们把图中的那个黄色球看做一个神经元的话，那么实际上神经网络就是多了几个或者几层的神经元：</p> <p><img src="https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624614731853-image.png" alt=""></p> <p>每一个神经元，内部的原理都是一样的。所以说，Logistic regression就是神经网络的基础。</p> <p>多层神经网络，因为它是多个非线性函数的叠加，理论上可以拟合任意复杂的函数，这就突破了Logistic regression的局限，可以对付各种非线性问题了。</p> <p><strong>神经网络的神秘之处在于</strong>，除了最开始的输入X是我们知道意义的，<strong>中间层的各种输入输出是我们无法理解的</strong>。</p> <p>但另一方面，<strong>这正是神经网络的强大之处</strong>。每一层的输入，都可以看做是对原数据提取的某些特征，然后再经过处理，提取另一些特征，再传给下一层，如此反复。这样经过学习，就可以学习到许多我们人无法定义或者不了解的特征，但是这些特征对于我们判断事务本身是有帮助的。</p> <p>这样，实际上我们是让神经网络主动地从数据中发掘特征，从而减少了我们人工定义特征的工作，**“让数据说话，而不是替数据说话”。**这也正是“深度学习”的主要思想，让模型的深度赋予模型以力量，从而让模型去自动提取特征，完成我们的任务。</p> <h2 id="_3-卷积神经网络"><a href="#_3-卷积神经网络" class="header-anchor">#</a> 3.卷积神经网络</h2> <p>... (此处省略一万字，请直接参看【从此明白了卷积神经网络】一文)</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.41fc4255.js" defer></script><script src="/assets/js/2.a266bdc2.js" defer></script><script src="/assets/js/40.51f0a3f5.js" defer></script>
  </body>
</html>
