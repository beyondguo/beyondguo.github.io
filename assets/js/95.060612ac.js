(window.webpackJsonp=window.webpackJsonp||[]).push([[95],{467:function(t,a,e){"use strict";e.r(a);var s=e(44),r=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"劫富济贫-对长尾数据进行特征空间增强-eccv20"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#劫富济贫-对长尾数据进行特征空间增强-eccv20"}},[t._v("#")]),t._v(" 劫富济贫：对长尾数据进行特征空间增强（ECCV20）")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113184208559.png",alt:""}})]),t._v(" "),e("ul",[e("li",[t._v("Title: Feature Space Augmentation for Long-Tailed Data")]),t._v(" "),e("li",[t._v("发表: ECCV-2020")]),t._v(" "),e("li",[t._v("机构:  GE Research")])]),t._v(" "),e("blockquote",[e("p",[e("strong",[t._v("一句话评价/总结：")])]),t._v(" "),e("p",[t._v("用“劫富济贫”的思想来进行特征空间的数据增强，从而缓解长尾数据太少的问题。")])]),t._v(" "),e("h2",{attrs:{id:"背景"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#背景"}},[t._v("#")]),t._v(" 背景")]),t._v(" "),e("p",[t._v("我们在做分类任务时，很多时候类别都是不平衡的，甚至不平衡的程度还很严重，例如作者对几个数据集做了统计（Fig.2）：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113191840080.png",alt:""}})]),t._v(" "),e("p",[t._v("那么在这种情况下，我们训练出来的分类模型的决策边界，很可能是不正确的。作者在上图（Fig.1）中做了示意：")]),t._v(" "),e("ul",[e("li",[t._v("当某类别数据少，但还是比较好地在散布在数据空间中，那可能还问题不大，因为这些少量的数据也可以比较好地反映整体的分布。通过简单的上下采样，或者对loss进行加权，就可以比较好地缓解不平衡问题；")]),t._v(" "),e("li",[t._v("但是如果数据少的类别，数据都聚集在某个小区域，那这些数据就跟该类别真实的样本分布相差很远了，我们通过采样、调loss的方法，学到的边界也还是很有问题的。")])]),t._v(" "),e("p",[t._v("现实场景中，第二种情况可能更容易出现，或者说，我们不能指望少量的数据也能够表示真实的分布，所以基于这些数据，进行简单的上下采样、调整loss，是没法解决问题的。")]),t._v(" "),e("h2",{attrs:{id:"核心思想"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#核心思想"}},[t._v("#")]),t._v(" 核心思想")]),t._v(" "),e("p",[t._v("对于长尾的类别，我们观测到的数据分布一般是不完整的，所以本文想通过那些富足的类别，来去帮助长尾的类别恢复一些分布。")]),t._v(" "),e("p",[t._v("具体来说，本文讲一个样本的特征分成两部分（基于class activation maps，CAM）：")]),t._v(" "),e("ul",[e("li",[t._v("class-generic feature，类别通用特征（类别间差异不大）")]),t._v(" "),e("li",[t._v("class-specific feature，类别特有特征（类别间差异很大）")])]),t._v(" "),e("p",[t._v("然后，把富足类别的数据的通用特征，跟长尾类别数据的特有特征进行融合，得到新的长尾类别的数据特征，从而对长尾类别进行了特征空间上的扩充。")]),t._v(" "),e("blockquote",[e("p",[t._v("举一个例子：猫的类别图片很多，但是狗类别的图片很少，那么我们可以把猫片的那些背景（相当于类别通用特征）抠出来，把狗片中的狗（相当于类别特有特征）抠出来，组合一下，就得到新的狗片。")])]),t._v(" "),e("h2",{attrs:{id:"具体方法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#具体方法"}},[t._v("#")]),t._v(" 具体方法")]),t._v(" "),e("p",[t._v("我们先看看总体框架，是一个“两步走”的方式：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20211227160032.png",alt:"整体框架图"}})]),t._v(" "),e("ul",[e("li",[t._v("第一步：正常训练分类模型，得到一个feature extractor")]),t._v(" "),e("li",[t._v("第二步：特征空间增强")]),t._v(" "),e("li",[t._v("第三步：基于这些新的特征，对分类器（这里就是FC层）进行微调")])]),t._v(" "),e("p",[t._v("这一三步都好理解，这里重点讲第二步：")]),t._v(" "),e("h3",{attrs:{id:"class-activation-map-cam"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#class-activation-map-cam"}},[t._v("#")]),t._v(" Class Activation Map (CAM)")]),t._v(" "),e("p",[t._v("这里首先涉及到CAM（class activation map）的概念，这玩意儿还挺有意思的，源自知乎大V、UCLA助理教授"),e("a",{attrs:{href:"https://www.zhihu.com/people/zhou-bo-lei",target:"_blank",rel:"noopener noreferrer"}},[t._v("周博磊"),e("OutboundLink")],1),t._v("的16年的CVPR上的大作：Learning Deep Features for Discriminative Localization.")]),t._v(" "),e("p",[t._v("上述论文中有一个图可以帮我们快速理解CAM：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113194757158.png",alt:"来自论文Learning Deep Features for Discriminative Localization"}})]),t._v(" "),e("p",[t._v("一个图片输入CNN模型，在经过global average pooling之后，最后一层的FC（也就是分类器了）的对应类别权重拿出来，对每个feature map进行一个线性加权求和，就得到了所谓的class activation map，这个CAM实际上就展示了该图片的那些部分是跟该类别高度相关的。")]),t._v(" "),e("p",[t._v("更多细节可以参见知乎：https://zhuanlan.zhihu.com/p/51631163")]),t._v(" "),e("p",[t._v("下面是计算公式：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113193808458.png",alt:""}})]),t._v(" "),e("h3",{attrs:{id:"feature-seperation"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#feature-seperation"}},[t._v("#")]),t._v(" Feature Seperation")]),t._v(" "),e("p",[t._v("有了CAM，我们再设定一个阈值，就可以把CAM中跟类别最相关的、最不相关的特征给挑出来：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://gitee.com/beyond_guo/typora_pics/raw/master/typora/20211227163026.png",alt:""}})]),t._v(" "),e("p",[t._v("对特征进行分割之后，作者做了一个可视化：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20211215221647548.png",alt:""}})]),t._v(" "),e("p",[t._v("左边的是类别特有特征，右边是通用特征，很明显，特有特征更能够代表对应的类别，更有区分度。")]),t._v(" "),e("p",[t._v("但同时，我们也看到，通用特征，也并不是完全都混在一起，它们也是有一定区分度的。")]),t._v(" "),e("h3",{attrs:{id:"feature-fusing-feature-space-augmentation"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#feature-fusing-feature-space-augmentation"}},[t._v("#")]),t._v(" Feature Fusing (Feature space augmentation)")]),t._v(" "),e("p",[t._v("最后就是对上面分割好的特征进行融合了。")]),t._v(" "),e("p",[t._v("上面的可视化我们也看到了，所谓的通用特征，并不一定真的各个类别都能通用，一般只有靠的比较斤的类别，容易混淆的类别，我们才能真的通用。所以，在特征融合时，也不能随便找，而是得"),e("strong",[t._v("找那些本身就比较近的类别来提供通用特征，这样对于恢复长尾类别分布更好。")])]),t._v(" "),e("p",[t._v("具体地，作者设定了一个超参数，对一个长尾数据，根据分类模型的预测混淆程度，来挑选k个易混淆头部类别，根据给定的阈值，划分出通用和特有两种特征，然后从k个头部类别中，挑a个图片，逐个进行线性组合，最终一个长尾样本特征，就会新增a套特征（相当于新增a个样本）。")]),t._v(" "),e("p",[t._v("这里的超参数还挺多的，所以最好还是对照那个框架图来进行理解。")]),t._v(" "),e("h2",{attrs:{id:"实验结果、分析"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#实验结果、分析"}},[t._v("#")]),t._v(" 实验结果、分析")]),t._v(" "),e("p",[t._v("实验结果我只节选一部分放放：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113201338710.png",alt:""}})]),t._v(" "),e("p",[t._v("主要看看一些更细致的分析：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113201424904.png",alt:""}})]),t._v(" "),e("p",[t._v("这个图记录了两个阶段的accuracy curve，挺有意思的，在进行特征增强之后，可以看到训练集又重新经历了一次爬坡，所以模型也确实再接收一些新知识。最终，测试集准确率有了提升。")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/typora/image-20220113201614911.png",alt:""}})]),t._v(" "),e("p",[t._v("上图左边是探究，怎么划分头部类别和长尾类别，这个ratio就是头部类别的样本数的总体占比，因为头部类别的划分，影响着后面进行特征融合时的操作对象。作者发现，在0.9左右的时候，总体效果比较好。")]),t._v(" "),e("p",[t._v("右图则是展示了使用不同的层的特征进行增强的效果，结论是靠后的层会更好，本实验中最好的就是整个表示模型的最后一层。作者给的解释也挺有意思，我觉得可以作为一个思考的角度："),e("strong",[t._v("越深的层（越靠近最终分类器），其特征越线性可分，这对于特征融合来说更好。另外，较浅的层，会包含很多局部的信息，带来更多的噪声。")])]),t._v(" "),e("p",[t._v("越靠近最终分类器，越线性可分，这个好理解，毕竟最终的softmax分类器就是线性分类器，所以到这一步了，特征肯定更加线性可分的。那为啥会对特征融合更好呢？这里作者没怎么解释，我做以下的猜想：因为我们这里使用的特征融合方式也是线性的，本文的特征融合，某种程度上，就是把头部类别的分布特征，给复制到长尾类别上的了，这时，对于线性可分的特征分布，这种做法就更有保障，因为不会有奇奇怪怪的分布；而如果是线性不可分的，比方说环形分布，那把这种分布复制到其他类别，很可能生成的样本就很怪异了。")]),t._v(" "),e("h2",{attrs:{id:"take-away-思考"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#take-away-思考"}},[t._v("#")]),t._v(" Take Away & 思考")]),t._v(" "),e("p",[t._v("总之，这个文章还是比较有意思的，有一定的脑洞。其实读论文最大的快感，就来源于发现了有趣的脑洞（最大的不快感，则来源于“这么烂也能发顶会？”）。这个文章的想法还是能够给人很多启发的，能够把生活中讲得通的想法(“劫富济贫”)，运用到理论中，这种工作一般都比较convincing.")]),t._v(" "),e("p",[e("strong",[t._v("本文的take away：")])]),t._v(" "),e("ul",[e("li",[t._v("样本的特征，可以通过class activation map (CAM)，分成generic和specific两种特征；")]),t._v(" "),e("li",[t._v("数据增强，可以用富足的类别的信息，去帮助少样本的类别")])]),t._v(" "),e("p",[e("strong",[t._v("思考：")])]),t._v(" "),e("ul",[e("li",[t._v("特征增强后，我们微调的，相当于只有最后的FC层，前面的模型主体并没有进行调整，所以我感觉这样做的真正提升还是有限的")]),t._v(" "),e("li",[t._v("对于类别通用特征，本文的做法一定好吗？很明显从作者自己的可视化可以看出，即使是通用特征，也是具有区分度的，因此作者选择采用confusing classes来作为通用特征提取的来源，但这应该算是一种“折中”的做法，因此，一定有更好的办法来找出通用特征，用于这里的特征融合。")])])])}),[],!1,null,null,null);a.default=r.exports}}]);