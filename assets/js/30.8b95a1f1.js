(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{398:function(t,s,a){"use strict";a.r(s);var n=a(44),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"【dl笔记3】一步步亲手用python实现logistic-regression"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#【dl笔记3】一步步亲手用python实现logistic-regression"}},[t._v("#")]),t._v(" 【DL笔记3】一步步亲手用python实现Logistic Regression")]),t._v(" "),a("blockquote",[a("p",[t._v("前面的"),a("a",{attrs:{href:"https://www.jianshu.com/p/4cf34bf158a1",target:"_blank",rel:"noopener noreferrer"}},[t._v("【DL笔记1】Logistic回归：最基础的神经网络"),a("OutboundLink")],1),t._v("和"),a("a",{attrs:{href:"https://www.jianshu.com/p/c67548909e99",target:"_blank",rel:"noopener noreferrer"}},[t._v("【DL笔记2】神经网络编程原则&Logistic Regression的算法解析"),a("OutboundLink")],1),t._v("讲解了Logistic regression的基本原理，并且我提到过这个玩意儿在我看来是学习神经网络和深度学习的基础，学到后面就发现，其实只要这个东西弄清楚了，后面的就很好明白。\n另外，虽然说现在有很多很多的机器学习包和深度学习框架，像sklearn、TensorFlow、Keras等等，让我们实现一个神经网络十分容易，但是如果你不了解原理，即使给你一个框架，里面的大量的函数和方法你依然不知道如何下手，不知道什么时候该使用什么，而这些框架里面经常提到的“前向传播”、“反向传播”、“计算图”、各种梯度下降、mini-batch、各种initialization方法等等你也难以理解，更别提如何针对你的实际场景在对症下药了。\n因此，我的深度学习系列笔记，主要是讲解神经网络的思路、算法、原理，然后前期主要使用python和numpy来实现，只有到我们把神经网络基本讲完，才会开始使用诸如TensorFlow这样的框架来实现。当然，这也是我正在听的吴恩达的深度学习系列课程的特点，不急不躁，耐心地用最朴素的方法来实践所有的原理，这样才能融会贯通，玩转各种框架。")])]),t._v(" "),a("p",[t._v("这次的前言有点啰嗦了。。。主要是怕有的读者说“明明可以用机器学习包几行代码搞定，为啥偏要用纯python费劲去实现”。\n好了，进入正题：")]),t._v(" "),a("h2",{attrs:{id:"用python实现logistic-regression"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#用python实现logistic-regression"}},[t._v("#")]),t._v(" 用python实现Logistic Regression")]),t._v(" "),a("h3",{attrs:{id:"一、算法搭建步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、算法搭建步骤"}},[t._v("#")]),t._v(" 一、算法搭建步骤")]),t._v(" "),a("h4",{attrs:{id:"一-数据预处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一-数据预处理"}},[t._v("#")]),t._v(" （一）数据预处理")]),t._v(" "),a("ul",[a("li",[t._v("搞清楚数据的形状、维度")]),t._v(" "),a("li",[t._v("将数据（例如图片）转化成向量（image to vector）方便处理")]),t._v(" "),a("li",[t._v("将数据标准化（standardize），这样更好训练")])]),t._v(" "),a("h4",{attrs:{id:"二-构造各种辅助函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二-构造各种辅助函数"}},[t._v("#")]),t._v(" （二）构造各种辅助函数")]),t._v(" "),a("ul",[a("li",[t._v("激活函数（此处我们使用sigmoid函数）--activation function")]),t._v(" "),a("li",[t._v("参数初始化函数（用来初始化W和b）--initialization")]),t._v(" "),a("li",[t._v("传播函数（这里是用来求损失cost并对W、b求导，即dW、db）--propagate")]),t._v(" "),a("li",[t._v("优化函数（迭代更新W和b，来最小化cost）--optimize")]),t._v(" "),a("li",[t._v("预测函数（根据学习到的W和b来进行预测）--predict")])]),t._v(" "),a("h4",{attrs:{id:"三-综合上面的辅助函数-结合成一个模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三-综合上面的辅助函数-结合成一个模型"}},[t._v("#")]),t._v(" （三）综合上面的辅助函数，结合成一个模型")]),t._v(" "),a("ul",[a("li",[t._v("可以直接输入训练集、预测集、超参数，然后给出模型参数和准确率")])]),t._v(" "),a("p",[t._v("上面这么多辅助函数可能看的让人有点懵逼，因此我花了半小时在PowerPoint里面画了这个图(ヾﾉ꒪ཫ꒪)，以便更清楚地说明它们之间的关系：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624595337891-image.png",alt:""}})]),t._v(" "),a("p",[t._v("构造辅助函数（helper function）是为了让我们的结构更清晰，更容易调试和修改。下面我们按照上面的步骤一个一个来。")]),t._v(" "),a("h3",{attrs:{id:"二、开始编程吧"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、开始编程吧"}},[t._v("#")]),t._v(" 二、开始编程吧")]),t._v(" "),a("p",[t._v("下面我们采用**“展示代码和注释+重点地方详解”**的方式来一步步实现：")]),t._v(" "),a("h4",{attrs:{id:"一-数据导入和预处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一-数据导入和预处理"}},[t._v("#")]),t._v(" （一）数据导入和预处理")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 导入数据，“_orig”代表这里是原始数据，我们还要进一步处理才能使用：")]),t._v("\ntrain_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train_set_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_set_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" load_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#由数据集获取一些基本参数，如训练样本数m，图片大小：")]),t._v("\nm_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#训练集大小209")]),t._v("\nm_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" test_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#测试集大小209")]),t._v("\nnum_px "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#图片宽度64，大小是64×64")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将图片数据向量化（扁平化）：")]),t._v("\ntrain_set_x_flatten "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T\ntest_set_x_flatten "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" test_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("test_set_x_orig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#对数据进行标准化：")]),t._v("\ntrain_set_x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_set_x_flatten"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\ntest_set_x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" test_set_x_flatten"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br")])]),a("p",[t._v("上面的代码有几点要说明：")]),t._v(" "),a("ol",[a("li",[t._v("数据导入是直接用吴恩达网课中的数据集，他提供了一个接口load_dataset()可以直接导入数据，如果"),a("strong",[t._v("需要数据的话可以在文章下方留言获取")]),t._v("。这里主要是展示方法，完全可以用自己的数据集来操作。\n数据集是一些图片，我们要训练一个识别猫的分类器。\n"),a("strong",[t._v("train_set_x_orig，也就是我们的原始数据")]),t._v("的"),a("strong",[t._v("形状")]),t._v("是**(209, 64, 64, 3)**，"),a("strong",[t._v("第一维代表m，即样本数量，第二维第三维分别是图片的长和宽，第四维代表图片的RGB三个通道")]),t._v("。")]),t._v(" "),a("li",[t._v("numpy包有重要的关于矩阵“形状”的方法："),a("strong",[t._v(".shape")]),t._v("和**.reshape()**\n.shape可以获取一个矩阵的形状，于是我们可以通过[i]来知道每一维的大小；\n.reshape()用来重构矩阵的形状，直接在里面填写维度即可，还有一些特殊用法，比如此处的用法：\n当我们要把一个向量X(m,a,b,c)这个"),a("strong",[t._v("四维向量")]),t._v("扁平化成X_flatten(m,a* b* c)的"),a("strong",[t._v("二维向量")]),t._v("，可以写***X_flatten=X.reshape(X.shape[0],-1)**"),a("em",[t._v("即可，其中“-1”代表把剩余维度压扁的模式。而代码中还有一个.T,代表转置，因为我们希望把训练样本压缩成（64")]),t._v(" 64 *3，m）的形式。")]),t._v(" "),a("li",[a("strong",[t._v("为什么需要标准化")]),t._v("？\n在说明为什么要标准化前，我们不妨说说一般的标准化是怎么做的：先求出数据的均值和方差，然后对每一个样本数据，先"),a("strong",[t._v("减去均值")]),t._v("，然后"),a("strong",[t._v("除以方差")]),t._v("，也就是(x-μ)/σ"),a("sup",[t._v("2")]),t._v(",说白了就是"),a("strong",[t._v("转化成标准正态分布")]),t._v("！这样，每个特征都转化成了同样的分布，不管原来的范围是什么，现在都基本限定在同样的范围内了。\n这样做的好处是什么呢？且看下面两个等高线图：")])]),t._v(" "),a("p",[t._v("未标准化:\n"),a("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624595362006-image.png",alt:"未标准化"}})]),t._v(" "),a("p",[t._v("标准化之后:\n"),a("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624595385826-image.png",alt:""}})]),t._v(" "),a("p",[t._v("上面两个图展示了数据在未标准化和标准化之后的情形。"),a("strong",[t._v("原数据的不同特征的范围可能会有很大差别")]),t._v("，比如一批数据中“年龄”的范围就比较小，可能20岁 ~ 60岁之间，但是另一个特征“年收入”可能波动范围就很大，也许0.5万 ~ 1000万，这种情况下回导致我们的"),a("strong",[t._v("等高线图变得十分“扁平”")]),t._v("，在梯度下降的时候会很"),a("strong",[t._v("容易走弯路")]),t._v("，因此"),a("strong",[t._v("梯度下降会比较慢，精度也不高")]),t._v("。但是经过标准化（也称归一化）之后，"),a("strong",[t._v("等高线就变规矩了，就很容易梯度下降了")]),t._v("。\n另外，对于图片数据的话，进行标准化很简单，因为RGB三个通道的范围都是255，我们对图片的处理就是直接除以255即可。")]),t._v(" "),a("p",[t._v("至此，数据预处理就完成了，我们进入下一步：")]),t._v(" "),a("h4",{attrs:{id:"二-构建辅助函数们"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二-构建辅助函数们"}},[t._v("#")]),t._v(" （二）构建辅助函数们")]),t._v(" "),a("p",[a("strong",[t._v("1.  激活函数/sigmoid函数：")])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sigmoid")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("z"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    a "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("z"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" a\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("就这么easy，sigmoid的公式就是1/(1+e"),a("sup",[t._v("-x")]),t._v(")，这里用**np.exp()**就可以轻松构建。")]),t._v(" "),a("p",[a("strong",[t._v("2. 参数初始化函数（给参数都初始化为0）：")])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("initialize_with_zeros")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    w "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    b "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br")])]),a("p",[t._v("W是一个列向量，传入维度dim，返回shape为（dim,1）的W，b就是一个数。\n这里用到的方法是"),a("strong",[t._v("np.zeros(shape)")]),t._v(".")]),t._v(" "),a("p",[a("strong",[t._v("3.propagate函数：")]),t._v("\n这里再次解释一下这个propagate，它包含了forward-propagate和backward-propagate，即正向传播和反向传播。正向传播求的是cost，反向传播是从cost的表达式倒推W和b的偏导数，当然我们会先求出Z的偏导数。这两个方向的传播也是神经网络的精髓。\n具体倒数怎么求，这里就不推导了，就是很简单的求导嘛，公式请参见上一篇文章："),a("a",{attrs:{href:"https://www.jianshu.com/p/c67548909e99",target:"_blank",rel:"noopener noreferrer"}},[t._v("【DL笔记2】神经网络编程原则&Logistic Regression的算法解析"),a("OutboundLink")],1),t._v("\n那么我就直接上代码了：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("propagate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    传参:\n    w -- 权重, shape： (num_px * num_px * 3, 1)\n    b -- 偏置项, 一个标量\n    X -- 数据集，shape： (num_px * num_px * 3, m),m为样本数\n    Y -- 真实标签，shape： (1,m)\n\n    返回值:\n    cost， dw ，db，后两者放在一个字典grads里\n    """')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#获取样本数m：")]),t._v("\n    m "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 前向传播 ：")]),t._v("\n    A "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sigmoid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#调用前面写的sigmoid函数    ")]),t._v("\n    cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("m                 \n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 反向传播：")]),t._v("\n    dZ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Y\n    dw "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("dZ"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("m\n    db "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dZ"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("m\n  \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#返回值：")]),t._v("\n    grads "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dw"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" dw"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"db"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" db"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cost\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br")])]),a("p",[t._v("这里需要额外说明的就是，"),a("strong",[t._v("numpy中矩阵的点乘")]),t._v("，也就是内积运算，是用"),a("strong",[t._v("np.dot(A,B)")]),t._v("，它要求前一个矩阵的列数等于后一个矩阵的行数。但矩阵也可以进行"),a("strong",[t._v("元素相乘（element product）")]),t._v("，就是两个相同形状的矩阵对于元素相乘得到一个新的相同形状的矩阵，可以直接用"),a("strong",[t._v("A * B")]),t._v("，或者用"),a("strong",[t._v("np.multiply(A,B)")]),t._v("。\n上面的代码中，既有点乘，也有元素相乘，我们在写的时候，先搞清楚形状，再确定用什么乘法。\n上面还有各种numpy的数学函数，对矩阵求log就用"),a("strong",[t._v("np.log()")]),t._v("，对矩阵元素求和就用"),a("strong",[t._v("np.sum()")]),t._v("，贼方便。")]),t._v(" "),a("p",[a("strong",[t._v("4.optimize函数：")]),t._v("\n有了上面这些函数的加持，optimize函数就很好写了，就是在迭代中调用各个我们刚刚写的函数就是：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("optimize")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_iterations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" learning_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" print_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#定义一个costs数组，存放每若干次迭代后的cost，从而可以画图看看cost的变化趋势：")]),t._v("\n    costs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#进行迭代：")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_iterations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用propagate计算出每次迭代后的cost和梯度：")]),t._v("\n        grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" propagate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        dw "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dw"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        db "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"db"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用上面得到的梯度来更新参数：")]),t._v("\n        w "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" w "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" learning_rate"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("dw\n        b "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" learning_rate"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("db\n        \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每100次迭代，保存一个cost看看：")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这个可以不在意，我们可以每100次把cost打印出来看看，从而随时掌握模型的进展：")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" print_cost "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Cost after iteration %i: %f"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#迭代完毕，将最终的各个参数放进字典，并返回：")]),t._v("\n    params "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    grads "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dw"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" dw"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"db"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" db"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" costs\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br")])]),a("p",[t._v("这个函数就没什么好解释的了。")]),t._v(" "),a("p",[a("strong",[t._v("5.predict函数：")]),t._v("\n预测就很简单了，我们已经学到了参数W和b，那么让我们的数据经过配备这些参数的模型就可得到预测值。注意，X->Z->激活得到A，此时还并不是预测值，由sigmoid函数我们知道，A的范围是0~1，但是我们的标签值是0和1，因此，我们可以设立规则：0.5~1的A对于预测值1,小于0.5的对应预测值0：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("predict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    m "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    Y_prediction "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    A "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sigmoid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("  i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            Y_prediction"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            Y_prediction"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" Y_prediction\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br")])]),a("p",[t._v("恭喜，如果你有耐心看到这里了。。。那。。。我真的忍不住送你一朵fa了：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624595430010-image.png",alt:""}})]),t._v(" "),a("p",[t._v("毕竟我自己都不相信会有几个人真的去看这么枯燥的过程。但是我相信，每一份耐心和付出都有回报吧，学习这事儿，急不来。")]),t._v(" "),a("p",[t._v("至此，我们已经构建好了所有的辅助函数。接下来就是结合在一起，然后用我们的数据去训练、预测了！")]),t._v(" "),a("h4",{attrs:{id:"三-结合起来-搭建模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三-结合起来-搭建模型"}},[t._v("#")]),t._v(" （三）结合起来，搭建模型！")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("logistic_model")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("learning_rate"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("num_iterations"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("print_cost"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#获特征维度，初始化参数：")]),t._v("\n    dim "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    W"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" initialize_with_zeros"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#梯度下降，迭代求出模型参数：")]),t._v("\n    params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("grads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("costs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" optimize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("W"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("num_iterations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("learning_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("print_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    W "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    b "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#用学得的参数进行预测：")]),t._v("\n    prediction_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("W"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    prediction_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("W"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#计算准确率，分别在训练集和测试集上：")]),t._v("\n    accuracy_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("abs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("prediction_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" Y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    accuracy_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("abs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("prediction_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" Y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Accuracy on train set:"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("accuracy_train "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Accuracy on test set:"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("accuracy_test "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#为了便于分析和检查，我们把得到的所有参数、超参数都存进一个字典返回出来：")]),t._v("\n    d "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"costs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Y_prediction_test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prediction_test "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Y_prediction_train"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prediction_train "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"learning_rate"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" learning_rate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_iterations"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_iterations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"train_acy"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("train_acy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test_acy"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("test_acy\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" d\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br")])]),a("p",[t._v("就是这么easy，只要我们一步步把前面的辅助函数搭建好，这里就可以很轻松很清晰地构造模型。\n"),a("strong",[t._v("唯一值得一提的是这个准确率怎么计算")]),t._v("的问题，我们的predict函数得到的是一个列向量（1，m），这个跟我们的标签Y是一样的形状。我们首先可以让"),a("strong",[t._v("两者相减")]),t._v("：\n"),a("strong",[t._v("prediction_test  - Y_test")]),t._v("，\n如果对应位置相同，则变成0，不同的话要么是1要么是-1，于是再"),a("strong",[t._v("取绝对值")]),t._v("：\n"),a("strong",[t._v("np.abs")]),t._v("(prediction_test  - Y_test)，\n就相当于得到了“哪些位置预测错了”的一个向量，于是我们再求一个"),a("strong",[t._v("均值")]),t._v("：\n"),a("strong",[t._v("np.mean")]),t._v("(np.abs(prediction_test  - Y_test))，\n就是**“错误率”"),a("strong",[t._v("了，然后用")]),t._v("1来减"),a("strong",[t._v("去它，就是")]),t._v("正确率**了！")]),t._v(" "),a("h3",{attrs:{id:"大功告成-试试效果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大功告成-试试效果"}},[t._v("#")]),t._v(" 大功告成！试试效果：")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("d "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_set_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" train_set_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_set_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_set_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_iterations "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" learning_rate "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.005")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" print_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("p",[t._v("运行模型就很简单了，把我们的数据集穿进去，设置我们想要的超参数，主要是学习率（learning rate）、迭代数（num_iterations），然后把print_cost设为True，这样可以在模型训练过程中打印cost的变化趋势。")]),t._v(" "),a("p",[t._v("运行，查看结果：")]),t._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Cost after iteration 0: 0.693147\nCost after iteration 100: 0.584508\nCost after iteration 200: 0.466949\nCost after iteration 300: 0.376007\nCost after iteration 400: 0.331463\nCost after iteration 500: 0.303273\nCost after iteration 600: 0.279880\nCost after iteration 700: 0.260042\nCost after iteration 800: 0.242941\nCost after iteration 900: 0.228004\nCost after iteration 1000: 0.214820\nCost after iteration 1100: 0.203078\nCost after iteration 1200: 0.192544\nCost after iteration 1300: 0.183033\nCost after iteration 1400: 0.174399\nCost after iteration 1500: 0.166521\nCost after iteration 1600: 0.159305\nCost after iteration 1700: 0.152667\nCost after iteration 1800: 0.146542\nCost after iteration 1900: 0.140872\n---------------------\ntrain accuracy: 99.04306220095694 %\ntest accuracy: 70.0 %\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br")])]),a("p",[t._v("可以看到，随着训练的进行，cost在不断地降低，这说明的参数在变得越来越好。\n最终，在训练集上的准确率达到了99%以上，测试集准确率为70%。\n哈哈，很明显，我们的模型"),a("strong",[t._v("过拟合了")]),t._v("，测试集的准确率还有待提高。**但是这个不重要！重要的是我们亲手再没有用任何框架的情况下用python把Logistic regression给实现了一遍，每一个细节都明明白白！**٩(๑>◡<๑)۶\n况且，这才仅仅是一个Logistic regression，相当于1层的只有一个神经元的神经网络，能对图片分类达到70%的准确率，我们已经很棒了!")]),t._v(" "),a("hr"),t._v(" "),a("p",[a("strong",[t._v("其实")]),t._v("，神经网络无非就是在Logistic regression的基础上，多了几个隐层，每层多了一些神经元，卷积神经网络无非就是再多了几个特殊的filter，多了一些有特定功能的层，但是核心都是跟Logistic Regression一样的：")]),t._v(" "),a("blockquote",[a("p",[t._v("前向传播求损失，"),a("br"),t._v("\n反向传播求倒数；"),a("br"),t._v("\n不断迭代和更新，"),a("br"),t._v("\n调参预测准确度。")])]),t._v(" "),a("p",[t._v("哟嗬！才发现自己还有写诗的天赋。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624595496062-image.png",alt:""}})]),t._v(" "),a("hr"),t._v(" "),a("blockquote",[a("p",[t._v("本文就到此结束，终于结束了，出去吃串串了~")])])])}),[],!1,null,null,null);s.default=r.exports}}]);