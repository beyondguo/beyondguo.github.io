(window.webpackJsonp=window.webpackJsonp||[]).push([[60],{428:function(s,t,a){"use strict";a.r(t);var n=a(44),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("blockquote",[a("p",[a("strong",[s._v("「Huggingface🤗NLP笔记系列-第3集」")]),s._v("\n最近跟着Huggingface上的NLP tutorial走了一遍，惊叹居然有如此好的讲解Transformers系列的NLP教程，于是决定记录一下学习的过程，分享我的笔记，可以算是官方教程的精简版。但最推荐的，还是直接跟着官方教程来一遍，真是一种享受。")])]),s._v(" "),a("ul",[a("li",[s._v("官方教程网址：https://huggingface.co/course/chapter1")]),s._v(" "),a("li",[s._v("本期内容对应网址：https://huggingface.co/course/chapter2/2?fw=pt")]),s._v(" "),a("li",[s._v("本系列笔记的"),a("strong",[s._v("GitHub")]),s._v("： https://github.com/beyondguo/Learn_PyTorch/tree/master/HuggingfaceNLP")])]),s._v(" "),a("hr"),s._v(" "),a("h1",{attrs:{id:"pipeline端到端的背后发生了什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pipeline端到端的背后发生了什么"}},[s._v("#")]),s._v(" Pipeline端到端的背后发生了什么")]),s._v(" "),a("p",[s._v("Pipeline的背后：\n"),a("img",{attrs:{src:"https://huggingface.co/course/static/chapter2/full_nlp_pipeline.png",width:"1000"}})]),s._v(" "),a("h2",{attrs:{id:"_1-tokenizer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-tokenizer"}},[s._v("#")]),s._v(" 1. Tokenizer")]),s._v(" "),a("p",[s._v("我们使用的tokenizer必须跟对应的模型在预训练时的tokenizer保持一致，也就是词表需要一致。"),a("br"),s._v("\nHuggingface中可以直接指定模型的checkpoint的名字，然后自动下载对应的词表。"),a("br"),s._v("\n具体方式是：")]),s._v(" "),a("ul",[a("li",[s._v("使用"),a("code",[s._v("AutoTokenizer")]),s._v("的"),a("code",[s._v("from_pretrained")]),s._v("方法")])]),s._v(" "),a("p",[a("code",[s._v("tokenizer")]),s._v("这个对象可以直接接受参数并输出结果，即它是callable的。具体参数见："),a("br"),s._v("\nhttps://huggingface.co/transformers/master/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase "),a("br"),s._v("\n主要参数包括：")]),s._v(" "),a("ul",[a("li",[s._v("text，可以是单条的string，也可以是一个string的list，还可以是list的list")]),s._v(" "),a("li",[s._v("padding，用于填白")]),s._v(" "),a("li",[s._v("truncation，用于截断")]),s._v(" "),a("li",[s._v("max_length，设置最大句长")]),s._v(" "),a("li",[s._v("return_tensors，设置返回数据类型")])]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" transformers "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" AutoTokenizer\n\ncheckpoint "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'distilbert-base-uncased-finetuned-sst-2-english'")]),s._v("\ntokenizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AutoTokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("先看看直接使用tokenizer的结果：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("raw_inputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Today is a good day! Woo~~~'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n              "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'How about tomorrow?'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\ntokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2651")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2003")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1037")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2204")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2154")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("15854")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2129")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2055")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4826")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1029")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("可以加上一个 "),a("code",[s._v("padding=Ture")]),s._v(" 参数，让得到的序列长度对齐：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2651")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2003")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1037")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2204")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2154")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("15854")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2129")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2055")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4826")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1029")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("tokenizer还有"),a("code",[s._v("truncation")]),s._v("和"),a("code",[s._v("max_length")]),s._v("属性，用于在max_length处截断：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2651")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2003")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1037")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2204")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2154")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2129")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2055")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4826")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1029")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[a("code",[s._v("return_tensors")]),s._v("属性也很重要，用来指定返回的是什么类型的tensors，"),a("code",[s._v("pt")]),s._v("就是pytorch，"),a("code",[s._v("tf")]),s._v("就是tensorflow：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" return_tensors"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2651")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2003")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1037")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2204")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2154")]),s._v(",   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("15854")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(",\n          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1066")]),s._v(",   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2129")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2055")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4826")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1029")]),s._v(",   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),s._v(",     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(",     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("h2",{attrs:{id:"_2-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-model"}},[s._v("#")]),s._v(" 2. Model")]),s._v(" "),a("p",[s._v("也可以通过AutoModel来直接从checkpoint导入模型。")]),s._v(" "),a("p",[s._v("这里导入的模型，是Transformer的基础模型，接受tokenize之后的输入，"),a("strong",[s._v("输出hidden states，即文本的向量表示")]),s._v("，是一种上下文表示。")]),s._v(" "),a("p",[s._v("这个向量表示，会有三个维度：")]),s._v(" "),a("ol",[a("li",[s._v("batch size")]),s._v(" "),a("li",[s._v("sequence length")]),s._v(" "),a("li",[s._v("hidden size")])]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" transformers "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" AutoModel\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AutoModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("加载了模型之后，就可以把tokenizer得到的输出，直接输入到model中：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("inputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" return_tensors"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noutputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 这里变量前面的**，代表把inputs这个dictionary给分解成一个个参数单独输进去")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("vars")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看一下输出有哪些属性")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("dict_keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'last_hidden_state'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hidden_states'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attentions'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("blockquote",[a("p",[a("strong",[s._v("这里顺便讲一讲这个函数中"),a("code",[s._v("**")]),s._v("的用法：")])])]),s._v(" "),a("p",[a("code",[s._v("**")]),s._v("在函数中的作用就是把后面紧跟着的这个参数，从一个字典的格式，解压成一个个单独的参数。")]),s._v(" "),a("p",[s._v("回顾一下上面tokenizer的输出，我们发现它是一个包含了input_ids和attention_mask两个key的"),a("strong",[s._v("字典")]),s._v("，因此通过"),a("code",[s._v("**")]),s._v("的解压，相当于变成了"),a("code",[s._v("intput_ids=..., attention_mask=...")]),s._v("喂给函数。")]),s._v(" "),a("p",[s._v("我们再来查看一下通过AutoModel加载的DistillBertModel模型的输入：\nhttps://huggingface.co/transformers/master/model_doc/distilbert.html#distilbertmodel")]),s._v(" "),a("p",[s._v("可以看到DistillBertModel的直接call的函数是：")]),s._v(" "),a("p",[a("code",[s._v("forward(input_ids=None, attention_mask=None, ...)")]),s._v("\n正好跟"),a("code",[s._v("**inputs")]),s._v("后的格式对应上。")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_hidden_state"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noutputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("last_hidden_state\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("输出")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("torch.Size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("768")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4627")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3042")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5431")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3706")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0033")]),s._v(", -0.6074"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6100")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3093")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2038")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3788")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9370")]),s._v(", -0.6439"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6514")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3185")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3855")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4152")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0199")]),s._v(", -0.4450"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3674")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1380")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.1619")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4976")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4758")]),s._v(", -0.5896"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4182")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2503")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0898")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4745")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4042")]),s._v(", -0.5444"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.1614")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2516")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9561")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5742")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8437")]),s._v(", -0.9604"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n    \n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7956")]),s._v(", -0.2343,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3810")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("., -0.1270,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5182")]),s._v(", -0.1612"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9337")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2074")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6202")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1874")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6584")]),s._v(", -0.1899"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6279")]),s._v(", -0.3176,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1596")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("., -0.2956,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2960")]),s._v(", -0.1447"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3050")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0396")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6345")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4271")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3367")]),s._v(", -0.3285"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1773")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0111")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6275")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3831")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3543")]),s._v(", -0.2919"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2756")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0048")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9281")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2006")]),s._v(",  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4375")]),s._v(", -0.3238"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n           "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("grad_fn")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("NativeLayerNormBackward"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br")])]),a("p",[s._v("可以看到，输出的shape是"),a("code",[s._v("torch.Size([2, 12, 768])")]),s._v("，三个维度分别是 batch，seq_len和hidden size。")]),s._v(" "),a("h2",{attrs:{id:"_3-model-heads"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-model-heads"}},[s._v("#")]),s._v(" 3. Model Heads")]),s._v(" "),a("p",[s._v("模型头，接在基础模型的后面，用于将hidden states文本表示进一步处理，用于具体的任务。")]),s._v(" "),a("p",[s._v("整体框架图：")]),s._v(" "),a("img",{attrs:{src:"https://huggingface.co/course/static/chapter2/transformer_and_head.png",width:"1000"}}),s._v(" "),a("p",[s._v("Head一般是由若干层的线性层来构成的。")]),s._v(" "),a("p",[s._v("Transformers库中的主要模型架构有：")]),s._v(" "),a("ul",[a("li",[s._v("*Model (retrieve the hidden states)")]),s._v(" "),a("li",[s._v("*ForCausalLM")]),s._v(" "),a("li",[s._v("*ForMaskedLM")]),s._v(" "),a("li",[s._v("*ForMultipleChoice")]),s._v(" "),a("li",[s._v("*ForQuestionAnswering")]),s._v(" "),a("li",[s._v("*ForSequenceClassification")]),s._v(" "),a("li",[s._v("*ForTokenClassification")]),s._v(" "),a("li",[s._v("...")])]),s._v(" "),a("p",[s._v("单纯的"),a("code",[s._v("*Model")]),s._v("，就是不包含 Head 的模型，而有"),a("code",[s._v("For*")]),s._v("的则是包含了具体 Head 的模型。")]),s._v(" "),a("p",[s._v("例如，对于前面的那个做在情感分析上pretrain的checkpoint(distilbert-base-uncased-finetuned-sst-2-english)，我们可以使用包含 SequenceClassification 的Head的模型去加载，就可以直接得到对应分类问题的logits，而不仅仅是文本向量表示。")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" transformers "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" AutoModelForSequenceClassification\nclf "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AutoModelForSequenceClassification"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ninputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" return_tensors"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noutputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("vars")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noutputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("logits\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("dict_keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'loss'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'logits'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hidden_states'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attentions'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\ntensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("-4.2098,  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.6444")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6367")]),s._v(", -0.3753"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("grad_fn")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("AddmmBackward"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("从outputs的属性就可以看出，带有Head的Model，跟不带Head的Model，输出的东西是不一样的。")]),s._v(" "),a("p",[a("strong",[s._v("没有Head的Model")]),s._v("，输出的是"),a("code",[s._v("'last_hidden_state', 'hidden_states', 'attentions'")]),s._v("这些玩意儿，因为它仅仅是一个表示模型；")]),s._v(" "),a("p",[a("strong",[s._v("有Head的Model")]),s._v("，输出的是"),a("code",[s._v("'loss', 'logits', 'hidden_states', 'attentions'")]),s._v("这些玩意儿，有logits，loss这些东西，因为它是一个完整的预测模型了。")]),s._v(" "),a("p",[s._v("可以顺便看看，加了这个 SequenceClassification Head的DistillBertModel的文档，看看其输入和输出：")]),s._v(" "),a("p",[s._v("https://huggingface.co/transformers/master/model_doc/distilbert.html#distilbertforsequenceclassification")]),s._v(" "),a("p",[s._v("可以看到，输入中，我们还可以提供"),a("code",[s._v("labels")]),s._v("，这样就可以直接计算loss了。")]),s._v(" "),a("h2",{attrs:{id:"_4-post-processing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-post-processing"}},[s._v("#")]),s._v(" 4. Post-Processing")]),s._v(" "),a("p",[s._v("后处理主要就是两步：")]),s._v(" "),a("ul",[a("li",[s._v("把logits转化成概率值 （用softmax）")]),s._v(" "),a("li",[s._v("把概率值跟具体的标签对应上 （使用模型的config中的id2label）")])]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\npredictions "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("functional"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("softmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("logits"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# dim=-1就是沿着最后一维进行操作")]),s._v("\npredictions\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(".4276e-04, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(".9986e-01"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(".3341e-01, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(".6659e-01"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("grad_fn")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("SoftmaxBackward"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("得到了概率分布，还得知道具体是啥标签吧。标签跟id的隐射关系，也已经被保存在每个pretrain model的config中了，\n我们可以去模型的"),a("code",[s._v("config")]),s._v("属性中查看"),a("code",[s._v("id2label")]),s._v("字段：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("id2label "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id2label\nid2label\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(": "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'NEGATIVE'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(": "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'POSITIVE'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("综合起来，直接从prediction得到标签：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("argmax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("predictions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id2label"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("输出：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("    POSITIVE\n    NEGATIVE\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);