(window.webpackJsonp=window.webpackJsonp||[]).push([[63],{432:function(s,t,a){"use strict";a.r(t);var n=a(44),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("blockquote",[a("p",[a("strong",[s._v("ã€ŒHuggingfaceğŸ¤—NLPç¬”è®°ç³»åˆ—-ç¬¬6é›†ã€")]),s._v("\næœ€è¿‘è·Ÿç€Huggingfaceä¸Šçš„NLP tutorialèµ°äº†ä¸€éï¼ŒæƒŠå¹å±…ç„¶æœ‰å¦‚æ­¤å¥½çš„è®²è§£Transformersç³»åˆ—çš„NLPæ•™ç¨‹ï¼Œäºæ˜¯å†³å®šè®°å½•ä¸€ä¸‹å­¦ä¹ çš„è¿‡ç¨‹ï¼Œåˆ†äº«æˆ‘çš„ç¬”è®°ï¼Œå¯ä»¥ç®—æ˜¯å®˜æ–¹æ•™ç¨‹çš„"),a("strong",[s._v("ç²¾ç®€+æ³¨è§£ç‰ˆ")]),s._v("ã€‚ä½†æœ€æ¨èçš„ï¼Œè¿˜æ˜¯ç›´æ¥è·Ÿç€å®˜æ–¹æ•™ç¨‹æ¥ä¸€éï¼ŒçœŸæ˜¯ä¸€ç§äº«å—ã€‚")])]),s._v(" "),a("ul",[a("li",[s._v("å®˜æ–¹æ•™ç¨‹ç½‘å€ï¼šhttps://huggingface.co/course/chapter1")]),s._v(" "),a("li",[s._v("æœ¬æœŸå†…å®¹å¯¹åº”ç½‘å€ï¼šhttps://huggingface.co/course/chapter3/2?fw=pt")]),s._v(" "),a("li",[s._v("æœ¬ç³»åˆ—ç¬”è®°çš„"),a("strong",[s._v("GitHub")]),s._v("ï¼š https://github.com/beyondguo/Learn_PyTorch/tree/master/HuggingfaceNLP")])]),s._v(" "),a("hr"),s._v(" "),a("h1",{attrs:{id:"æ•°æ®é›†çš„é¢„å¤„ç†-ä½¿ç”¨dynamic-paddingæ„é€ batch"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#æ•°æ®é›†çš„é¢„å¤„ç†-ä½¿ç”¨dynamic-paddingæ„é€ batch"}},[s._v("#")]),s._v(" æ•°æ®é›†çš„é¢„å¤„ç†ï¼Œä½¿ç”¨dynamic paddingæ„é€ batch")]),s._v(" "),a("p",[s._v("ä»è¿™ä¸€é›†ï¼Œæˆ‘ä»¬å°±æ­£å¼å¼€å§‹ä½¿ç”¨Transformeræ¥è®­ç»ƒæ¨¡å‹äº†ã€‚ä»Šå¤©çš„éƒ¨åˆ†æ˜¯å…³äºæ•°æ®é›†é¢„å¤„ç†ã€‚")]),s._v(" "),a("h2",{attrs:{id:"è¯•ç€è®­ç»ƒä¸€ä¸¤æ¡æ ·æœ¬"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#è¯•ç€è®­ç»ƒä¸€ä¸¤æ¡æ ·æœ¬"}},[s._v("#")]),s._v(" è¯•ç€è®­ç»ƒä¸€ä¸¤æ¡æ ·æœ¬")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# å…ˆçœ‹çœ‹cudaæ˜¯å¦å¯ç”¨")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\ntorch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cuda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" True\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("é¦–å…ˆï¼Œæˆ‘ä»¬åŠ è½½æ¨¡å‹ã€‚æ—¢ç„¶æ¨¡å‹è¦åœ¨å…·ä½“ä»»åŠ¡ä¸Šå¾®è°ƒäº†ï¼Œæˆ‘ä»¬å°±è¦åŠ è½½å¸¦æœ‰Headçš„æ¨¡å‹ï¼Œè¿™é‡Œåšçš„åˆ†ç±»é—®é¢˜ï¼Œå› æ­¤åŠ è½½"),a("code",[s._v("ForSequenceClassification")]),s._v("è¿™ä¸ªHeadï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" transformers "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" AdamW"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" AutoTokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" AutoModelForSequenceClassification\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Same as before")]),s._v("\ncheckpoint "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"bert-base-uncased"')]),s._v("\ntokenizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AutoTokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AutoModelForSequenceClassification"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("checkpoint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("ä¸‹é¢æ˜¯æ¨¡å‹è¾“å‡ºçš„warningï¼š")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" \nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.predictions.bias'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.predictions.transform.dense.weight'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.predictions.transform.dense.bias'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.predictions.decoder.weight'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.seq_relationship.weight'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.seq_relationship.bias'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.predictions.transform.LayerNorm.weight'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cls.predictions.transform.LayerNorm.bias'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n- This IS expected "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".\n- This IS NOT expected "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" you are initializing BertForSequenceClassification from the checkpoint of a model that you "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("expect")]),s._v(" to be exactly identical "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("initializing a BertForSequenceClassification model from a BertForSequenceClassification model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'classifier.weight'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'classifier.bias'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nYou should probably TRAIN this model on a down-stream task to be able to use it "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" predictions and inference.\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("çœ‹åˆ°è¿™ä¹ˆä¸€å¤§ä¸²çš„warningå‡ºç°ï¼Œä¸è¦æ€•ï¼Œè¿™ä¸ªwarningæ­£æ˜¯æˆ‘ä»¬å¸Œæœ›çœ‹åˆ°çš„ã€‚")]),s._v(" "),a("p",[s._v("ä¸ºå•¥ä¼šå‡ºç°è¿™ä¸ªwarningå‘¢ï¼Œå› ä¸ºæˆ‘ä»¬åŠ è½½çš„é¢„è®­ç»ƒæƒé‡æ˜¯"),a("code",[s._v("bert-based-uncased")]),s._v("ï¼Œè€Œä½¿ç”¨çš„éª¨æ¶æ˜¯"),a("code",[s._v("AutoModelForSequenceClassification")]),s._v("ï¼Œå‰è€…æ˜¯æ²¡æœ‰åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šå¾®è°ƒè¿‡çš„ï¼Œæ‰€ä»¥ç”¨å¸¦æœ‰ä¸‹æ¸¸ä»»åŠ¡Headçš„éª¨æ¶å»åŠ è½½ï¼Œä¼šéšæœºåˆå§‹åŒ–è¿™ä¸ªHeadã€‚è¿™äº›åœ¨warningä¸­ä¹Ÿè¯´çš„å¾ˆæ˜ç™½ã€‚")]),s._v(" "),a("p",[s._v("æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¯•è¯•ç›´æ¥æ„é€ ä¸€ä¸ªsize=2çš„batchï¼Œä¸¢è¿›æ¨¡å‹å»ã€‚")]),s._v(" "),a("p",[s._v('å½“è¾“å…¥çš„batchæ˜¯å¸¦æœ‰"labels"å±æ€§çš„æ—¶å€™ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è®¡ç®—lossï¼Œæ‹¿ç€è¿™ä¸ªlossï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œåå‘ä¼ æ’­å¹¶æ›´æ–°å‚æ•°äº†ï¼š')]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("sequences "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"I\'ve been waiting for a HuggingFace course my whole life."')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"This course is amazing!"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nbatch "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sequences"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" return_tensors"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"pt"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nbatch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'labels'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tensor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tokenizerå‡ºæ¥çš„ç»“æœæ˜¯ä¸€ä¸ªdictionaryï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥åŠ å…¥æ–°çš„ key-value")]),s._v("\n\noptimizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AdamW"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nloss "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("loss  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#è¿™é‡Œçš„ loss æ˜¯ç›´æ¥æ ¹æ® batch ä¸­æä¾›çš„ labels æ¥è®¡ç®—çš„ï¼Œå›å¿†ï¼šå‰é¢ç« èŠ‚æŸ¥çœ‹ model çš„è¾“å‡ºçš„æ—¶å€™ï¼Œæœ‰lossè¿™ä¸€é¡¹")]),s._v("\nloss"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noptimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br")])]),a("h2",{attrs:{id:"ä»huggingface-hubä¸­åŠ è½½æ•°æ®é›†"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ä»huggingface-hubä¸­åŠ è½½æ•°æ®é›†"}},[s._v("#")]),s._v(" ä»Huggingface Hubä¸­åŠ è½½æ•°æ®é›†")]),s._v(" "),a("p",[s._v("è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨MRPCæ•°æ®é›†ï¼Œå®ƒçš„å…¨ç§°æ˜¯Microsoft Research Paraphrase Corpusï¼ŒåŒ…å«äº†5801ä¸ªå¥å­å¯¹ï¼Œæ ‡ç­¾æ˜¯ä¸¤ä¸ªå¥å­æ˜¯å¦æ˜¯åŒä¸€ä¸ªæ„æ€ã€‚")]),s._v(" "),a("p",[s._v("Huggingfaceæœ‰ä¸€ä¸ª"),a("code",[s._v("datasets")]),s._v("åº“ï¼Œå¯ä»¥è®©æˆ‘ä»¬è½»æ¾åœ°ä¸‹è½½å¸¸è§çš„æ•°æ®é›†ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" load_dataset\n\nraw_datasets "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" load_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"glue"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mrpc"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nraw_datasets\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("çœ‹çœ‹åŠ è½½çš„datasetçš„æ ·å­ï¼š")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("DatasetDict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    train: Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        features: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        num_rows: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3668")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    validation: Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        features: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        num_rows: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("408")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    test: Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        features: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        num_rows: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1725")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br")])]),a("p",[s._v("load_datasetå‡ºæ¥çš„æ˜¯ä¸€ä¸ªDatasetDictå¯¹è±¡ï¼Œå®ƒåŒ…å«äº†trainï¼Œvalidationï¼Œtestä¸‰ä¸ªå±æ€§ã€‚å¯ä»¥é€šè¿‡keyæ¥ç›´æ¥æŸ¥è¯¢ï¼Œå¾—åˆ°å¯¹åº”çš„trainã€validå’Œtestæ•°æ®é›†ã€‚")]),s._v(" "),a("p",[s._v("è¿™é‡Œçš„trainï¼Œvalidï¼Œtestéƒ½æ˜¯Datasetç±»å‹ï¼Œæœ‰ featureså’Œnum_rowsä¸¤ä¸ªå±æ€§ã€‚è¿˜å¯ä»¥ç›´æ¥é€šè¿‡ä¸‹æ ‡æ¥æŸ¥è¯¢å¯¹åº”çš„æ ·æœ¬ã€‚")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("raw_train_dataset "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" raw_datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nraw_train_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("çœ‹çœ‹æ•°æ®é•¿å•¥æ ·ï¼š")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("å¯è§ï¼Œæ¯ä¸€æ¡æ•°æ®ï¼Œå°±æ˜¯ä¸€ä¸ªdictionaryã€‚")]),s._v(" "),a("p",[s._v("Datasetçš„featureså¯ä»¥ç†è§£ä¸ºä¸€å¼ è¡¨çš„columnsï¼ŒDatasetç”šè‡³å¯ä»¥çœ‹åšä¸€ä¸ªpandasçš„dataframeï¼ŒäºŒè€…çš„ä½¿ç”¨å¾ˆç±»ä¼¼ã€‚")]),s._v(" "),a("p",[s._v("æˆ‘ä»¬å¯ä»¥ç›´æ¥åƒæ“ä½œdataframeä¸€æ ·ï¼Œå–å‡ºæŸä¸€åˆ—ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_train_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ç›´æ¥å–å‡ºæ‰€æœ‰çš„sentence1ï¼Œå½¢æˆä¸€ä¸ªlist")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" list\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("é€šè¿‡Datasetçš„featureså±æ€§ï¼Œå¯ä»¥è¯¦ç»†æŸ¥çœ‹æ•°æ®é›†ç‰¹å¾ï¼ŒåŒ…æ‹¬labelså…·ä½“éƒ½æ˜¯å•¥ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("raw_train_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("features\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" Value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'string'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" Value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'string'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" ClassLabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_classes"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("names")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'not_equivalent'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'equivalent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("names_file")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None, "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" Value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dtype"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'int32'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("None"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("h2",{attrs:{id:"æ•°æ®é›†çš„é¢„å¤„ç†"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#æ•°æ®é›†çš„é¢„å¤„ç†"}},[s._v("#")]),s._v(" æ•°æ®é›†çš„é¢„å¤„ç†")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" transformers "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" AutoTokenizer\ntokenizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" AutoTokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'bert-base-cased'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("æˆ‘ä»¬å¯ä»¥ç›´æ¥ä¸‹é¢è¿™æ ·å¤„ç†ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("tokenized_sentences_1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_train_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntokenized_sentences_2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("raw_train_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("ä½†å¯¹äºMRPCä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸èƒ½æŠŠä¸¤ä¸ªå¥å­åˆ†å¼€è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼ŒäºŒè€…åº”è¯¥ç»„æˆä¸€ä¸ªpairè¾“è¿›å»ã€‚")]),s._v(" "),a("p",[s._v("tokenizerä¹Ÿå¯ä»¥ç›´æ¥å¤„ç†sequence pairï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pprint "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),s._v("\ninputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first sentence"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"second one"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2034")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6251")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2117")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2028")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token_type_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("æˆ‘ä»¬æŠŠè¿™é‡Œçš„input_idsç»™decodeçœ‹ä¸€ä¸‹ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("input_ids"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'[CLS] first sentence [SEP] second one [SEP]'")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("å¯ä»¥çœ‹åˆ°è¿™é‡Œinputsé‡Œï¼Œè¿˜æœ‰ä¸€ä¸ª"),a("code",[s._v("token_type_ids")]),s._v("å±æ€§ï¼Œå®ƒåœ¨è¿™é‡Œçš„ä½œç”¨å°±å¾ˆæ˜æ˜¾äº†ï¼ŒæŒ‡ç¤ºå“ªäº›è¯æ˜¯å±äºç¬¬ä¸€ä¸ªå¥å­ï¼Œå“ªäº›è¯æ˜¯å±äºç¬¬äºŒä¸ªå¥å­ã€‚tokenizerå¤„ç†åå¾—åˆ°çš„idsï¼Œè§£ç ä¹‹åï¼Œåœ¨å¼€å¤´ç»“å°¾å¤šäº†"),a("code",[s._v("[CLS]")]),s._v("å’Œ"),a("code",[s._v("[SEP]")]),s._v("ï¼Œä¸¤ä¸ªå¥å­ä¸­é—´ä¹Ÿæ·»åŠ äº†ä¸€ä¸ª"),a("code",[s._v("[SEP]")]),s._v("ã€‚å¦å¤–æ³¨æ„ï¼Œè™½ç„¶è¾“å…¥çš„æ˜¯ä¸€ä¸ªå¥å­å¯¹ï¼Œä½†æ˜¯ç¼–ç ä¹‹åæ˜¯ä¸€ä¸ªæ•´ä½“ï¼Œé€šè¿‡"),a("code",[s._v("[SEP]")]),s._v("ç¬¦å·ç›¸è¿ã€‚")]),s._v(" "),a("p",[a("strong",[s._v("è¿™ç§ç¥å¥‡çš„åšæ³•ï¼Œå…¶å®æ˜¯æºäºbert-baseé¢„è®­ç»ƒçš„ä»»åŠ¡")]),s._v("ï¼Œå³"),a("strong",[s._v("next sentence prediction")]),s._v("ã€‚æ¢æˆå…¶ä»–æ¨¡å‹ï¼Œæ¯”å¦‚DistilBertï¼Œå®ƒåœ¨é¢„è®­ç»ƒçš„æ—¶å€™æ²¡æœ‰è¿™ä¸ªä»»åŠ¡ï¼Œé‚£å®ƒçš„tokenizerçš„ç»“æœå°±ä¸ä¼šæœ‰è¿™ä¸ª"),a("code",[s._v("token_type_ids")]),s._v("å±æ€§äº†ã€‚")]),s._v(" "),a("p",[s._v("æ—¢ç„¶è¿™é‡Œçš„tokenizerå¯ä»¥ç›´æ¥å¤„ç†pairï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿™ä¹ˆå»åˆ†è¯ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("tokenized_dataset "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    raw_datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"train"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sentence1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    raw_datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"train"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sentence2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("ä½†æ˜¯è¿™æ ·ä¸ä¸€å®šå¥½ï¼Œå› ä¸ºå…ˆæ˜¯ç›´æ¥æŠŠè¦å¤„ç†çš„æ•´ä¸ªæ•°æ®é›†éƒ½è¯»è¿›äº†å†…å­˜ï¼Œåˆè¿”å›ä¸€ä¸ªæ–°çš„dictionaryï¼Œä¼šå æ®å¾ˆå¤šå†…å­˜ã€‚")]),s._v(" "),a("p",[s._v("å®˜æ–¹æ¨èçš„åšæ³•æ˜¯é€šè¿‡"),a("code",[s._v("Dataset.map")]),s._v("æ–¹æ³•ï¼Œæ¥è°ƒç”¨ä¸€ä¸ªåˆ†è¯æ–¹æ³•ï¼Œå®ç°æ‰¹é‡åŒ–çš„åˆ†è¯ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("tokenize_function")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# è¿™é‡Œå¯ä»¥æ·»åŠ å¤šç§æ“ä½œï¼Œä¸å…‰æ˜¯tokenize")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# è¿™ä¸ªå‡½æ•°å¤„ç†çš„å¯¹è±¡ï¼Œå°±æ˜¯Datasetè¿™ç§æ•°æ®ç±»å‹ï¼Œé€šè¿‡featuresä¸­çš„å­—æ®µæ¥é€‰æ‹©è¦å¤„ç†çš„æ•°æ®")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" truncation"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\ntokenized_datasets "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" raw_datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tokenize_function"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batched"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntokenized_datasets\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br")])]),a("p",[s._v("å¤„ç†åçš„datasetçš„ä¿¡æ¯ï¼š")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("DatasetDict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    train: Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        features: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token_type_ids'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        num_rows: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3668")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    validation: Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        features: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token_type_ids'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        num_rows: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("408")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    test: Dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        features: "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token_type_ids'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(",\n        num_rows: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1725")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br")])]),a("p",[s._v("çœ‹çœ‹è¿™ä¸ªmapçš„ä¸€äº›å‚æ•°ï¼š")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("raw_datasets.map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    function,\n    with_indices: bool "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" False,\n    input_columns: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str, List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,\n    batched: bool "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" False,\n    batch_size: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("int, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v(",\n    remove_columns: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str, List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,\n    keep_in_memory: bool "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" False,\n    load_from_cache_file: bool "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" True,\n    cache_file_names: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("Dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str, Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(", NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,\n    writer_batch_size: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("int, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v(",\n    features: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("datasets.features.Features, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,\n    disable_nullable: bool "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" False,\n    fn_kwargs: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("dict, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,\n    num_proc: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("int, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ä½¿ç”¨æ­¤å‚æ•°ï¼Œå¯ä»¥ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†")]),s._v("\n    desc: Union"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("str, NoneType"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" None,\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" -"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DatasetDict'")]),s._v("\nDocstring:\nApply a "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" to all the elements "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" the table "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("individually or "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" batches"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nand update the table "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("if "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" does updated examples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(".\nThe transformation is applied to all the datasets of the dataset dictionary.\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("p",[s._v("å…³äºè¿™ä¸ªmapï¼Œåœ¨Huggingfaceçš„æµ‹è¯•é¢˜ä¸­æœ‰è®²è§£ï¼Œè¿™é‡Œæ¬è¿å¹¶ç¿»è¯‘ä¸€ä¸‹ï¼Œè¾…åŠ©ç†è§£ï¼š")]),s._v(" "),a("h3",{attrs:{id:"dataset-mapæ–¹æ³•æœ‰å•¥å¥½å¤„"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dataset-mapæ–¹æ³•æœ‰å•¥å¥½å¤„"}},[s._v("#")]),s._v(" Dataset.mapæ–¹æ³•æœ‰å•¥å¥½å¤„ï¼š")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("The results of the function are cached, so it won't take any time if we re-execute the code.")]),s._v(" "),a("p",[s._v("ï¼ˆé€šè¿‡è¿™ä¸ªmapï¼Œå¯¹æ•°æ®é›†çš„å¤„ç†ä¼šè¢«ç¼“å­˜ï¼Œæ‰€ä»¥é‡æ–°æ‰§è¡Œä»£ç ï¼Œä¹Ÿä¸ä¼šå†è´¹æ—¶é—´ã€‚ï¼‰")])]),s._v(" "),a("li",[a("p",[s._v("It can apply multiprocessing to go faster than applying the function on each element of the dataset.")]),s._v(" "),a("p",[s._v("ï¼ˆå®ƒå¯ä»¥ä½¿ç”¨å¤šè¿›ç¨‹æ¥å¤„ç†ä»è€Œæé«˜å¤„ç†é€Ÿåº¦ã€‚ï¼‰")])]),s._v(" "),a("li",[a("p",[s._v("It does not load the whole dataset into memory, saving the results as soon as one element is processed.")]),s._v(" "),a("p",[s._v("ï¼ˆå®ƒä¸éœ€è¦æŠŠæ•´ä¸ªæ•°æ®é›†éƒ½åŠ è½½åˆ°å†…å­˜é‡Œï¼ŒåŒæ—¶æ¯ä¸ªå…ƒç´ ä¸€ç»å¤„ç†å°±ä¼šé©¬ä¸Šè¢«ä¿å­˜ï¼Œå› æ­¤ååˆ†èŠ‚çœå†…å­˜ã€‚ï¼‰")])])]),s._v(" "),a("p",[s._v("è§‚å¯Ÿä¸€ä¸‹ï¼Œè¿™é‡Œé€šè¿‡mapä¹‹åï¼Œå¾—åˆ°çš„Datasetçš„featureså˜å¤šäº†ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'idx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sentence2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token_type_ids'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("å¤šçš„å‡ ä¸ªcolumnså°±æ˜¯tokenizerå¤„ç†åçš„ç»“æœã€‚")]),s._v(" "),a("p",[s._v("æ³¨æ„åˆ°ï¼Œ"),a("strong",[s._v("åœ¨è¿™ä¸ª"),a("code",[s._v("tokenize_function")]),s._v("ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨"),a("code",[s._v("padding")])]),s._v("ï¼Œå› ä¸ºå¦‚æœä½¿ç”¨äº†paddingä¹‹åï¼Œå°±ä¼šå…¨å±€ç»Ÿä¸€å¯¹ä¸€ä¸ªmaxlenè¿›è¡Œpaddingï¼Œè¿™æ ·æ— è®ºåœ¨tokenizeè¿˜æ˜¯æ¨¡å‹çš„è®­ç»ƒä¸Šéƒ½ä¸å¤Ÿé«˜æ•ˆã€‚")]),s._v(" "),a("h2",{attrs:{id:"dynamic-padding-åŠ¨æ€padding"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dynamic-padding-åŠ¨æ€padding"}},[s._v("#")]),s._v(" Dynamic Padding åŠ¨æ€padding")]),s._v(" "),a("p",[s._v("å®é™…ä¸Šï¼Œæˆ‘ä»¬æ˜¯æ•…æ„å…ˆä¸è¿›è¡Œpaddingçš„ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³"),a("strong",[s._v("åœ¨åˆ’åˆ†batchçš„æ—¶å€™å†è¿›è¡Œpadding")]),s._v("ï¼Œè¿™æ ·å¯ä»¥é¿å…å‡ºç°å¾ˆå¤šæœ‰ä¸€å †paddingçš„åºåˆ—ï¼Œä»è€Œå¯ä»¥æ˜¾è‘—èŠ‚çœæˆ‘ä»¬çš„è®­ç»ƒæ—¶é—´ã€‚")]),s._v(" "),a("p",[s._v("è¿™é‡Œï¼Œæˆ‘ä»¬å°±éœ€è¦ç”¨åˆ°**"),a("code",[s._v("DataCollatorWithPadding")]),a("strong",[s._v("ï¼Œæ¥è¿›è¡Œ")]),s._v("åŠ¨æ€padding**ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" transformers "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" DataCollatorWithPadding\ndata_collator "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" DataCollatorWithPadding"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tokenizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("tokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("æ³¨æ„ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨tokenizeræ¥åˆå§‹åŒ–è¿™ä¸ª"),a("code",[s._v("DataCollatorWithPadding")]),s._v("ï¼Œå› ä¸ºéœ€è¦tokenizeræ¥å‘ŠçŸ¥å…·ä½“çš„padding tokenæ˜¯å•¥ï¼Œä»¥åŠpaddingçš„æ–¹å¼æ˜¯åœ¨å·¦è¾¹è¿˜æ˜¯å³è¾¹ï¼ˆä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨çš„padding tokenä»¥åŠæ–¹å¼å¯èƒ½ä¸åŒï¼‰ã€‚")]),s._v(" "),a("p",[s._v("ä¸‹é¢å‡è®¾æˆ‘ä»¬è¦æä¸€ä¸ªsize=5çš„batchï¼Œçœ‹çœ‹å¦‚ä½•ä½¿ç”¨"),a("code",[s._v("DataCollatorWithPadding")]),s._v("æ¥å®ç°ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("samples "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tokenized_datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nsamples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# >>> ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids']")]),s._v("\nsamples "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("k"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" k"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" samples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" k "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"idx"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sentence1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sentence2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# æŠŠè¿™é‡Œå¤šä½™çš„å‡ åˆ—å»æ‰")]),s._v("\nsamples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# >>> ['attention_mask', 'input_ids', 'label', 'token_type_ids']")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# æ‰“å°å‡ºæ¯ä¸ªå¥å­çš„é•¿åº¦ï¼š")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" x "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" samples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"input_ids"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("59")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("47")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("59")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("ç„¶åæˆ‘ä»¬ä½¿ç”¨data_collatoræ¥å¤„ç†ï¼š")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("batch "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" data_collator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("samples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# samplesä¸­å¿…é¡»åŒ…å« input_ids å­—æ®µï¼Œå› ä¸ºè¿™å°±æ˜¯collatorè¦å¤„ç†çš„å¯¹è±¡")]),s._v("\nbatch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# >>> dict_keys(['attention_mask', 'input_ids', 'token_type_ids', 'labels'])")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# å†æ‰“å°é•¿åº¦ï¼š")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" x "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ª"),a("code",[s._v("data_collator")]),s._v("å°±æ˜¯ä¸€ä¸ªæŠŠç»™å®šdatasetè¿›è¡Œpaddingçš„å·¥å…·ï¼Œå…¶è¾“å…¥è·Ÿè¾“å‡ºæ˜¯å®Œå…¨ä¸€æ ·çš„æ ¼å¼ã€‚")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("k"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" k"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'attention_mask'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" torch.Size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'input_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" torch.Size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token_type_ids'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" torch.Size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("67")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(",\n "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'labels'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" torch.Size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("è¿™ä¸ªbatchï¼Œå¯ä»¥å½¢æˆä¸€ä¸ªtensoräº†ï¼æ¥ä¸‹æ¥å°±å¯ä»¥ç”¨äºè®­ç»ƒäº†ï¼")]),s._v(" "),a("hr"),s._v(" "),a("p",[s._v("å¯¹äº†ï¼Œè¿™é‡Œå¤šæä¸€å¥ï¼Œ"),a("code",[s._v("collator")]),s._v("è¿™ä¸ªå•è¯å®é™…ä¸Šåœ¨å¹³æ—¶ä½¿ç”¨è‹±è¯­çš„æ—¶å€™å¹¶ä¸å¸¸è§ï¼Œä½†å´åœ¨ç¼–ç¨‹ä¸­è§åˆ°å¤šæ¬¡ã€‚")]),s._v(" "),a("p",[s._v("æœ€å¼€å§‹ä¸€ç›´ä»¥ä¸ºæ˜¯"),a("code",[s._v("collector")]),s._v("ï¼Œæ„ä¸ºâ€œæ”¶é›†è€…â€ç­‰æ„æ€ï¼Œåæ¥æŸ¥äº†æŸ¥ï¼Œå‘ç°ä¸æ˜¯çš„ã€‚ä¸‹é¢æ˜¯æŸ¯æ—æ–¯è¯å…¸ä¸­å¯¹"),a("code",[s._v("collate")]),s._v("è¿™ä¸ªè¯çš„è§£é‡Šï¼š")]),s._v(" "),a("blockquote",[a("p",[a("strong",[s._v("collate")]),s._v(":")]),s._v(" "),a("p",[s._v("When you collate pieces of information, you "),a("strong",[s._v("gather")]),s._v(" them all together and "),a("strong",[s._v("examine")]),s._v(" them.")])]),s._v(" "),a("p",[s._v("å°±æ˜¯å½’çº³å¹¶æ•´ç†çš„æ„æ€ã€‚æ‰€ä»¥åœ¨æˆ‘ä»¬è¿™ä¸ªæƒ…æ™¯ä¸‹ï¼Œå°±æ˜¯å¯¹è¿™äº›æ‚ä¹±æ— ç« é•¿çŸ­ä¸ä¸€çš„åºåˆ—æ•°æ®ï¼Œè¿›è¡Œä¸€ä¸ªä¸ªåœ°åˆ†ç»„ï¼Œç„¶åæ£€æŸ¥å¹¶ç»Ÿä¸€é•¿åº¦ã€‚")]),s._v(" "),a("p",[s._v("å…³äºDataCollatoræ›´å¤šçš„ä¿¡æ¯ï¼Œå¯ä»¥å‚è§æ–‡æ¡£ï¼š\nhttps://huggingface.co/transformers/master/main_classes/data_collator.html?highlight=datacollatorwithpadding#data-collator")])])}),[],!1,null,null,null);t.default=e.exports}}]);