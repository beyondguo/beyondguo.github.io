(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{401:function(t,n,v){"use strict";v.r(n);var _=v(44),e=Object(_.a)({},(function(){var t=this,n=t.$createElement,v=t._self._c||n;return v("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[v("h1",{attrs:{id:"【dl笔记6】从此明白了卷积神经网络-cnn"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#【dl笔记6】从此明白了卷积神经网络-cnn"}},[t._v("#")]),t._v(" 【DL笔记6】从此明白了卷积神经网络（CNN）")]),t._v(" "),v("h2",{attrs:{id:"初识卷积神经网络-cnn"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#初识卷积神经网络-cnn"}},[t._v("#")]),t._v(" 初识卷积神经网络（CNN）")]),t._v(" "),v("blockquote",[v("p",[t._v("从今天起，正式开始讲解卷积神经网络。这是一种曾经让我无论如何也无法弄明白的东西，主要是名字就太“高级”了，网上的各种各样的文章来介绍“什么是卷积”尤为让人受不了。听了吴恩达的网课之后，豁然开朗，终于搞明白了这个东西是什么和为什么。我这里大概会用6~7篇文章来讲解CNN并实现一些有趣的应用。看完之后大家应该可以自己动手做一些自己喜欢的事儿了。")])]),t._v(" "),v("h2",{attrs:{id:"一、引子-边界检测"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一、引子-边界检测"}},[t._v("#")]),t._v(" 一、引子————边界检测")]),t._v(" "),v("p",[t._v("我们来看一个最简单的例子：“边界检测（edge detection）”，假设我们有这样的一张图片，大小8×8：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624596919699-image.png",alt:""}})]),t._v(" "),v("p",[t._v("图片中的数字代表该位置的像素值，我们知道，像素值越大，颜色越亮，所以为了示意，我们把右边小像素的地方画成深色。图的中间两个颜色的分界线就是我们要检测的边界。")]),t._v(" "),v("p",[t._v("怎么检测这个边界呢？我们可以设计这样的一个 "),v("strong",[t._v("滤波器（filter，也称为kernel）")]),t._v("，大小3×3：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624596931966-image.png",alt:""}})]),t._v(" "),v("p",[t._v("然后，我们用这个filter，往我们的图片上“盖”，覆盖一块跟filter一样大的区域之后，对应元素相乘，然后求和。计算一个区域之后，就向其他区域挪动，接着计算，直到把原图片的每一个角落都覆盖到了为止。这个过程就是 "),v("strong",[t._v("“卷积”")]),t._v("。\n（我们不用管卷积在数学上到底是指什么运算，我们只用知道在CNN中是怎么计算的。）\n这里的“挪动”，就涉及到一个步长了，假如我们的步长是1，那么覆盖了一个地方之后，就挪一格，容易知道，总共可以覆盖6×6个不同的区域。")]),t._v(" "),v("p",[t._v("那么，我们将这6×6个区域的卷积结果，拼成一个矩阵：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624596940911-image.png",alt:"边界检测"}})]),t._v(" "),v("p",[t._v("诶？！发现了什么？\n这个图片，中间颜色浅，两边颜色深，这说明咱们的原图片中间的边界，在这里被反映出来了!")]),t._v(" "),v("p",[t._v("从上面这个例子中，我们发现，"),v("strong",[t._v("我们可以通过设计特定的filter，让它去跟图片做卷积，就可以识别出图片中的某些特征")]),t._v("，比如边界。\n上面的例子是检测竖直边界，我们也可以设计出检测水平边界的，只用把刚刚的filter旋转90°即可。对于其他的特征，理论上只要我们经过精细的设计，总是可以设计出合适的filter的。")]),t._v(" "),v("p",[v("strong",[t._v("我们的CNN（convolutional neural network），主要就是通过一个个的filter，不断地提取特征，从局部的特征到总体的特征，从而进行图像识别等等功能。")])]),t._v(" "),v("p",[v("strong",[t._v("那么问题来了")]),t._v("，我们怎么可能去设计这么多各种各样的filter呀？首先，我们都不一定清楚对于一大推图片，我们需要识别哪些特征，其次，就算知道了有哪些特征，想真的去设计出对应的filter，恐怕也并非易事，要知道，特征的数量可能是成千上万的。")]),t._v(" "),v("p",[t._v("其实学过神经网络之后，我们就知道，"),v("strong",[t._v("这些filter，根本就不用我们去设计")]),t._v("，每个filter中的各个数字，不就是参数吗，我们可以通过大量的数据，来 "),v("strong",[t._v("让机器自己去“学习”这些参数")]),t._v("嘛。这，就是CNN的原理。")]),t._v(" "),v("h2",{attrs:{id:"二、cnn的基本概念"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#二、cnn的基本概念"}},[t._v("#")]),t._v(" 二、CNN的基本概念")]),t._v(" "),v("p",[v("strong",[t._v("1.padding 填白")]),t._v("\n从上面的引子中，我们可以知道，原图像在经过filter卷积之后，变小了，从(8,8)变成了(6,6)。假设我们再卷一次，那大小就变成了(4,4)了。")]),t._v(" "),v("p",[v("strong",[t._v("这样有啥问题呢？")]),t._v("\n主要有两个问题：")]),t._v(" "),v("ul",[v("li",[t._v("每次卷积，图像都缩小，这样卷不了几次就没了；")]),t._v(" "),v("li",[t._v("相比于图片中间的点，图片边缘的点在卷积中被计算的次数很少。这样的话，边缘的信息就易于丢失。")])]),t._v(" "),v("p",[t._v("为了解决这个问题，我们可以采用padding的方法。我们每次卷积前，先给图片周围都补一圈空白，让卷积之后图片跟原来一样大，同时，原来的边缘也被计算了更多次。")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624596957365-image.png",alt:"padding"}})]),t._v(" "),v("p",[t._v("比如，我们把(8,8)的图片给补成(10,10)，那么经过(3,3)的filter之后，就是(8,8)，没有变。")]),t._v(" "),v("p",[t._v("我们把上面这种“让卷积之后的大小不变”的padding方式，称为 **“Same”**方式，\n把不经过任何填白的，称为 **“Valid”**方式。这个是我们在使用一些框架的时候，需要设置的超参数。")]),t._v(" "),v("p",[v("strong",[t._v("2.stride 步长")]),t._v("\n前面我们所介绍的卷积，都是默认步长是1，但实际上，我们可以设置步长为其他的值。\n比如，对于(8,8)的输入，我们用(3,3)的filter，\n如果stride=1，则输出为(6,6);\n如果stride=2，则输出为(3,3);（这里例子举得不大好，除不断就向下取整）")]),t._v(" "),v("p",[v("strong",[t._v("3.pooling 池化")]),t._v("\n这个pooling，是为了提取一定区域的主要特征，并减少参数数量，防止模型过拟合。\n比如下面的MaxPooling，采用了一个2×2的窗口，并取stride=2：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624596970488-image.png",alt:"Maxpooling"}})]),t._v(" "),v("p",[t._v("除了MaxPooling,还有AveragePooling，顾名思义就是取那个区域的平均值。")]),t._v(" "),v("p",[v("strong",[t._v("4.对多通道（channels）图片的卷积")]),t._v("\n这个需要单独提一下。彩色图像，一般都是RGB三个通道（channel）的，因此输入数据的维度一般有三个："),v("strong",[t._v("（长，宽，通道）")]),t._v("。\n比如一个28×28的RGB图片，维度就是(28,28,3)。")]),t._v(" "),v("p",[t._v("前面的引子中，输入图片是2维的(8,8)，filter是(3,3)，输出也是2维的(6,6)。")]),t._v(" "),v("p",[t._v("如果输入图片是三维的呢（即增多了一个channels），比如是(8,8,3)，这个时候，我们的filter的维度就要变成(3,3,3)了，它的 "),v("strong",[t._v("最后一维要跟输入的channel维度一致。")]),t._v("\n这个时候的卷积，"),v("strong",[t._v("是三个channel的所有元素对应相乘后求和")]),t._v("，也就是之前是9个乘积的和，现在是27个乘积的和。因此，输出的维度并不会变化。还是(6,6)。")]),t._v(" "),v("p",[t._v("但是，一般情况下，我们会 "),v("strong",[t._v("使用多了filters同时卷积")]),t._v("，比如，如果我们同时使用4个filter的话，那么 "),v("strong",[t._v("输出的维度则会变为(6,6,4)")]),t._v("。")]),t._v(" "),v("p",[t._v("我特地画了下面这个图，来展示上面的过程：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624596984822-image.png",alt:"同时有4个filter"}})]),t._v(" "),v("p",[t._v("图中的输入图像是(8,8,3)，filter有4个，大小均为(3,3,3)，得到的输出为(6,6,4)。\n我觉得这个图已经画的很清晰了，而且给出了3和4这个两个关键数字是怎么来的，所以我就不啰嗦了（这个图画了我起码40分钟）。")]),t._v(" "),v("p",[t._v("其实，如果套用我们前面学过的神经网络的符号来看待CNN的话，")]),t._v(" "),v("ul",[v("li",[t._v("我们的输入图片就是X，shape=(8,8,3);")]),t._v(" "),v("li",[t._v("4个filters其实就是第一层神金网络的参数W1,，shape=(3,3,3,"),v("strong",[t._v("4")]),t._v("),这个4是指有4个filters;")]),t._v(" "),v("li",[t._v("我们的输出，就是Z1，shape=(6,6,4);")]),t._v(" "),v("li",[t._v("后面其实还应该有一个激活函数，比如relu，经过激活后，Z1变为A1，shape=(6,6,4);")])]),t._v(" "),v("p",[t._v("所以，在前面的图中，我加一个激活函数，给对应的部分标上符号，就是这样的：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597001077-image.png",alt:"呕心沥血画的好图片，值得收藏"}})]),t._v(" "),v("h2",{attrs:{id:"三、cnn的结构组成"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#三、cnn的结构组成"}},[t._v("#")]),t._v(" 三、CNN的结构组成")]),t._v(" "),v("p",[t._v("上面我们已经知道了卷积（convolution）、池化（pooling）以及填白（padding）是怎么进行的，接下来我们就来看看CNN的整体结构，它包含了3种层（layer）：")]),t._v(" "),v("p",[v("strong",[t._v("1. Convolutional layer（卷积层--CONV）")]),t._v("\n由滤波器filters和激活函数构成。\n一般要设置的超参数包括filters的数量、大小、步长，以及padding是“valid”还是“same”。当然，还包括选择什么激活函数。")]),t._v(" "),v("p",[v("strong",[t._v("2. Pooling layer （池化层--POOL）")]),t._v("\n这里里面没有参数需要我们学习，因为这里里面的参数都是我们设置好了，要么是Maxpooling，要么是Averagepooling。\n需要指定的超参数，包括是Max还是average，窗口大小以及步长。\n通常，我们使用的比较多的是Maxpooling,而且一般取大小为(2,2)步长为2的filter，这样，经过pooling之后，输入的长宽都会缩小2倍，channels不变。")]),t._v(" "),v("p",[v("strong",[t._v("3. Fully Connected layer（全连接层--FC）")]),t._v("\n这个前面没有讲，是因为这个就是我们最熟悉的家伙，"),v("strong",[t._v("就是我们之前学的神经网络中的那种最普通的层，就是一排神经元")]),t._v("。因为这一层是每一个单元都和前一层的每一个单元相连接，所以称之为“全连接”。\n这里要指定的超参数，无非就是神经元的数量，以及激活函数。")]),t._v(" "),v("p",[t._v("接下来，我们随便看一个CNN的模样，来获取对CNN的一些感性认识：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597018184-image.png",alt:"一个CNN的例子"}})]),t._v(" "),v("p",[t._v("上面这个CNN是我随便拍脑门想的一个。它的结构可以用：\nX--\x3eCONV(relu)--\x3eMAXPOOL--\x3eCONV(relu)--\x3eFC(relu)--\x3eFC(softmax)--\x3eY\n来表示。")]),t._v(" "),v("p",[t._v("这里需要说明的是，在经过数次卷积和池化之后，我们 **最后会先将多维的数据进行“扁平化”，**也就是把 **(height,width,channel)**的数据压缩成长度为 "),v("strong",[t._v("height × width × channel")]),t._v(" 的一维数组，然后再与 "),v("strong",[t._v("FC层")]),t._v("连接，"),v("strong",[t._v("这之后就跟普通的神经网络无异了")]),t._v("。")]),t._v(" "),v("p",[t._v("可以从图中看到，随着网络的深入，我们的图像（严格来说中间的那些不能叫图像了，但是为了方便，还是这样说吧）越来越小，但是channels却越来越大了。在图中的表示就是长方体面对我们的面积越来越小，但是长度却越来越长了。")]),t._v(" "),v("hr"),t._v(" "),v("h2",{attrs:{id:"四、卷积神经网络-vs-传统神经网络"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#四、卷积神经网络-vs-传统神经网络"}},[t._v("#")]),t._v(" 四、卷积神经网络 VS. 传统神经网络")]),t._v(" "),v("p",[t._v("其实现在回过头来看，CNN跟我们之前学习的神经网络，也没有很大的差别。\n传统的神经网络，其实就是多个FC层叠加起来。\nCNN，无非就是把FC改成了CONV和POOL，就是把传统的由一个个神经元组成的layer，变成了由filters组成的layer。")]),t._v(" "),v("p",[t._v("那么，为什么要这样变？有什么好处？\n具体说来有两点：")]),t._v(" "),v("p",[v("strong",[t._v("1.参数共享机制（parameters sharing）")]),t._v("\n我们对比一下传统神经网络的层和由filters构成的CONV层：\n假设我们的图像是8×8大小，也就是64个像素，假设我们用一个有9个单元的全连接层：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597032687-image.png",alt:"使用全连接"}})]),t._v(" "),v("p",[t._v("那这一层我们需要多少个参数呢？需要 "),v("strong",[t._v("64×9 = 576个参数")]),t._v("（先不考虑偏置项b）。因为每一个链接都需要一个权重w。")]),t._v(" "),v("p",[t._v("那我们看看 "),v("strong",[t._v("同样有9个单元的filter")]),t._v("是怎么样的：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597046812-image.png",alt:"使用filter"}})]),t._v(" "),v("p",[t._v("其实不用看就知道，"),v("strong",[t._v("有几个单元就几个参数，所以总共就9个参数")]),t._v("！")]),t._v(" "),v("p",[t._v("因为，对于不同的区域，我们都共享同一个filter，因此就共享这同一组参数。\n这也是有道理的，通过前面的讲解我们知道，filter是用来检测特征的，"),v("strong",[t._v("那一个特征一般情况下很可能在不止一个地方出现")]),t._v("，比如“竖直边界”，就可能在一幅图中多出出现，那么 "),v("strong",[t._v("我们共享同一个filter不仅是合理的，而且是应该这么做的。")])]),t._v(" "),v("p",[t._v("由此可见，参数共享机制，"),v("strong",[t._v("让我们的网络的参数数量大大地减少")]),t._v("。这样，我们可以用较少的参数，训练出更加好的模型，典型的事半功倍，而且可以有效地 "),v("strong",[t._v("避免过拟合")]),t._v("。\n同样，由于filter的参数共享，即使图片进行了一定的平移操作，我们照样可以识别出特征，这叫做 "),v("strong",[t._v("“平移不变性”")]),t._v("。因此，模型就更加稳健了。")]),t._v(" "),v("p",[v("strong",[t._v("2.连接的稀疏性（sparsity of connections）")]),t._v("\n由卷积的操作可知，输出图像中的任何一个单元，"),v("strong",[t._v("只跟输入图像的一部分有关")]),t._v("系：")]),t._v(" "),v("p",[v("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/beyondguo/mdnice_pictures/2021-6-25/1624597060209-image.png",alt:"只跟输入的一部分有关"}})]),t._v(" "),v("p",[t._v("而传统神经网络中，由于都是全连接，所以输出的任何一个单元，都要受输入的所有的单元的影响。这样无形中会对图像的识别效果大打折扣。比较，每一个区域都有自己的专属特征，我们不希望它受到其他区域的影响。")]),t._v(" "),v("p",[v("strong",[t._v("正是由于上面这两大优势，使得CNN超越了传统的NN，开启了神经网络的新时代。")])]),t._v(" "),v("hr"),t._v(" "),v("blockquote",[v("p",[t._v("好了，今天的文章到此结束！今天是我画图最累的一次，不过也画的最有成就感的一次！没想到用PowerPoint也可以画出这么好看的图hhh，让我自己得意一下~~")])])])}),[],!1,null,null,null);n.default=e.exports}}]);